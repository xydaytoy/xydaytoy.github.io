<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>æœ­è®°</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-07-14T11:48:04.396Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>xydaytoy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>gitç‰ˆæœ¬æ§åˆ¶</title>
    <link href="http://example.com/2022/07/13/git-note/"/>
    <id>http://example.com/2022/07/13/git-note/</id>
    <published>2022-07-13T07:59:13.000Z</published>
    <updated>2022-07-14T11:48:04.396Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>gitåœ¨linuxç³»ç»Ÿå’Œwindowsç³»ç»Ÿä¸­è¿›è¡Œç‰ˆæœ¬æ§åˆ¶çš„å­¦ä¹ è®°å½•ã€‚</p><p>æƒ³è¦å®Œæˆä¸¤ä¸ªç›®æ ‡ï¼š</p><p>ä¸€æ˜¯åœ¨ä¸ªäººç”µè„‘å’Œå®éªŒå®¤ç”µè„‘éƒ½èƒ½å†™åšå®¢å¹¶åŒæ­¥å¤‡ä»½åˆ°githubï¼›</p><p>äºŒæ˜¯å°†linuxæœåŠ¡å™¨çš„ä»£ç å¤‡ä»½åˆ°æœ¬åœ°è®¡ç®—æœºä¸­ä¸€ä»½ï¼Œé˜²æ­¢ä¸¢å¤±ï¼Œæš‚æœªè§£å†³ã€‚</p><span id="more"></span></blockquote><h1 id="Gitå®‰è£…"><a href="#Gitå®‰è£…" class="headerlink" title="Gitå®‰è£…"></a>Gitå®‰è£…</h1><p>åœ¨windowsç³»ç»Ÿä¸­ï¼Œå¯ä»¥é€šè¿‡å®˜ç½‘ç›´æ¥ä¸‹è½½ï¼Œåœ¨æ–‡ä»¶å¤¹ç©ºç™½å¤„å³å‡»æ‰“å¼€<code>git bash</code>ï¼Œå…¶ä½™æ“ä½œå’Œlinuxä¸­ç›¸åŒï¼Œä¸‹é¢ç»Ÿä¸€æè¿°ã€‚</p><p>åœ¨linuxç³»ç»Ÿä¸­ç›´æ¥åœ¨å‘½ä»¤è¡Œä¸­è¿›è¡Œå®‰è£…ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install git</span><br></pre></td></tr></table></figure><p>æ£€æŸ¥æ˜¯å¦å·²ç»å®‰è£…ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git</span><br></pre></td></tr></table></figure><h1 id="å¸¸ç”¨å‘½ä»¤"><a href="#å¸¸ç”¨å‘½ä»¤" class="headerlink" title="å¸¸ç”¨å‘½ä»¤"></a>å¸¸ç”¨å‘½ä»¤</h1><h2 id="åˆ›å»ºç‰ˆæœ¬åº“ï¼š"><a href="#åˆ›å»ºç‰ˆæœ¬åº“ï¼š" class="headerlink" title="åˆ›å»ºç‰ˆæœ¬åº“ï¼š"></a>åˆ›å»ºç‰ˆæœ¬åº“ï¼š</h2><p>å°†ä¸€ä¸ªç›®å½•å˜ä¸ºgitå¯ç®¡ç†çš„ä»“åº“ï¼Œåˆ›å»ºåä¼šåœ¨æ–‡ä»¶å¤¹ä¸‹å¤šä¸€ä¸ª<code>.git</code>æ–‡ä»¶ï¼Œç”¨äºè·Ÿè¸ªç®¡ç†ç‰ˆæœ¬åº“ï¼Œæ˜¯éšè—æ–‡ä»¶å¤¹ã€‚</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir learngit</span><br><span class="line">cd learngit</span><br><span class="line">git init</span><br></pre></td></tr></table></figure><h2 id="æ·»åŠ æ–‡ä»¶åˆ°ç‰ˆæœ¬åº“"><a href="#æ·»åŠ æ–‡ä»¶åˆ°ç‰ˆæœ¬åº“" class="headerlink" title="æ·»åŠ æ–‡ä»¶åˆ°ç‰ˆæœ¬åº“"></a>æ·»åŠ æ–‡ä»¶åˆ°ç‰ˆæœ¬åº“</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add readme.md</span><br></pre></td></tr></table></figure><h2 id="å°†æ–‡ä»¶æäº¤åˆ°ä»“åº“"><a href="#å°†æ–‡ä»¶æäº¤åˆ°ä»“åº“" class="headerlink" title="å°†æ–‡ä»¶æäº¤åˆ°ä»“åº“"></a>å°†æ–‡ä»¶æäº¤åˆ°ä»“åº“</h2><p>å¼•å·ä¸­æ˜¯å¯¹æœ¬æ¬¡æäº¤çš„æè¿°ï¼Œå¯ä»¥å¤šæ¬¡æ·»åŠ æ–‡ä»¶åè¿›è¡Œç»Ÿä¸€æäº¤ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m &quot;add a readme file&quot;</span><br></pre></td></tr></table></figure><h2 id="æäº¤ä¿®æ”¹ç›¸å…³æ“ä½œ"><a href="#æäº¤ä¿®æ”¹ç›¸å…³æ“ä½œ" class="headerlink" title="æäº¤ä¿®æ”¹ç›¸å…³æ“ä½œ"></a>æäº¤ä¿®æ”¹ç›¸å…³æ“ä½œ</h2><p><code>git status</code>å¯ä»¥æŸ¥çœ‹å“ªäº›æ–‡ä»¶è¢«ä¿®æ”¹äº†è¿˜æ²¡æœ‰è¢«æäº¤ã€‚</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure><p>åœ¨æ–‡ä»¶è¢«<code>git add</code>å‘½ä»¤æ·»åŠ ä¹‹å‰ï¼Œ<code>git status</code>å‘½ä»¤çš„è¾“å‡ºï¼Œæ³¨æ„æ˜¯æœ‰addæç¤ºçš„ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">modified:   readme.txt</span><br><span class="line"></span><br><span class="line">no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)</span><br></pre></td></tr></table></figure><p>åœ¨æ–‡ä»¶è¢«<code>git add</code>å‘½ä»¤æ·»åŠ ä¹‹åï¼Œ<code>git status</code>å‘½ä»¤çš„è¾“å‡ºï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">modified:   readme.txt</span><br></pre></td></tr></table></figure><p>åœ¨æ–‡ä»¶è¢«<code>git commit</code>å‘½ä»¤æäº¤ä¹‹åï¼Œ<code>git status</code>å‘½ä»¤çš„è¾“å‡ºï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">On branch master</span><br><span class="line">nothing to commit, working tree clean</span><br></pre></td></tr></table></figure><p><code>git diff</code>å¯ä»¥æŸ¥çœ‹æ–‡ä»¶çš„å…·ä½“çš„æ›´æ”¹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git diff readme.md</span><br></pre></td></tr></table></figure><h2 id="ç‰ˆæœ¬å›é€€ç›¸å…³æ“ä½œ"><a href="#ç‰ˆæœ¬å›é€€ç›¸å…³æ“ä½œ" class="headerlink" title="ç‰ˆæœ¬å›é€€ç›¸å…³æ“ä½œ"></a>ç‰ˆæœ¬å›é€€ç›¸å…³æ“ä½œ</h2><p>æŸ¥çœ‹ç‰ˆæœ¬æ§åˆ¶çš„å†å²è®°å½•ï¼Œä»è¿‘åˆ°è¿œï¼Œå¯é€‰é¡¹å¯ä»¥è®©æ¯æ¡è®°å½•å•è¡Œå‘ˆç°ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log [--pretty=oneline]</span><br></pre></td></tr></table></figure><p>åœ¨gitä¸­ï¼Œ<code>HEAD</code>è¡¨ç¤ºå½“å‰ç‰ˆæœ¬ï¼Œ<code>HEAD^</code>è¡¨ç¤ºä¸Šä¸€ä¸ªç‰ˆæœ¬ï¼Œ<code>HEAD~100</code>è¡¨ç¤ºå¾€ä¸Šç¬¬100ä¸ªç‰ˆæœ¬ã€‚</p><p>å›é€€ä¸€ä¸ªç‰ˆæœ¬ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard HEAD^</span><br></pre></td></tr></table></figure><p>è¿™æ—¶ï¼Œlogä¸­å·²ç»æ²¡æœ‰å›é€€ä¹‹å‰çš„ç‰ˆæœ¬äº†ï¼Œå¦‚æœæƒ³è¦æ¢å¤ï¼Œéœ€è¦æ‰¾åˆ°å›é€€ä¹‹å‰ç‰ˆæœ¬çš„commit idï¼ˆä¸éœ€è¦å†™å…¨ï¼Œä¸äº§ç”Ÿæ­§ä¹‰å°±è¡Œï¼‰ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤è®°å½•æ¥æ‰¾åˆ°ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reflog</span><br></pre></td></tr></table></figure><h2 id="æ’¤é”€ä¿®æ”¹"><a href="#æ’¤é”€ä¿®æ”¹" class="headerlink" title="æ’¤é”€ä¿®æ”¹"></a>æ’¤é”€ä¿®æ”¹</h2><p>å·²ç»addä½†æ²¡æœ‰commitï¼Œéœ€è¦å°†æš‚å­˜åŒºçš„ä¿®æ”¹æ’¤é”€åˆ°å·¥ä½œåŒº</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset HEAD &lt;file&gt;</span><br></pre></td></tr></table></figure><p>å°†æ²¡æœ‰addçš„å·¥ä½œåŒºä¿®æ”¹æ’¤é”€</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -- &lt;file&gt;</span><br></pre></td></tr></table></figure><p>åˆ é™¤æ–‡ä»¶ä¹Ÿæ˜¯ä¸€æ ·ï¼Œå½“ç”¨rmæ“ä½œåï¼Œå·¥ä½œåŒºå’Œç‰ˆæœ¬åº“ä¸ä¸€æ ·ï¼Œè‹¥ç¡®å®éœ€è¦åˆ é™¤ï¼Œåˆ™</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git rm &lt;file&gt;</span><br><span class="line">git commit -m &quot;remove file&quot;</span><br></pre></td></tr></table></figure><p>è‹¥åˆ é™¤é”™äº†ï¼Œåˆ™å¯ä»¥ä»ç‰ˆæœ¬åº“ä¸­æ¢å¤</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -- &lt;file&gt;</span><br></pre></td></tr></table></figure><p><code>git checkout</code>æ˜¯ç”¨ç‰ˆæœ¬åº“ä¸­çš„ç‰ˆæœ¬ä»£æ›¿å·¥ä½œåŒºï¼Œå› æ­¤ä¸¤ç§æƒ…å†µéƒ½å¯ä»¥ç”¨ä½œæ’¤å›ã€‚</p><p>æ€»ç»“ä¸€ä¸‹ï¼Œ<code>git checkout</code>æ˜¯é’ˆå¯¹å·¥ä½œåŒºçš„ä¿®æ”¹ï¼›<code>git reset</code>å’Œ<code>git remove</code>æ˜¯é’ˆå¯¹ç‰ˆæœ¬åº“çš„ä¿®æ”¹ã€‚</p><h1 id="è¿œç¨‹ä»“åº“github"><a href="#è¿œç¨‹ä»“åº“github" class="headerlink" title="è¿œç¨‹ä»“åº“github"></a>è¿œç¨‹ä»“åº“github</h1><h2 id="åˆ›å»ºsshå¯†é’¥"><a href="#åˆ›å»ºsshå¯†é’¥" class="headerlink" title="åˆ›å»ºsshå¯†é’¥"></a>åˆ›å»ºsshå¯†é’¥</h2><p>åœ¨linuxçš„ç”¨æˆ·æ ¹ç›®å½•ä¸‹ï¼Œwindowsçš„<code>C:\Users\username</code>ä¸‹ï¼ŒæŸ¥çœ‹æœ‰æ²¡æœ‰<code>.ssh</code>ç›®å½•ï¼Œå’Œè¿™ä¸ªç›®å½•ä¸‹æœ‰æ²¡æœ‰<code>id_rsa</code>å’Œ<code>id_rsa.pub</code>è¿™ä¸¤ä¸ªæ–‡ä»¶ï¼Œå¦‚æœå·²ç»æœ‰äº†ï¼Œå¯ç›´æ¥è·³åˆ°ä¸‹ä¸€æ­¥ã€‚å¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºSSH Keyï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;youremail@example.com&quot;</span><br></pre></td></tr></table></figure><p>ç™»é™†GitHubï¼Œæ‰“å¼€â€œAccount settingsâ€ï¼Œâ€œSSH Keysâ€é¡µé¢ï¼Œç‚¹â€œAdd SSH Keyâ€ï¼Œå¡«ä¸Šä»»æ„Titleï¼Œåœ¨Keyæ–‡æœ¬æ¡†é‡Œç²˜è´´<code>id_rsa.pub</code>æ–‡ä»¶çš„å†…å®¹ï¼Œç‚¹â€œAdd Keyâ€ï¼Œä½ å°±åº”è¯¥çœ‹åˆ°å·²ç»æ·»åŠ çš„Keyã€‚</p><h2 id="æœ‰è¿œç¨‹ä»“åº“æ—¶å¦‚ä½•å…‹éš†åˆ°æœ¬åœ°"><a href="#æœ‰è¿œç¨‹ä»“åº“æ—¶å¦‚ä½•å…‹éš†åˆ°æœ¬åœ°" class="headerlink" title="æœ‰è¿œç¨‹ä»“åº“æ—¶å¦‚ä½•å…‹éš†åˆ°æœ¬åœ°"></a>æœ‰è¿œç¨‹ä»“åº“æ—¶å¦‚ä½•å…‹éš†åˆ°æœ¬åœ°</h2><p>å…ˆåˆ›å»ºè¿œç¨‹ä»“åº“å¯ä»¥ç›´æ¥ç”Ÿæˆreadmeæ–‡ä»¶ï¼Œåœ¨è¿œç¨‹åº“å‡†å¤‡å¥½åï¼Œé€šè¿‡<code>git clone</code>å…‹éš†åˆ°æœ¬åœ°</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:michaelliao/gitskills.git</span><br></pre></td></tr></table></figure><p>æ³¨ï¼š<code>michaelliao/gitskills</code>è¦æ”¹æˆè‡ªå·±çš„ç”¨æˆ·åå’Œä»“åº“åï¼Œè¿™é‡Œå¦‚æœæŠ¥é”™<code>The authenticity of host canâ€™t be established.</code>çš„è¯ï¼Œå¯èƒ½æ˜¯æ–‡ä»¶å¤¹å†…å°‘äº†ä¸€ä¸ªknown_hostsæ–‡ä»¶ï¼Œå¯ä»¥yeså›è½¦è§£å†³ã€‚</p><h2 id="å…ˆæœ‰æœ¬åœ°ä»“åº“æ—¶å¦‚ä½•å…³è”è¿œç¨‹ä»“åº“"><a href="#å…ˆæœ‰æœ¬åœ°ä»“åº“æ—¶å¦‚ä½•å…³è”è¿œç¨‹ä»“åº“" class="headerlink" title="å…ˆæœ‰æœ¬åœ°ä»“åº“æ—¶å¦‚ä½•å…³è”è¿œç¨‹ä»“åº“"></a>å…ˆæœ‰æœ¬åœ°ä»“åº“æ—¶å¦‚ä½•å…³è”è¿œç¨‹ä»“åº“</h2><p>é¦–å…ˆåˆ›å»ºä¸€ä¸ªgithubç©ºä»“åº“ï¼Œç„¶ååœ¨æœ¬åœ°ä»“åº“ä¸‹è¿è¡Œï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin git@github.com:michaelliao/learngit.git</span><br></pre></td></tr></table></figure><p><code>michaelliao/learngit</code>ç”¨è‡ªå·±çš„ç”¨æˆ·åå’Œä»“åº“åï¼Œ<code>origin</code>æ˜¯gité»˜è®¤çš„è¿œç¨‹ä»“åº“åï¼Œä¹Ÿå¯ä»¥æ”¹æˆåˆ«çš„</p><p>æŸ¥çœ‹è¿œç¨‹åº“ä¿¡æ¯ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote -v</span><br></pre></td></tr></table></figure><h2 id="å°†æœ¬åœ°ä»“åº“æ¨é€åˆ°è¿œç¨‹ä»“åº“"><a href="#å°†æœ¬åœ°ä»“åº“æ¨é€åˆ°è¿œç¨‹ä»“åº“" class="headerlink" title="å°†æœ¬åœ°ä»“åº“æ¨é€åˆ°è¿œç¨‹ä»“åº“"></a>å°†æœ¬åœ°ä»“åº“æ¨é€åˆ°è¿œç¨‹ä»“åº“</h2><p>å°†<code>main</code>åˆ†æ”¯æ¨é€åˆ°<code>origin</code>è¿œç¨‹ä»“åº“ï¼Œç¬¬ä¸€æ¬¡æ¨é€<code>master</code>åˆ†æ”¯æ—¶ï¼ŒåŠ ä¸Šäº†<code>-u</code>å‚æ•°ï¼ŒGitä¸ä½†ä¼šæŠŠæœ¬åœ°çš„<code>master</code>åˆ†æ”¯å†…å®¹æ¨é€çš„è¿œç¨‹æ–°çš„<code>master</code>åˆ†æ”¯ï¼Œè¿˜ä¼šæŠŠæœ¬åœ°çš„<code>master</code>åˆ†æ”¯å’Œè¿œç¨‹çš„<code>master</code>åˆ†æ”¯å…³è”èµ·æ¥ï¼Œåœ¨ä»¥åçš„æ¨é€æˆ–è€…æ‹‰å–æ—¶å°±å¯ä»¥ç®€åŒ–å‘½ä»¤ã€‚</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure><p>ä»¥åçš„æ¨é€å¯ä»¥ç”¨å‘½ä»¤</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push origin master</span><br></pre></td></tr></table></figure><h2 id="è§£é™¤å…³è”"><a href="#è§£é™¤å…³è”" class="headerlink" title="è§£é™¤å…³è”"></a>è§£é™¤å…³è”</h2><p>å…ˆæŸ¥çœ‹è¿œç¨‹åº“çš„ä¿¡æ¯</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote -v</span><br></pre></td></tr></table></figure><p>è§£é™¤å…³è”</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote rm origin</span><br></pre></td></tr></table></figure><h2 id="githubå¼€æºåº“"><a href="#githubå¼€æºåº“" class="headerlink" title="githubå¼€æºåº“"></a>githubå¼€æºåº“</h2><p>åœ¨githubä¸­çš„å¼€æºä»£ç ï¼Œå¯ä»¥å…ˆForkå…‹éš†åˆ°è‡ªå·±çš„ä»“åº“ï¼Œç„¶ååœ¨è‡ªå·±çš„è´¦å·ä¸‹cloneåˆ°æœ¬åœ°ä¿®æ”¹ï¼Œå†å‘è‡ªå·±çš„ä»“åº“æ¨é€ï¼Œå¦‚æœå¸Œæœ›å‘å¸ƒåˆ°åŸå§‹çš„githubä»“åº“ï¼Œå¯ä»¥å‘èµ·pull requestï¼Œéœ€è¦å¯¹æ–¹æ¥å—ã€‚</p><h1 id="åˆ†æ”¯ç®¡ç†"><a href="#åˆ†æ”¯ç®¡ç†" class="headerlink" title="åˆ†æ”¯ç®¡ç†"></a>åˆ†æ”¯ç®¡ç†</h1><p>æ¯æ¬¡æäº¤éƒ½æ˜¯gitæ—¶é—´çº¿ä¸Šçš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œ<code>master</code>æŒ‡å‘æœ€æ–°çš„æäº¤ï¼Œ<code>HEAD</code>æŒ‡å‘å½“å‰åˆ†æ”¯çš„æœ€æ–°æäº¤ç‚¹ï¼Œå½“åˆ›å»ºæ–°çš„åˆ†æ”¯æ—¶ï¼Œä¹Ÿå°±æ˜¯åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„æŒ‡é’ˆ<code>dev</code>æŒ‡å‘<code>master</code>ç›¸åŒçš„æŒ‡é’ˆï¼Œå°†<code>HEAD</code>æŒ‡å‘<code>dev</code>è¡¨ç¤ºå½“å‰åˆ†æ”¯åœ¨<code>dev</code>ä¸Šï¼Œåˆå¹¶åˆ é™¤å’Œåˆ›å»ºéƒ½æ˜¯æŒ‡é’ˆæ“ä½œï¼Œå› æ­¤é€Ÿåº¦å¾ˆå¿«ã€‚</p><h2 id="åˆ†æ”¯æ“ä½œ"><a href="#åˆ†æ”¯æ“ä½œ" class="headerlink" title="åˆ†æ”¯æ“ä½œ"></a>åˆ†æ”¯æ“ä½œ</h2><p>åˆ›å»ºå’Œåˆ‡æ¢åˆ°<code>dev</code>åˆ†æ”¯ï¼Œå¯ä»¥ç”¨<code>git checkout</code>å‘½ä»¤ï¼Œ<code>-b</code>è¡¨ç¤ºåˆ›å»ºå¹¶åˆ‡æ¢ï¼›</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b dev</span><br></pre></td></tr></table></figure><p>ä¹Ÿå¯ä»¥ç”¨ä¸“é—¨çš„å‘½ä»¤ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git switch -c dev</span><br></pre></td></tr></table></figure><p>ä¹Ÿå¯åˆ†ä¸¤æ­¥ç”¨ä¸¤æ¡å‘½ä»¤å®ç°ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git branch dev</span><br><span class="line">git checkout dev</span><br></pre></td></tr></table></figure><p>æŸ¥çœ‹å½“å‰åˆ†æ”¯ï¼Œä¼šåˆ—å‡ºå¤šæœ‰åˆ†æ”¯ï¼Œå½“å‰åˆ†æ”¯å‰æœ‰<code>*</code>å·ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure><p>åˆ‡æ¢å›<code>master</code>åˆ†æ”¯ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout master</span><br></pre></td></tr></table></figure><p>ä¹Ÿå¯ä»¥ç”¨ä¸“é—¨çš„å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git switch master</span><br></pre></td></tr></table></figure><p>å°†æŒ‡å®šåˆ†æ”¯<code>dev</code>åˆ†æ”¯çš„å·¥ä½œæˆæœåˆå¹¶åˆ°å½“å‰åˆ†æ”¯<code>master</code>åˆ†æ”¯ä¸Šï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git merge dev</span><br></pre></td></tr></table></figure><p>å½“å‡ºç°å†²çªæ—¶ï¼Œéœ€è¦æ‰‹åŠ¨è§£å†³å†²çªå†æäº¤ï¼Œç”¨<code>git log --graph</code>å¯ä»¥æŸ¥çœ‹åˆ†æ”¯åˆå¹¶å›¾ã€‚</p><p>åˆ é™¤<code>dev</code>åˆ†æ”¯</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -d dev  </span><br></pre></td></tr></table></figure><h2 id="å¤šäººåä½œ"><a href="#å¤šäººåä½œ" class="headerlink" title="å¤šäººåä½œ"></a>å¤šäººåä½œ</h2><p>é¦–å…ˆä»è¿œç¨‹å…‹éš†ä»“åº“åˆ°æœ¬åœ°ï¼Œé»˜è®¤æƒ…å†µåªèƒ½çœ‹åˆ°masteråˆ†æ”¯</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone git@github.com:michaelliao/learngit.git</span><br></pre></td></tr></table></figure><p>å‡è®¾æˆ‘ä»¬éœ€è¦åœ¨<code>dev</code>åˆ†æ”¯ä¸Šå¼€å‘ï¼Œåˆ™éœ€è¦åˆ›å»ºæœ¬åœ°çš„<code>dev</code>åˆ†æ”¯</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b dev origin originã€dev</span><br></pre></td></tr></table></figure><p>åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œä¿®æ”¹å’Œæäº¤å¹¶æ¨é€</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push origin dev</span><br></pre></td></tr></table></figure><p>å¦‚æœæ¨é€å¤±è´¥ï¼Œåˆ™å› ä¸ºè¿œç¨‹åˆ†æ”¯æ¯”ä½ çš„æœ¬åœ°æ›´æ–°ï¼Œéœ€è¦å…ˆç”¨<code>git pull</code>è¯•å›¾åˆå¹¶</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull</span><br></pre></td></tr></table></figure><p>å¦‚æœ<code>pull</code>å¤±è´¥ï¼Œæ˜¯å› ä¸ºæ²¡æœ‰æŒ‡å®šæœ¬åœ°<code>dev</code>åˆ†æ”¯ä¸è¿œç¨‹<code>origin/dev</code>åˆ†æ”¯çš„é“¾æ¥ï¼Œæ ¹æ®æç¤ºï¼Œè®¾ç½®<code>dev</code>å’Œ<code>origin/dev</code>çš„é“¾æ¥ï¼Œå¹¶å†æ¬¡<code>pull</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git branch --set-upstream-to=origin/dev dev</span><br><span class="line">git pull</span><br></pre></td></tr></table></figure><p>å¦‚æœå†æ¬¡æäº¤å’Œæ¨é€ï¼Œæ˜¾ç¤ºå†²çªï¼Œåˆ™æ‰‹åŠ¨è§£å†³å†²çªï¼Œå¹¶åœ¨æœ¬åœ°æäº¤ï¼›</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push origin dev</span><br></pre></td></tr></table></figure><h1 id="æ€»ç»“ä¸€ä¸‹"><a href="#æ€»ç»“ä¸€ä¸‹" class="headerlink" title="æ€»ç»“ä¸€ä¸‹"></a>æ€»ç»“ä¸€ä¸‹</h1><p>å¯¹ç¬¬ä¸€ä¸ªéœ€æ±‚ï¼ŒGithubå…è®¸æ·»åŠ å¤šä¸ªkeyï¼Œå¯ä»¥å°†æ¯å°ç”µè„‘çš„keyéƒ½æ·»åŠ åˆ°githubä¸­ï¼Œå³å¯å®ç°å¤šä¸ªè®¾å¤‡å¯¹åŒä¸€ä¸ªåº“çš„åŒæ­¥æ›´æ–°ï¼Œæ¯æ¬¡cloneä¸‹æ¥å¹¶è¿›è¡Œä¿®æ”¹æäº¤æ¨é€å³å¯ã€‚</p><p>å¯¹ç¬¬äºŒä¸ªéœ€æ±‚ï¼Œæš‚æœªè§£å†³å¤–ç½‘è®¿é—®çš„é—®é¢˜ã€‚</p><blockquote><p>å‚è€ƒï¼š<a href="https://www.liaoxuefeng.com/wiki/896043488029600/">https://www.liaoxuefeng.com/wiki/896043488029600/</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;gitåœ¨linuxç³»ç»Ÿå’Œwindowsç³»ç»Ÿä¸­è¿›è¡Œç‰ˆæœ¬æ§åˆ¶çš„å­¦ä¹ è®°å½•ã€‚&lt;/p&gt;
&lt;p&gt;æƒ³è¦å®Œæˆä¸¤ä¸ªç›®æ ‡ï¼š&lt;/p&gt;
&lt;p&gt;ä¸€æ˜¯åœ¨ä¸ªäººç”µè„‘å’Œå®éªŒå®¤ç”µè„‘éƒ½èƒ½å†™åšå®¢å¹¶åŒæ­¥å¤‡ä»½åˆ°githubï¼›&lt;/p&gt;
&lt;p&gt;äºŒæ˜¯å°†linuxæœåŠ¡å™¨çš„ä»£ç å¤‡ä»½åˆ°æœ¬åœ°è®¡ç®—æœºä¸­ä¸€ä»½ï¼Œé˜²æ­¢ä¸¢å¤±ï¼Œæš‚æœªè§£å†³ã€‚&lt;/p&gt;</summary>
    
    
    
    <category term="other" scheme="http://example.com/categories/other/"/>
    
    <category term="git" scheme="http://example.com/categories/other/git/"/>
    
    
  </entry>
  
  <entry>
    <title>æ¯å‘¨çŸ¥è¯†ç¢ç‰‡3</title>
    <link href="http://example.com/2022/03/31/weekly-220331/"/>
    <id>http://example.com/2022/03/31/weekly-220331/</id>
    <published>2022-03-31T12:17:50.000Z</published>
    <updated>2022-04-06T12:25:15.267Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ä¸‰æœˆçš„æœ€åä¸€å¤©ï¼å¤ªé˜³å¾ˆå¥½çš„ä¸€å¤©ï¼huggingfaceğŸ¤—ï¼</p></blockquote><span id="more"></span><h1 id="pythonä¸­çš„-staticmethodæ–¹æ³•"><a href="#pythonä¸­çš„-staticmethodæ–¹æ³•" class="headerlink" title="pythonä¸­çš„@staticmethodæ–¹æ³•"></a>pythonä¸­çš„@staticmethodæ–¹æ³•</h1><p>ä½œç”¨ï¼šæ–¹ä¾¿å¤–éƒ¨å‡½æ•°é›†æˆåˆ°ç±»ä¸­ï¼Œå¯ä»¥<strong>åœ¨ä¸å®ä¾‹åŒ–ç±»çš„æƒ…å†µä¸‹ç›´æ¥è®¿é—®è¯¥æ–¹æ³•</strong>ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>:</span></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,num</span>):</span></span><br><span class="line">            self.num = num;</span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">cout_num</span>(<span class="params">self</span>):</span></span><br><span class="line">            <span class="built_in">print</span>(self.num)</span><br><span class="line"><span class="meta">      @staticmethod</span></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">print_num</span>():</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Hello World&quot;</span>)         </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">      <span class="string">&quot;&quot;&quot;å®ä¾‹åŒ–&quot;&quot;&quot;</span></span><br><span class="line">      obj = Test(<span class="number">10</span>)</span><br><span class="line">      <span class="string">&quot;&quot;&quot;å®ä¾‹åŒ–æˆå‘˜æ–¹æ³•&quot;&quot;&quot;</span></span><br><span class="line">      obj.cout_num()</span><br><span class="line">      <span class="string">&quot;&quot;&quot;ç›´æ¥è®¿é—®é™æ€æ–¹æ³•&quot;&quot;&quot;</span></span><br><span class="line">      Test.print_num()</span><br><span class="line">      <span class="string">&quot;&quot;&quot;å®ä¾‹åŒ– è®¿é—®é™æ€æ–¹æ³•&quot;&quot;&quot;</span></span><br><span class="line">      obj.print_num()</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;è¾“å‡ºç»“æœ&quot;&quot;&quot;</span></span><br><span class="line"><span class="number">10</span></span><br><span class="line">Hello World</span><br><span class="line">Hello World</span><br></pre></td></tr></table></figure><p>åœ¨è¯»embeddingç±»çš„ä»£ç ï¼ˆ<a href="https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/models/WordEmbeddings.py">sentence-transformers/sentence-transformers/models/WordEmbeddings.py</a>ï¼‰æ—¶çœ‹åˆ°è¯¥æ–¹æ³•ï¼Œå®ä¾‹åŒ–æ–¹æ³•éœ€è¦ä¼ å…¥embedding_weightå˜é‡ï¼Œé€šè¿‡staticmethodå¯ä»¥ç›´æ¥é€šè¿‡txtæ–‡ä»¶æˆ–è€…æ¨¡å‹æ¥åˆ›å»ºå®ä¾‹ï¼Œç›¸å½“äºæä¾›äº†ä¸‰ç§åˆ›å»ºæ–¹æ³•ã€‚</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;ä¸‰æœˆçš„æœ€åä¸€å¤©ï¼å¤ªé˜³å¾ˆå¥½çš„ä¸€å¤©ï¼huggingfaceğŸ¤—ï¼&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="weekly" scheme="http://example.com/categories/weekly/"/>
    
    
  </entry>
  
  <entry>
    <title>linuxç¯å¢ƒæ­å»º</title>
    <link href="http://example.com/2022/03/19/environment/"/>
    <id>http://example.com/2022/03/19/environment/</id>
    <published>2022-03-19T08:43:08.000Z</published>
    <updated>2022-04-06T12:32:41.492Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>linuxä¸Šç¯å¢ƒæ­å»ºè®°å½•ï¼ˆgpuï¼‰ã€‚</p></blockquote><span id="more"></span><h1 id="æ•´ä½“æµç¨‹"><a href="#æ•´ä½“æµç¨‹" class="headerlink" title="æ•´ä½“æµç¨‹"></a>æ•´ä½“æµç¨‹</h1><p>anacondaå®‰è£…</p><p>pytorchï¼ˆcudaç‰ˆæœ¬ï¼‰å®‰è£…</p><p>fairseqå®‰è£…</p><p>huggingfaceå®‰è£…</p><p>requirements.txtç”Ÿæˆ</p><h1 id="1-anacondaå®‰è£…"><a href="#1-anacondaå®‰è£…" class="headerlink" title="1 anacondaå®‰è£…"></a>1 anacondaå®‰è£…</h1><p>åœ¨<a href="https://www.anaconda.com/products/individual">anacondaå®˜ç½‘</a>ä¸Šæ‰¾åˆ°ç¬¦åˆç³»ç»Ÿå’Œé…ç½®çš„ç‰ˆæœ¬ï¼Œå¤åˆ¶ä¸‹è½½é“¾æ¥ï¼Œä½¿ç”¨wgetå‘½ä»¤å®‰è£…ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://repo.anaconda.com/archive/Anaconda3-2021.11-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>æ‰§è¡Œå®‰è£…ç¨‹åºï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3-2021.11-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>ä¸­é—´è¿‡ç¨‹é€‰æ‹©yesï¼Œå°†condaåŠ å…¥ç¯å¢ƒå˜é‡ï¼Œç»“æŸåè¾“å…¥ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda -V</span><br></pre></td></tr></table></figure><p>å¦‚å‡ºç°ç‰ˆæœ¬å·è¯´æ˜å®‰è£…æˆåŠŸã€‚</p><p>åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼Œä¸ºé…ç½®ç‰¹å®šç¯å¢ƒåšå‡†å¤‡ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n envname python&#x3D;3.x</span><br></pre></td></tr></table></figure><p><em>tips</em>ï¼š</p><p>æŸ¥çœ‹linuxçš„ç³»ç»Ÿæ„æ¶çš„å‘½ä»¤ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$</span><span class="bash"> arch</span></span><br></pre></td></tr></table></figure><h1 id="2-pytorch-cudaå®‰è£…"><a href="#2-pytorch-cudaå®‰è£…" class="headerlink" title="2 pytorch+cudaå®‰è£…"></a>2 pytorch+cudaå®‰è£…</h1><p>åœ¨<a href="https://pytorch.org/get-started/locally/">pytorchå®˜ç½‘</a>æ ¹æ®ç³»ç»Ÿå’Œç‰ˆæœ¬å¤åˆ¶å®‰è£…å‘½ä»¤ï¼Œå¦‚æœé¦–é¡µæ²¡æœ‰æ‰€éœ€ç‰ˆæœ¬å¯åœ¨â€œYou can also <a href="https://pytorch.org/get-started/previous-versions">install previous versions of PyTorch</a>â€œå¤„æŸ¥æ‰¾ã€‚</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch</span><br></pre></td></tr></table></figure><p>æµ‹è¯•æ˜¯å¦å®‰è£…æˆåŠŸï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">flag = torch.cuda.is_available()</span><br><span class="line">print(flag)</span><br><span class="line">ngpu= 1</span><br><span class="line">device = torch.device(&quot;cuda:0&quot; if (torch.cuda.is_available() and ngpu &gt; 0) else &quot;cpu&quot;)</span><br><span class="line">print(device)</span><br><span class="line">print(torch.cuda.get_device_name(0))</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">True</span><br><span class="line">cuda:0</span><br><span class="line">NVIDIA GeForce RTX 3090</span><br></pre></td></tr></table></figure><h1 id="3-huggingfaceå®‰è£…"><a href="#3-huggingfaceå®‰è£…" class="headerlink" title="3 huggingfaceå®‰è£…"></a>3 huggingfaceå®‰è£…</h1><p>æ­¤å¤„é€‰æ‹©æºç æ–¹å¼å®‰è£…huggingfaceä¾¿äºè‡ªè¡Œä¿®æ”¹ï¼Œå…¶å®ƒå®‰è£…æ–¹å¼åœ¨<a href="https://huggingface.co/docs/transformers/installation">å®˜ç½‘</a>ä¸­æœ‰ä»‹ç»ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;transformers.git</span><br><span class="line">cd transformers</span><br><span class="line">pip install -e .</span><br></pre></td></tr></table></figure><p><em>tips</em>ï¼š</p><p><code>pip install -e</code>çš„ä½œç”¨æ˜¯æ·»åŠ éå®˜æ–¹çš„æ¨¡å—ï¼Œå…ˆä¸‹è½½æºç ï¼Œè¿›å…¥æºç ç›®å½•ï¼Œå¹¶æ‰§è¡Œè¯¥å‘½ä»¤å¯è§£å†³<code>No module named &#39;XXX&#39;</code>çš„æŠ¥é”™ï¼Œå®ƒè¿›è¡Œçš„æ“ä½œæœ‰ï¼š</p><ul><li>å®‰è£…site-packages/PackageName.egg-linkæ–‡ä»¶</li><li>æ·»åŠ è·¯å¾„ site-packages/easy-install.pth</li></ul><h1 id="4-æ¸…åæºåŠ é€Ÿ"><a href="#4-æ¸…åæºåŠ é€Ÿ" class="headerlink" title="4 æ¸…åæºåŠ é€Ÿ"></a>4 æ¸…åæºåŠ é€Ÿ</h1><p>pipé€Ÿåº¦æ…¢æˆ–å‡ºç°è¶…æ—¶é”™è¯¯æ—¶ï¼Œè€ƒè™‘æ¢æˆæ¸…åæºä¸‹è½½åŒ…ã€‚</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple xxx</span><br></pre></td></tr></table></figure><h1 id="5-requirements-txtç”Ÿæˆ"><a href="#5-requirements-txtç”Ÿæˆ" class="headerlink" title="5 requirements.txtç”Ÿæˆ"></a>5 requirements.txtç”Ÿæˆ</h1><p>5.1 ç”Ÿæˆå½“å‰ç¯å¢ƒä¸‹çš„æ‰€æœ‰ä¾èµ–ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip freeze &gt; requirements.txt</span><br></pre></td></tr></table></figure><p>5.2 ç”ŸæˆæŒ‡å®šé¡¹ç›®ä¸‹çš„æ‰€æœ‰ä¾èµ–ï¼š</p><p><em>tipsï¼šæ ¹æ®importï¼Œå³é¡¹ç›®å¼•å…¥äº†å“ªäº›åŒ…æ‰ä¼šå†™è¿›requirements.txtä¸­ï¼Œç›¸æ¯”å‰ä¸€ç§æ–¹æ³•æ›´ç®€æ´ï¼Œä½†å¯èƒ½åŒ…å«çš„åŒ…ä¸å…¨ã€‚</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install pipreqs</span><br><span class="line">pipreqs ./ [--encoding=utf-8]</span><br></pre></td></tr></table></figure><p>5.3 å®‰è£…requirements.txtè¦æ±‚çš„æ‰€æœ‰æ¨¡å—:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt [-i HTTPS://mirrors.aliyun.com/pypi/simple/]</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;linuxä¸Šç¯å¢ƒæ­å»ºè®°å½•ï¼ˆgpuï¼‰ã€‚&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="other" scheme="http://example.com/categories/other/"/>
    
    <category term="linux" scheme="http://example.com/categories/other/linux/"/>
    
    
  </entry>
  
  <entry>
    <title>æ¯å‘¨çŸ¥è¯†ç¢ç‰‡2</title>
    <link href="http://example.com/2022/01/20/weekly-220120/"/>
    <id>http://example.com/2022/01/20/weekly-220120/</id>
    <published>2022-01-20T15:12:39.000Z</published>
    <updated>2022-01-21T13:52:48.514Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>åŠ›æ‰£åŠ›æ‰£åŠ›æ‰£ï¼</p></blockquote><span id="more"></span><h1 id="python-åˆå§‹åŒ–å…¨é›¶çš„äºŒç»´åˆ—è¡¨"><a href="#python-åˆå§‹åŒ–å…¨é›¶çš„äºŒç»´åˆ—è¡¨" class="headerlink" title="python åˆå§‹åŒ–å…¨é›¶çš„äºŒç»´åˆ—è¡¨"></a>python åˆå§‹åŒ–å…¨é›¶çš„äºŒç»´åˆ—è¡¨</h1><p>åˆå§‹åŒ–ä¸€ä¸ªå…¨é›¶çš„n*mçš„äºŒç»´åˆ—è¡¨ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list1=[[<span class="number">0</span>]*(m) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br></pre></td></tr></table></figure><p>é”™è¯¯çš„åˆ›å»ºæ–¹å¼ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list2=[[<span class="number">0</span>]*m]*nde</span><br></pre></td></tr></table></figure><p>åœ¨åç»­ä¿®æ”¹å€¼çš„è¿‡ç¨‹ä¸­ä¼šå‡ºç°é—®é¢˜ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list2[<span class="number">0</span>][<span class="number">0</span>]=<span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(list2)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[2, 0, 0], [2, 0, 0]]</span><br></pre></td></tr></table></figure><h1 id="python-åˆå€¼é»˜è®¤çš„å­—å…¸"><a href="#python-åˆå€¼é»˜è®¤çš„å­—å…¸" class="headerlink" title="python åˆå€¼é»˜è®¤çš„å­—å…¸"></a>python åˆå€¼é»˜è®¤çš„å­—å…¸</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line">dict1 = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">dict2 = defaultdict(<span class="built_in">set</span>)</span><br><span class="line">dict3 = defaultdict(<span class="built_in">str</span>)</span><br><span class="line">dict4 = defaultdict(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dict1[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(dict2[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(dict3[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(dict4[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>åœ¨ä½¿ç”¨dict[n]æ—¶ï¼Œä¸ä¼šå‡ºç°keyä¸å­˜åœ¨çš„æƒ…å†µï¼Œä¼šè¿”å›é»˜è®¤å€¼ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0</span><br><span class="line">set()</span><br><span class="line"></span><br><span class="line">[]</span><br></pre></td></tr></table></figure><h1 id="åŠ›æ‰£-å‰‘æŒ‡offer-æ•°ç»„"><a href="#åŠ›æ‰£-å‰‘æŒ‡offer-æ•°ç»„" class="headerlink" title="åŠ›æ‰£-å‰‘æŒ‡offer-æ•°ç»„"></a>åŠ›æ‰£-å‰‘æŒ‡offer-æ•°ç»„</h1><p>â…¡007ï¼š</p><p>æ’åºåæœ‰ä¸€ä¸ªé¡ºåºçš„ä¿¡æ¯å¯ä»¥åˆ©ç”¨ï¼Œå›ºå®šä¸€ä¸ªå€¼ï¼ˆè·³è¿‡çœç•¥å’Œè¿‡å¤§çš„å€¼ï¼‰ï¼Œå¦å¤–ä¸¤ä¸ªç”¨ä¸¤ä¸ªæŒ‡é’ˆæ ¹æ®å¤§å°è°ƒæ•´å¯ä»¥æ›´å¿«çš„æŸ¥æ‰¾ã€‚</p><p>â…¡010ï¼š</p><p>æ•°ç»„å…ƒç´ å­˜åœ¨è´Ÿæ•°æ—¶ä¸èƒ½ç”¨åŒæŒ‡é’ˆæ»‘çª—ï¼Œå› ä¸ºä¸æ»¡è¶³æ¡ä»¶å°±æ»‘çª—çš„æ€§è´¨ä¸å…·å¤‡äº†ï¼Œè¿™æ˜¯é‡‡ç”¨å‰ç¼€å’Œå’Œå“ˆå¸Œè¡¨ã€‚</p><p>â…¡011ï¼š</p><p>æŠŠ0æ¢æˆ-1å°±å’Œä¸Šä¸€é“é¢˜çš„å’Œä¸ºkçš„å­æ•°ç»„ä¸€æ ·äº†ï¼Œç”¨å­—å…¸è®°å½•ä¸€ä¸‹æœ€å¼€å¤´çš„ç›¸åŒå‰ç¼€å’Œçš„ä½ç½®å³å¯ã€‚</p><p>â…¡013ï¼š</p><p>äºŒç»´å‰ç¼€å’Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯äºŒç»´å…¨é›¶åˆ—è¡¨çš„åˆå§‹åŒ–æ–¹å¼ï¼ˆé”™è¯¯çš„åˆå§‹åŒ–æ–¹å¼ä¼šå¯¼è‡´åœ¨åæœŸèµ‹å€¼çš„æ—¶å€™å‡ºç°é”™è¯¯ï¼‰</p><h1 id="å¦‚ä½•åˆ¤æ–­ç ”ç©¶å·¥ä½œçš„ä»·å€¼ï¼ˆææ²ï¼‰"><a href="#å¦‚ä½•åˆ¤æ–­ç ”ç©¶å·¥ä½œçš„ä»·å€¼ï¼ˆææ²ï¼‰" class="headerlink" title="å¦‚ä½•åˆ¤æ–­ç ”ç©¶å·¥ä½œçš„ä»·å€¼ï¼ˆææ²ï¼‰"></a>å¦‚ä½•åˆ¤æ–­ç ”ç©¶å·¥ä½œçš„ä»·å€¼ï¼ˆææ²ï¼‰</h1><h2 id="ä¸€å¥è¯ï¼šç”¨æœ‰æ–°æ„çš„æ–¹æ³•æœ‰æ•ˆçš„è§£å†³ä¸€ä¸ªç ”ç©¶é—®é¢˜ã€‚"><a href="#ä¸€å¥è¯ï¼šç”¨æœ‰æ–°æ„çš„æ–¹æ³•æœ‰æ•ˆçš„è§£å†³ä¸€ä¸ªç ”ç©¶é—®é¢˜ã€‚" class="headerlink" title="ä¸€å¥è¯ï¼šç”¨æœ‰æ–°æ„çš„æ–¹æ³•æœ‰æ•ˆçš„è§£å†³ä¸€ä¸ªç ”ç©¶é—®é¢˜ã€‚"></a>ä¸€å¥è¯ï¼šç”¨æœ‰<strong>æ–°æ„</strong>çš„æ–¹æ³•<strong>æœ‰æ•ˆ</strong>çš„è§£å†³ä¸€ä¸ª<strong>ç ”ç©¶</strong>é—®é¢˜ã€‚</h2><p><strong>ç ”ç©¶</strong>ï¼š<br>å·¥ç¨‹é—®é¢˜ï¼šä¾‹å¦‚å†…å­˜ï¼Œç²¾åº¦ç­‰é—®é¢˜ï¼Œå¯¹äºä¸€ä¸ªé—®é¢˜å¯ä»¥æå‡ºå‡ ä¸ªè§£å†³æ–¹æ¡ˆï¼ˆä¹°å†…å­˜ï¼Œæ ‡æ•°æ®ï¼‰ï¼Œå¹¶ä¸”åœ¨æ–¹æ¡ˆæ²¡æœ‰å®éªŒçš„æ—¶å€™å°±çŸ¥é“ä¸€å®šå¯ä»¥è§£å†³é—®é¢˜ï¼Œé‚£ä¹ˆå±äºå·¥ç¨‹é—®é¢˜ã€‚<br>ç ”ç©¶é—®é¢˜ï¼šæ¯”è¾ƒå›°éš¾ï¼Œå¯ä»¥æƒ³åˆ°çš„è§£å†³æ–¹æ¡ˆåœ¨å®éªŒå‰ä¸èƒ½ç¡®å®šæ˜¯å¦å¯ä»¥è§£å†³é—®é¢˜ã€‚</p><p><strong>æœ‰æ•ˆ</strong>ï¼š</p><p>ç›¸å¯¹äºä¹‹å‰çš„å·¥ä½œï¼Œæˆ‘è§£å†³è¿™ä¸ªé—®é¢˜çš„æœ‰æ•ˆæ€§æœ‰æ‰€æå‡ã€‚</p><p><strong>æ–°æ„</strong>ï¼š</p><p>å¯¹æ‰€åœ¨ç ”ç©¶ç¤¾åŒºé‡Œé¢çš„ç»å¤§å¤šæ•°ç ”ç©¶è€…æ˜¯æœ‰æ–°æ„çš„ï¼Œå¯èƒ½æ˜¯å¾ˆä¹…ä¹‹å‰çš„æ–¹æ³•ï¼Œæˆ–è€…åœ¨åˆ«çš„é¢†åŸŸæœ‰ç ”ç©¶è€…åœ¨ä½¿ç”¨çš„æ–¹æ³•ã€‚</p><p><em>è¿™ä¹Ÿå¯ä»¥ä½“ç°åœ¨è‡ªå·±å†™è®ºæ–‡æ‘˜è¦çš„æ—¶å€™</em>ï¼š</p><p>æˆ‘è¦è§£å†³ä¸€ä¸ªä»€ä¹ˆç ”ç©¶é—®é¢˜ï¼Œæˆ‘ç”¨çš„æ–¹æ³•æ–°æ„åœ¨å“ªï¼Œæœ€åæˆ‘çš„ç»“æœå¦‚ä½•ã€‚</p><h2 id="ä»·å€¼-æ–°æ„åº¦-æœ‰æ•ˆæ€§-é—®é¢˜å¤§å°"><a href="#ä»·å€¼-æ–°æ„åº¦-æœ‰æ•ˆæ€§-é—®é¢˜å¤§å°" class="headerlink" title="ä»·å€¼ = æ–°æ„åº¦ * æœ‰æ•ˆæ€§ * é—®é¢˜å¤§å°"></a>ä»·å€¼ = æ–°æ„åº¦ * æœ‰æ•ˆæ€§ * é—®é¢˜å¤§å°</h2><p><strong>é—®é¢˜å¤§å°</strong>ï¼š</p><p>1ï¼šå¯¹å‰ä¸€ä¸ªå·¥ä½œä¸å¥½çš„åœ°æ–¹è¿›è¡Œæ”¹è¿›</p><p>10ï¼šå¯¹ä¸€ä¸ªé¢†åŸŸçš„æŸä¸ªå­ä»»åŠ¡è¿›è¡Œæå‡</p><p>100ï¼šæå‡æœºå™¨å¯¹æ–‡å­—/å›¾ç‰‡çš„ç†è§£</p><p><strong>æœ‰æ•ˆæ€§</strong>ï¼š</p><p>1ï¼šå¯èƒ½å¤šæ¬¡å®éªŒç²¾åº¦æå‡ä¸æ˜æ˜¾</p><p>10ï¼šä¸€ä¸ªç‚¹</p><p>100ï¼šäº”ä¸ªç‚¹</p><p>æ•ˆæœå¥½ï¼Œè§„æ¨¡åšå¤§ï¼ˆæˆæœ¬é™ä½ï¼‰ï¼Œå®‰å…¨</p><p><strong>æ–°æ„åº¦</strong>ï¼š</p><p>1ï¼šå¤§å®¶éƒ½ä¸æ„å¤–æ–¹æ³•ï¼ŒåŒæ—¶çœ‹åˆ°æ–¹æ³•çš„æ—¶å€™ä¸æ„å¤–ç»“æœ</p><p>10ï¼šåœ¨æŸä¸€ä¸ªæ–¹é¢ç”¨æŸä¸ªæŠ€æœ¯èªæ˜çš„è§£å†³é—®é¢˜</p><p>100ï¼šç”¨äº†ä¸€ä¸ªå¤§å®¶ä¸ç†Ÿæ‚‰çš„æŠ€æœ¯</p><p><em>åœ¨æŸä¸€ä¸ªæŒ‡æ ‡ä¸Šè¾¾åˆ°è¾ƒå¥½ç®—ä¸€ä¸ªæœ‰ä»·å€¼çš„å·¥ä½œã€‚</em></p><h1 id="æ€æ ·è¯»è®ºæ–‡ï¼ˆææ²ï¼‰"><a href="#æ€æ ·è¯»è®ºæ–‡ï¼ˆææ²ï¼‰" class="headerlink" title="æ€æ ·è¯»è®ºæ–‡ï¼ˆææ²ï¼‰"></a>æ€æ ·è¯»è®ºæ–‡ï¼ˆææ²ï¼‰</h1><p><strong>ç¬¬ä¸€é</strong>ï¼š</p><p>æ ‡é¢˜ã€æ‘˜è¦ã€ç»“è®ºã€‚å¯ä»¥çœ‹ä¸€çœ‹æ–¹æ³•å’Œå®éªŒéƒ¨åˆ†é‡è¦çš„å›¾å’Œè¡¨ã€‚èŠ±è´¹åå‡ åˆ†é’Ÿæ—¶é—´äº†è§£åˆ°è®ºæ–‡æ˜¯å¦é€‚åˆä½ çš„ç ”ç©¶æ–¹å‘ã€‚</p><p><strong>ç¬¬äºŒé</strong>ï¼š</p><p>ç¡®å®šè®ºæ–‡å€¼å¾—è¯»ä¹‹åï¼Œå¯ä»¥å¿«é€Ÿçš„æŠŠæ•´ä¸ªè®ºæ–‡è¿‡ä¸€éï¼Œä¸éœ€è¦çŸ¥é“æ‰€æœ‰çš„ç»†èŠ‚ï¼Œéœ€è¦äº†è§£é‡è¦çš„å›¾å’Œè¡¨ï¼ŒçŸ¥é“æ¯ä¸€ä¸ªéƒ¨åˆ†åœ¨å¹²ä»€ä¹ˆï¼Œåœˆå‡ºç›¸å…³æ–‡çŒ®ã€‚è§‰å¾—æ–‡ç« å¤ªéš¾ï¼Œå¯ä»¥è¯»å¼•ç”¨çš„æ–‡çŒ®ã€‚</p><p><strong>ç¬¬ä¸‰é</strong>ï¼š</p><p>è¦çŸ¥é“æ¯ä¸€å¥è¯æ¯ä¸€æ®µåœ¨è¯´ä»€ä¹ˆï¼Œåœ¨å¿ƒé‡Œå¤è¿°ä¸€ä¸‹æ–‡ç« æå‡ºä»€ä¹ˆé—®é¢˜ï¼Œç”¨ä»€ä¹ˆæ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå®éªŒæ˜¯æ€ä¹ˆåšçš„ã€‚æƒ³ä¸€ä¸‹å¦‚æœæ˜¯æˆ‘æ¥åšæˆ‘è¦æ€ä¹ˆåšï¼Œä½œè€…æ²¡æœ‰è§£å†³çš„é—®é¢˜æˆ‘æ˜¯å¦æœ‰åˆé€‚çš„æ–¹æ³•å¯ä»¥ç»§ç»­è§£å†³ã€‚åˆä¸Šæ–‡ç« ï¼Œå›å¿†æ¯ä¸€ä¸ªéƒ¨åˆ†åœ¨è®²ä»€ä¹ˆã€‚</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;åŠ›æ‰£åŠ›æ‰£åŠ›æ‰£ï¼&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="weekly" scheme="http://example.com/categories/weekly/"/>
    
    
  </entry>
  
  <entry>
    <title>æ¯å‘¨çŸ¥è¯†ç¢ç‰‡1</title>
    <link href="http://example.com/2021/11/29/weekly-211129/"/>
    <id>http://example.com/2021/11/29/weekly-211129/</id>
    <published>2021-11-29T07:49:47.000Z</published>
    <updated>2021-11-29T10:54:58.252Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ç–¯ç‹‚å†™å¤§ä½œä¸šçš„ä¸€å‘¨ã€‚</p></blockquote><span id="more"></span><h1 id="python-è·å–è·¯å¾„ç›¸å…³"><a href="#python-è·å–è·¯å¾„ç›¸å…³" class="headerlink" title="python è·å–è·¯å¾„ç›¸å…³"></a>python è·å–è·¯å¾„ç›¸å…³</h1><p>è·å–linuxä¸‹çš„ç”¨æˆ·æ ¹è·¯å¾„</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> os</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>os.envrion[<span class="string">&#x27;HOME&#x27;</span>]</span><br><span class="line"><span class="string">&#x27;/home/user&#x27;</span></span><br></pre></td></tr></table></figure><p>è¿æ¥è·¯å¾„</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import os</span><br><span class="line">&gt;&gt;&gt; os.path.join(os.envrion[&#39;HOME&#39;], &#39;xxx&#39;, &#39;yyy.txt&#39;)</span><br><span class="line">&#39;&#x2F;home&#x2F;user&#x2F;xxx&#x2F;yyy.txt&#39;</span><br></pre></td></tr></table></figure><p>globè¿”å›æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from glob import glob</span><br><span class="line">&gt;&gt;&gt; files &#x3D; glob(os.path.join(ROOT, cat, &#39;*.txt&#39;))</span><br><span class="line">[&#39;xxx.txt&#39;, &#39;111.txt&#39;]</span><br></pre></td></tr></table></figure><h1 id="é”™è¯¯ï¼šAttributeError-module-â€˜threadingâ€™-has-no-attribute-â€˜RLockâ€™"><a href="#é”™è¯¯ï¼šAttributeError-module-â€˜threadingâ€™-has-no-attribute-â€˜RLockâ€™" class="headerlink" title="é”™è¯¯ï¼šAttributeError: module â€˜threadingâ€™ has no attribute â€˜RLockâ€™"></a>é”™è¯¯ï¼šAttributeError: module â€˜threadingâ€™ has no attribute â€˜RLockâ€™</h1><p><strong>é”™è¯¯åŸå› </strong>ï¼šè‡ªå·±çš„ä»£ç æ–‡ä»¶ä¸pythonè‡ªå¸¦çš„è„šæœ¬æ–‡ä»¶é‡åï¼Œå¯¼è‡´importå¼•å…¥åŒ…çš„æ—¶å€™å¼•å…¥é”™è¯¯ã€‚</p><p><strong>ä¿®æ”¹åŠæ³•</strong>ï¼šæ ¹æ®é”™è¯¯æç¤ºï¼Œä¿®æ”¹ç›¸å…³æ–‡ä»¶çš„æ–‡ä»¶åï¼Œè¦æ³¨æ„é™¤äº†æç¤ºçš„åŒ…ï¼Œåœ¨å¼•å…¥è¯¥åŒ…çš„è¿‡ç¨‹ä¸­å¼•å…¥çš„å…¶ä»–åŒ…çš„é”™è¯¯ä¹Ÿå¯èƒ½å¯¼è‡´è¿™ä¸ªé”™è¯¯æç¤ºï¼Œä¾‹å¦‚è¯¥é”™è¯¯æç¤ºä¸ºï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">nohup: ignoring input</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;data/split_data.py&quot;, line 4, in &lt;module&gt;</span><br><span class="line">    import pandas as pd</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/site-packages/pandas/__init__.py&quot;, line 11, in &lt;module&gt;</span><br><span class="line">    __import__(dependency)</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/site-packages/numpy/__init__.py&quot;, line 142, in &lt;module&gt;</span><br><span class="line">    from . import core</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/site-packages/numpy/core/__init__.py&quot;, line 103, in &lt;module&gt;</span><br><span class="line">    from . import _internal</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/site-packages/numpy/core/_internal.py&quot;, line 11, in &lt;module&gt;</span><br><span class="line">    import platform</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/platform.py&quot;, line 117, in &lt;module&gt;</span><br><span class="line">    import sys, os, re, subprocess</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/subprocess.py&quot;, line 131, in &lt;module&gt;</span><br><span class="line">    import threading</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/threading.py&quot;, line 7, in &lt;module&gt;</span><br><span class="line">    from traceback import format_exc as _format_exc</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/traceback.py&quot;, line 5, in &lt;module&gt;</span><br><span class="line">    import linecache</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/linecache.py&quot;, line 11, in &lt;module&gt;</span><br><span class="line">    import tokenize</span><br><span class="line">  File &quot;/home/user/text-classify/Bert-THUCNews-Classification-master/data/tokenize.py&quot;, line 2, in &lt;module&gt;</span><br><span class="line">    from pytorch_pretrained_bert import BertTokenizer</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/site-packages/pytorch_pretrained_bert/__init__.py&quot;, line 2, in &lt;module&gt;</span><br><span class="line">    from .tokenization import BertTokenizer, BasicTokenizer, WordpieceTokenizer</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/site-packages/pytorch_pretrained_bert/tokenization.py&quot;, line 20, in &lt;module&gt;</span><br><span class="line">    import logging</span><br><span class="line">  File &quot;/home/user/anaconda3/envs/bert/lib/python3.5/logging/__init__.py&quot;, line 212, in &lt;module&gt;</span><br><span class="line">    _lock = threading.RLock()</span><br><span class="line">AttributeError: module &#x27;threading&#x27; has no attribute &#x27;RLock&#x27;</span><br></pre></td></tr></table></figure><p>ä½†å¹¶ä¸æ˜¯<code>threading</code>åŒ…æœ‰é‡åé—®é¢˜ï¼Œè€Œæ˜¯åœ¨<code>import tokenize</code>è¿™æ­¥ä¸­ï¼Œæœ¬æ–‡ä»¶å¤¹ä¸‹æœ‰ä¸€ä¸ª<code>tokenize.py</code>æ–‡ä»¶ï¼Œå¯ä»¥çœ‹åˆ°å¼•å…¥çš„fileè·¯å¾„å’Œå…¶ä»–æ˜æ˜¾ä¸åŒã€‚</p><h1 id="é”™è¯¯ï¼šNo-module-named-xxx"><a href="#é”™è¯¯ï¼šNo-module-named-xxx" class="headerlink" title="é”™è¯¯ï¼šNo module named xxx"></a>é”™è¯¯ï¼šNo module named xxx</h1><p>å¼•å…¥è‡ªå·±å†™çš„ä»£ç ä¸­çš„æ–‡ä»¶æ—¶<code>from filename import xxx</code>ï¼Œå‡ºç°è¿™ä¸ªé”™è¯¯ï¼Œæ£€æŸ¥ä¸‹é¢ä¸¤ç‚¹ï¼š</p><p>1.åœ¨è¢«å¼•å…¥(import)çš„ç›®å½•ä¸‹éœ€è¦æœ‰ä¸€ä¸ª<code>__init__.py</code>æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶å¯ä»¥ä¸ºç©ºã€‚</p><p>2.åŒçº§ç›®å½•ä¸å¯ä»¥ç›´æ¥å¯¼å…¥ï¼Œéœ€è¦åŠ ä¸Šä¸Šä¸€çº§çš„æ–‡ä»¶åï¼Œä¾‹å¦‚ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from folder.filename import xxx</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;ç–¯ç‹‚å†™å¤§ä½œä¸šçš„ä¸€å‘¨ã€‚&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="weekly" scheme="http://example.com/categories/weekly/"/>
    
    
  </entry>
  
  <entry>
    <title>linux-tips</title>
    <link href="http://example.com/2021/11/28/linux-tips/"/>
    <id>http://example.com/2021/11/28/linux-tips/</id>
    <published>2021-11-28T05:29:06.000Z</published>
    <updated>2022-03-19T08:47:49.108Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>linuxæœåŠ¡å™¨ä¸‹çš„ä¸€äº›å¸¸ç”¨æ“ä½œã€‚</p></blockquote><span id="more"></span><h1 id="0-åœ¨çº¿æ‰‹å†Œ"><a href="#0-åœ¨çº¿æ‰‹å†Œ" class="headerlink" title="0 åœ¨çº¿æ‰‹å†Œ"></a>0 åœ¨çº¿æ‰‹å†Œ</h1><p>1.<a href="https://www.linuxcool.com/">Linuxå‘½ä»¤å¤§å…¨ï¼ˆæ‰‹å†Œï¼‰</a></p><p>2.<a href="https://www.cnblogs.com/jingmoxukong/p/7867397.html">ä¸€ç¯‡æ–‡ç« è®©ä½ å½»åº•æŒæ¡shellè¯­è¨€</a></p><p>3.<a href="https://www.runoob.com/linux/linux-command-manual.html">Linuxå‘½ä»¤å¤§å…¨ï¼ˆRUNOOB.COMï¼‰</a></p><h1 id="1-èµ„æºå ç”¨æƒ…å†µ"><a href="#1-èµ„æºå ç”¨æƒ…å†µ" class="headerlink" title="1 èµ„æºå ç”¨æƒ…å†µ"></a>1 èµ„æºå ç”¨æƒ…å†µ</h1><h2 id="1-1-GPUæ˜¾å¡å ç”¨"><a href="#1-1-GPUæ˜¾å¡å ç”¨" class="headerlink" title="1.1 GPUæ˜¾å¡å ç”¨"></a>1.1 GPUæ˜¾å¡å ç”¨</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><p>æ˜¾ç¤ºå¦‚ä¸‹ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Sun Nov 28 13:47:48 2021       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 430.64       Driver Version: 430.64       CUDA Version: 10.1     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  Tesla V100-PCIE...  Off  | 00000000:04:00.0 Off |                    0 |</span><br><span class="line">| N/A   60C    P0    73W / 250W |  16487MiB / 32510MiB |     39%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   1  Tesla V100-PCIE...  Off  | 00000000:06:00.0 Off |                    0 |</span><br><span class="line">| N/A   40C    P0    27W / 250W |      0MiB / 32510MiB |      0%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   2  Tesla V100S-PCI...  Off  | 00000000:0C:00.0 Off |                    0 |</span><br><span class="line">| N/A   75C    P0   166W / 250W |  17412MiB / 32510MiB |     27%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   3  Tesla V100S-PCI...  Off  | 00000000:0E:00.0 Off |                    0 |</span><br><span class="line">| N/A   72C    P0   140W / 250W |  15442MiB / 32510MiB |     28%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0     10685      C   ...g/anaconda3/envs/torch/bin/python 16475MiB |</span><br><span class="line">|    2     11578      C   ...g/anaconda3/envs/torch/bin/python 17401MiB |</span><br><span class="line">|    3     11579      C   ...g/anaconda3/envs/torch/bin/python 15431MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="1-2-æŸ¥çœ‹è¿›ç¨‹"><a href="#1-2-æŸ¥çœ‹è¿›ç¨‹" class="headerlink" title="1.2 æŸ¥çœ‹è¿›ç¨‹"></a>1.2 æŸ¥çœ‹è¿›ç¨‹</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top</span><br></pre></td></tr></table></figure><p>æ˜¾ç¤ºå¦‚ä¸‹ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND </span><br><span class="line">   10010      20  10  10.15g  3.63g   200200   4.0  1.5   0:30:31 top</span><br></pre></td></tr></table></figure><p>æŸ¥çœ‹æŸä¸€ç”¨æˆ·çš„æ‰€æœ‰è¿›ç¨‹ï¼ˆtopä¸‹ï¼‰ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">u username</span><br></pre></td></tr></table></figure><p>å±•å¼€å…·ä½“å‘½ä»¤ï¼ˆtopä¸‹ï¼‰ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c</span><br></pre></td></tr></table></figure><p>é€€å‡ºtopå‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ctrl+c</span><br></pre></td></tr></table></figure><p>æŸ¥çœ‹æŸä¸€è¿›ç¨‹çš„è¯¦ç»†ä¿¡æ¯ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep PID</span><br></pre></td></tr></table></figure><p>ç»“æŸè¿›ç¨‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill PID</span><br></pre></td></tr></table></figure><h1 id="2-æ–‡ä»¶è·¯å¾„"><a href="#2-æ–‡ä»¶è·¯å¾„" class="headerlink" title="2 æ–‡ä»¶è·¯å¾„"></a>2 æ–‡ä»¶è·¯å¾„</h1><p>1.å½“å‰è·¯å¾„ï¼š<code>$pwd</code></p><p>2.å½“å‰ç›®å½•ï¼š<code>.</code>ï¼Œä¸Šçº§ç›®å½•ï¼š<code>..</code></p><p>3.æ ¹ç›®å½•ï¼š<code>/</code></p><p>4.ç”¨æˆ·çš„homeè·¯å¾„ï¼š<code>~</code>ï¼Œ<code>~user</code>è¡¨ç¤ºç”¨æˆ·åä¸ºuserï¼ˆåœ¨/etc/passwdä¸­å­˜åœ¨çš„ç”¨æˆ·åï¼‰çš„homeè·¯å¾„</p><h1 id="3-ä»ç½‘é¡µä¸‹è½½æ•°æ®"><a href="#3-ä»ç½‘é¡µä¸‹è½½æ•°æ®" class="headerlink" title="3 ä»ç½‘é¡µä¸‹è½½æ•°æ®"></a>3 ä»ç½‘é¡µä¸‹è½½æ•°æ®</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget æ•°æ®é“¾æ¥</span><br></pre></td></tr></table></figure><h1 id="4-é˜²è¯¯åˆ ï¼ˆå›æ”¶ç«™ï¼‰"><a href="#4-é˜²è¯¯åˆ ï¼ˆå›æ”¶ç«™ï¼‰" class="headerlink" title="4 é˜²è¯¯åˆ ï¼ˆå›æ”¶ç«™ï¼‰"></a>4 é˜²è¯¯åˆ ï¼ˆå›æ”¶ç«™ï¼‰</h1><p>ç›®å½•ç»“æ„ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\.bashrc</span><br><span class="line">\00-trash</span><br><span class="line">-trash.sh</span><br><span class="line">-.trash</span><br><span class="line">-.bashrc</span><br></pre></td></tr></table></figure><h2 id="4-1-ç§»å…¥å›æ”¶ç«™"><a href="#4-1-ç§»å…¥å›æ”¶ç«™" class="headerlink" title="4.1 ç§»å…¥å›æ”¶ç«™"></a>4.1 ç§»å…¥å›æ”¶ç«™</h2><p>å°†<code>rm</code>å‘½ä»¤åˆ é™¤çš„æ–‡ä»¶ç§»å…¥<code>.trash</code>æ–‡ä»¶ä¸­ï¼Œå¹¶ç”¨æ—¶é—´å‘½åé˜²æ­¢é‡å¤ã€‚</p><p>ä½¿ç”¨æ—¶åœ¨<code>.bashrc</code>æ–‡ä»¶ä¸­åŠ å…¥ä»¥ä¸‹å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># trash for rm command</span><br><span class="line">alias rm&#x3D;&#x2F;user&#x2F;00-trash&#x2F;trash.sh</span><br></pre></td></tr></table></figure><p>æ‰§è¡Œ<code>source .bashrc</code>ä½¿å…¶ç”Ÿæ•ˆã€‚</p><p><code>trash.sh</code>å¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">#ä¸€ä¸ªç®€æ˜“å›æ”¶ç«™</span><br><span class="line">#https:&#x2F;&#x2F;github.com&#x2F;LIU-LIU-LIU&#x2F;Recycle_bin</span><br><span class="line"></span><br><span class="line">TarshDir&#x3D;&quot;&#96;echo ~&#96;&#x2F;00-trash&#x2F;.trash&quot;</span><br><span class="line">FileNamePrefix&#x3D;&#96;date +%y-%m-%d-%H-%M-%S&#96;</span><br><span class="line"></span><br><span class="line">error()&#123;</span><br><span class="line">echo -e &quot;\033[31m é”™è¯¯!\nç§»åŠ¨è‡³å›æ”¶ç«™ä¸éœ€è¦ä»»ä½•å‘½ä»¤é€‰é¡¹ã€‚æ ¼å¼:rm [æ–‡ä»¶]  \033[0m&quot;</span><br><span class="line">exit 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tarsh()&#123;</span><br><span class="line">case $1 in</span><br><span class="line">-*|.&#x2F;)</span><br><span class="line">        error</span><br><span class="line">;;</span><br><span class="line">&#x2F;)</span><br><span class="line">        echo -e &quot;\033[31m æ­¤æ“ä½œé£é™©å¤ªé«˜,å·²ç¦æ­¢! \033[0m&quot;</span><br><span class="line">        exit 1</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">        mkdir -p &quot;$TarshDir&quot;&#x2F;&quot;$FileNamePrefix&quot;</span><br><span class="line">        &#x2F;bin&#x2F;mv -i &quot;$@&quot; &quot;&quot;$TarshDir&quot;&#x2F;&quot;$FileNamePrefix&quot;&#x2F;&quot;</span><br><span class="line">        if [ &quot;$?&quot; &#x3D;&#x3D; &quot;0&quot; ] ; then</span><br><span class="line">                echo &quot;å·²å°†&quot;$@&quot;ç§»åŠ¨è‡³å›æ”¶ç«™(&quot;$TarshDir&quot;&#x2F;&quot;$FileNamePrefix&quot;&#x2F;)&quot;</span><br><span class="line">        else</span><br><span class="line">                echo -e &quot;\033[31m ç§»åŠ¨è‡³å›æ”¶ç«™å¤±è´¥ã€‚\033[0m&quot;</span><br><span class="line">                &#x2F;bin&#x2F;rm -rf &quot;$TarshDir&quot;&#x2F;&quot;$FileNamePrefix&quot;</span><br><span class="line">        fi</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if [ -z &quot;$1&quot; ];then</span><br><span class="line">        error</span><br><span class="line">else</span><br><span class="line">        tarsh $*</span><br><span class="line">fi</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="4-2-æ¸…ç©ºå›æ”¶ç«™"><a href="#4-2-æ¸…ç©ºå›æ”¶ç«™" class="headerlink" title="4.2 æ¸…ç©ºå›æ”¶ç«™"></a>4.2 æ¸…ç©ºå›æ”¶ç«™</h1><p>åœ¨<code>.trash</code>æ–‡ä»¶å¤¹ä¸­ï¼Œå†™ä¸€ä¸ª<code>.bashrc</code>æ–‡ä»¶</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alias rm&#x3D;&quot;rm&quot;</span><br></pre></td></tr></table></figure><p>æ‰§è¡Œ<code>source .bashrc</code>æ–‡ä»¶æ¢å¤åŸå§‹<code>rm</code>å‘½ä»¤åŠŸèƒ½ï¼Œæ¸…ç©ºå›æ”¶ç«™ã€‚</p><h1 id="5-è§£å‹æ–‡ä»¶"><a href="#5-è§£å‹æ–‡ä»¶" class="headerlink" title="5 è§£å‹æ–‡ä»¶"></a>5 è§£å‹æ–‡ä»¶</h1><h2 id="5-1-zipæ–‡ä»¶"><a href="#5-1-zipæ–‡ä»¶" class="headerlink" title="5.1 zipæ–‡ä»¶"></a>5.1 zipæ–‡ä»¶</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip filename</span><br></pre></td></tr></table></figure><h2 id="5-2-tar-gzæ–‡ä»¶"><a href="#5-2-tar-gzæ–‡ä»¶" class="headerlink" title="5.2 tar.gzæ–‡ä»¶"></a>5.2 tar.gzæ–‡ä»¶</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf filename</span><br></pre></td></tr></table></figure><h1 id="6-æ‰§è¡Œè¿›ç¨‹ç›¸å…³"><a href="#6-æ‰§è¡Œè¿›ç¨‹ç›¸å…³" class="headerlink" title="6 æ‰§è¡Œè¿›ç¨‹ç›¸å…³"></a>6 æ‰§è¡Œè¿›ç¨‹ç›¸å…³</h1><h2 id="6-1-æŒ‡å®šè¿›ç¨‹ä½¿ç”¨çš„GPU"><a href="#6-1-æŒ‡å®šè¿›ç¨‹ä½¿ç”¨çš„GPU" class="headerlink" title="6.1 æŒ‡å®šè¿›ç¨‹ä½¿ç”¨çš„GPU"></a>6.1 æŒ‡å®šè¿›ç¨‹ä½¿ç”¨çš„GPU</h2><p>åœ¨ç»ˆç«¯æ‰§è¡Œæ—¶æŒ‡å®šï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES&#x3D;0,1ï¼Œå½“è®¾ä¸º-1æ—¶ä»£è¡¨ä¸ä½¿ç”¨ä»»ä½•gpu</span><br></pre></td></tr></table></figure><p>åœ¨shè„šæœ¬æ–‡ä»¶ä¸­æŒ‡å®š:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#export CUDA_VISIBLE_DEVICES&#x3D;0,1</span><br></pre></td></tr></table></figure><p>åœ¨pythonç¨‹åºä¸­æŒ‡å®šï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import os; os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] &#x3D; &quot;0&quot;</span><br></pre></td></tr></table></figure><h2 id="6-2-åå°è¿è¡Œä¸æŒ‚æ–­"><a href="#6-2-åå°è¿è¡Œä¸æŒ‚æ–­" class="headerlink" title="6.2 åå°è¿è¡Œä¸æŒ‚æ–­"></a>6.2 åå°è¿è¡Œä¸æŒ‚æ–­</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup python -u train.py &gt; nohup.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>è¯¥å‘½ä»¤ä¼šå°†è¾“å‡ºé‡å®šå‘åˆ°nohup.logæ–‡ä»¶ä¸­ã€‚</p><h1 id="7-ç£ç›˜ç©ºé—´"><a href="#7-ç£ç›˜ç©ºé—´" class="headerlink" title="7 ç£ç›˜ç©ºé—´"></a>7 ç£ç›˜ç©ºé—´</h1><p>æŸ¥çœ‹æ•´ä¸ªæœåŠ¡å™¨çš„ç©ºé—´:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df -h</span><br></pre></td></tr></table></figure><p>æŸ¥çœ‹å½“å‰ç›®å½•ä¸‹æ¯ä¸€çº§ç›®å½•çš„ç©ºé—´ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">du -h --max-depth&#x3D;1</span><br></pre></td></tr></table></figure><h1 id="8-æ–‡æœ¬å†…å®¹æŠ½å–å’Œå¯¹æ¯”"><a href="#8-æ–‡æœ¬å†…å®¹æŠ½å–å’Œå¯¹æ¯”" class="headerlink" title="8 æ–‡æœ¬å†…å®¹æŠ½å–å’Œå¯¹æ¯”"></a>8 æ–‡æœ¬å†…å®¹æŠ½å–å’Œå¯¹æ¯”</h1><h1 id="8-1-æ–‡æœ¬æ¯”å¯¹"><a href="#8-1-æ–‡æœ¬æ¯”å¯¹" class="headerlink" title="8.1 æ–‡æœ¬æ¯”å¯¹"></a>8.1 æ–‡æœ¬æ¯”å¯¹</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vimdiff file1 file2</span><br></pre></td></tr></table></figure><h2 id="8-2-å†…å®¹æŠ½å–ï¼šcut"><a href="#8-2-å†…å®¹æŠ½å–ï¼šcut" class="headerlink" title="8.2 å†…å®¹æŠ½å–ï¼šcut"></a>8.2 å†…å®¹æŠ½å–ï¼šcut</h2><p>å¯¹æ¯è¡ŒæŠ½å–éœ€è¦çš„éƒ¨åˆ†ï¼Œå¸¸ç”¨å‚æ•°å¦‚ä¸‹ï¼š</p><ol><li><code>-d</code>ï¼šæŒ‡å®šåˆ†éš”ç¬¦ï¼Œé»˜è®¤ä¸ºâ€œTABâ€</li><li><code>-f</code>ï¼šæŠ½å–æŒ‡å®šéƒ¨åˆ†</li><li><code>N-</code>ï¼šä»ç¬¬Nä¸ªéƒ¨åˆ†åˆ°ç»“å°¾</li><li><code>N-M</code>ï¼šä»ç¬¬Nä¸ªéƒ¨åˆ†åˆ°ç¬¬Mä¸ªï¼ˆåŒ…æ‹¬Mï¼‰éƒ¨åˆ†</li><li><code>-M</code>ï¼šä»ç¬¬1ä¸ªéƒ¨åˆ†åˆ°ç¬¬Mä¸ªï¼ˆåŒ…æ‹¬Mï¼‰éƒ¨åˆ†</li></ol><p><strong>ä¸¾ä¾‹ï¼š</strong> åœ¨æ–‡ä»¶ldc_test.resultä¸­æŠ½å–å‡ºä»¥<code>-T</code>å¼€å¤´çš„å¥å­</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-S: å†³è®® è¦æ±‚ åŸƒå¡ä¿„æ¯”äºš ç«‹å³ é‡‡å– å…·ä½“ æ­¥éª¤ , ä½¿ å„ åŸƒ è¾¹ç•Œ å§”å‘˜ä¼š èƒ½ åœ¨ æ²¡æœ‰ å…ˆå†³æ¡ä»¶ çš„ æƒ…å†µ ä¸‹ è¿…é€Ÿ æ ‡@@ å®š è¾¹ç•Œ ; è¦æ±‚ å„ç«‹ç‰¹é‡Œäºš ä¸å† æ‹–å»¶ , ä¸ è®¾ å…ˆå†³æ¡ä»¶ åœ° å–æ¶ˆ å¯¹ åŸƒ@@ å„ ç‰¹æ´¾ å›¢ çš„ è¡ŒåŠ¨ å’Œ ä½œä¸š çš„ æ‰€æœ‰ é™åˆ¶ .</span><br><span class="line">-T: The resolution requires Ethiopia to immediately take concrete steps to allow the Erit@@ rea - Ethiopia Boundary Commission to speedily demarc@@ ate the border without any preconditions ; and requires Erit@@ rea to cancel all of its restrictions on UN@@ ME@@ E &#39;s actions and operations without any further delay and without setting any preconditions .</span><br><span class="line">-P: The resolution asked Ethiopia to take specific steps immediately to enable the Erit@@ rean border committee to rapidly set its boundary without a precondition ; Erit@@ rea would no longer delay or set a precedent for the removal of all restrictions on the actions and operations of the Erit@@ rean special missions .</span><br><span class="line"></span><br><span class="line">-S: æœ‰å…³ éƒ¨é—¨ åº” å¼ºåŒ– ä½ ä¿@@ æˆ· åœ¨ äº«å— ä½ ä¿ æ—¶ é¡» å±¥è¡Œ çš„ ä¹‰åŠ¡ : å¦‚ åŠæ—¶ é€šæŠ¥ å®¶åº­ äººå‘˜ åŠ æ”¶å…¥ å˜åŒ– æƒ…å†µ , æ±‡æŠ¥ å°±ä¸š æƒ…å†µ , æ¥å— å®šæœŸ å¤@@ å®¡ ç­‰ , è€Œ æœ‰å…³ éƒ¨é—¨ åˆ™ åº” åŠ å¤§ ç›‘ç£ æ£€æŸ¥ çš„ åŠ›åº¦ .</span><br><span class="line">-T: The relevant department should stress the obligations that welfare recipients must carry out while enjoying the welfare : for example , promptly notifying the changes in the family members and incomes , reporting the status of employment , accepting regular reviews , etc. On the other hand , the relevant department should step up monitoring and inspection .</span><br><span class="line">-P: The relevant departments should strengthen the obligation of low - bonded households to carry out such tasks as helping low - income families to enjoy low - income insured : if timely reporting of changes in the income and changes in the income and reporting on employment , and receiving regular reviews , the relevant departments should intensify supervision and inspection .</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨å‘½ä»¤ï¼š<code>grep ^-T ldc_test.result | cut -f2- -d&quot; &quot; &gt; new.result</code>ã€‚å…¶ä¸­ï¼Œ<code>-d&quot; &quot;</code>å°†ç©ºæ ¼è®¾ä¸ºåˆ†éš”ç¬¦ï¼Œ<code>-f2-</code>åœ¨ç”¨ç©ºæ ¼åˆ†å¼€åçš„éƒ¨åˆ†ä¸­ï¼Œä»ç¬¬äºŒä¸ªéƒ¨åˆ†èµ·ï¼ŒæŠ½å–åé¢æ‰€æœ‰éƒ¨åˆ†ã€‚æ•ˆæœå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">The resolution requires Ethiopia to immediately take concrete steps to allow the Erit@@ rea - Ethiopia Boundary Commission to speedily demarc@@ ate the border without any preconditions ; and requires Erit@@ rea to cancel all of its restrictions on UN@@ ME@@ E &#39;s actions and operations without any further delay and without setting any preconditions .</span><br><span class="line">The relevant department should stress the obligations that welfare recipients must carry out while </span><br></pre></td></tr></table></figure><h1 id="9-ç»Ÿè®¡ç›®å½•ä¸‹çš„æ–‡ä»¶æ•°é‡"><a href="#9-ç»Ÿè®¡ç›®å½•ä¸‹çš„æ–‡ä»¶æ•°é‡" class="headerlink" title="9 ç»Ÿè®¡ç›®å½•ä¸‹çš„æ–‡ä»¶æ•°é‡"></a>9 ç»Ÿè®¡ç›®å½•ä¸‹çš„æ–‡ä»¶æ•°é‡</h1><p>1.ç»Ÿè®¡å½“å‰ç›®å½•ä¸‹çš„ä¸€èˆ¬æ–‡ä»¶çš„æ•°é‡ï¼ˆä¸åŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼Œä¹Ÿä¸åŒ…æ‹¬å­æ–‡ä»¶å¤¹å†…çš„æ–‡ä»¶ï¼‰</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -l |grep &quot;^-&quot;|wc -l</span><br></pre></td></tr></table></figure><p>2.ç»Ÿè®¡å½“å‰ç›®å½•ä¸‹çš„å­æ–‡ä»¶å¤¹æ•°é‡ï¼ˆä¸åŒ…æ‹¬ä¸€èˆ¬æ–‡ä»¶ï¼Œä¹Ÿä¸åŒ…æ‹¬å­æ–‡ä»¶å¤¹å†…çš„æ–‡ä»¶ï¼‰</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -l |grep &quot;^ï½„&quot;|wc -l</span><br></pre></td></tr></table></figure><p>3.ç»Ÿè®¡å½“å‰ç›®å½•ä¸‹çš„ä¸€èˆ¬æ–‡ä»¶æ•°é‡ï¼ˆåŒ…æ‹¬å­æ–‡ä»¶å¤¹å†…çš„ä¸€èˆ¬æ–‡ä»¶ï¼Œä½†ä¸åŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼Œä¹Ÿä¸åŒ…æ‹¬å­æ–‡ä»¶å¤¹å†…çš„å­æ–‡ä»¶å¤¹ï¼‰</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lR|grep &quot;^-&quot;|wc -l </span><br></pre></td></tr></table></figure><p>è§£é‡Šï¼š</p><p><code>ls-l</code>å‘½ä»¤è¾“å‡ºå½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶ä¿¡æ¯ï¼ˆåŒ…å«ç›®å½•ã€é“¾æ¥ã€è®¾å¤‡æ–‡ä»¶ç­‰ï¼‰ï¼Œæ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªæ–‡ä»¶ã€‚</p><p><code>ls -lR</code>å‘½ä»¤è¾“å‡ºå½“å‰ç›®å½•ä¸‹çš„åŒ…æ‹¬å­ç›®å½•çš„æ–‡ä»¶ä¿¡æ¯ã€‚</p><p><code>grep &quot;^-&quot;</code>è¿‡æ»¤<code>ls</code>çš„è¾“å‡ºä¿¡æ¯ï¼Œåªä¿ç•™ä¸€èˆ¬æ–‡ä»¶ã€‚</p><p><code>grep &quot;^d&quot;</code>è¿‡æ»¤<code>ls</code>çš„è¾“å‡ºä¿¡æ¯ï¼Œåªä¿ç•™å­æ–‡ä»¶å¤¹ã€‚</p><p><code>wc -l</code>å‘½ä»¤ç»Ÿè®¡è¾“å‡ºä¿¡æ¯çš„è¡Œæ•°ã€‚</p><h1 id="10-æŸ¥çœ‹ç³»ç»Ÿæ„æ¶"><a href="#10-æŸ¥çœ‹ç³»ç»Ÿæ„æ¶" class="headerlink" title="10 æŸ¥çœ‹ç³»ç»Ÿæ„æ¶"></a>10 æŸ¥çœ‹ç³»ç»Ÿæ„æ¶</h1><p>æ–¹æ³•1ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$</span><span class="bash"> uname -a</span></span><br><span class="line">Linux alt 5.4.0-104-generic #118-Ubuntu SMP Wed Mar 2 19:02:41 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure><p>æ–¹æ³•2ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">~$</span><span class="bash"> arch</span></span><br><span class="line">x86_64</span><br></pre></td></tr></table></figure><blockquote><p>å‚è€ƒï¼š</p><p><a href="https://hannlp.github.io/2021-01-15-Linux-&amp;-Shell-Usage-Record/">https://hannlp.github.io/2021-01-15-Linux-&amp;-Shell-Usage-Record/</a></p><p><a href="https://github.com/LIU-LIU-LIU/Recycle_bin">https://github.com/LIU-LIU-LIU/Recycle_bin</a></p><p><a href="https://www.cnblogs.com/dylancao/p/9012790.html">https://www.cnblogs.com/dylancao/p/9012790.html</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;linuxæœåŠ¡å™¨ä¸‹çš„ä¸€äº›å¸¸ç”¨æ“ä½œã€‚&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="other" scheme="http://example.com/categories/other/"/>
    
    <category term="linux" scheme="http://example.com/categories/other/linux/"/>
    
    
  </entry>
  
  <entry>
    <title>chinese_text_classify</title>
    <link href="http://example.com/2021/11/28/chinese-text-classify/"/>
    <id>http://example.com/2021/11/28/chinese-text-classify/</id>
    <published>2021-11-28T05:16:23.000Z</published>
    <updated>2021-12-03T15:30:34.915Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ä¸­æ–‡æ–‡æœ¬åˆ†ç±»æµç¨‹</p></blockquote><span id="more"></span><h1 id="1-ç›¸å…³å·¥å…·åŠç›®å½•ç»“æ„"><a href="#1-ç›¸å…³å·¥å…·åŠç›®å½•ç»“æ„" class="headerlink" title="1 ç›¸å…³å·¥å…·åŠç›®å½•ç»“æ„"></a>1 ç›¸å…³å·¥å…·åŠç›®å½•ç»“æ„</h1><h2 id="1-1-ç›¸å…³å·¥å…·"><a href="#1-1-ç›¸å…³å·¥å…·" class="headerlink" title="1.1 ç›¸å…³å·¥å…·"></a>1.1 ç›¸å…³å·¥å…·</h2><p>é™¤<strong>jieba</strong>æ˜¯ä½¿ç”¨<code>pip install</code>å®‰è£…å¤–ï¼Œå…¶ä»–å‡ ä¸ªå·¥å…·éƒ½æ˜¯å»ºè®®ç›´æ¥å…‹éš†åº“åˆ°è‡ªå·±çš„ç”¨æˆ·ç›®å½•ä¸­ï¼Œæ–¹ä¾¿ä½¿ç”¨å…¶è„šæœ¬(<strong>moses</strong>/<strong>subword-nmt</strong>)ï¼Œæˆ–æœªæ¥å¯èƒ½è¦è‡ªå·±æ‹“å±•å…¶ä¸­çš„æ¨¡å‹(<strong>fairseq</strong>)</p><ol><li><p>jieba (ä¸­æ–‡åˆ†è¯ç»„ä»¶)ï¼Œå®‰è£…æŒ‡ä»¤å¦‚ä¸‹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install jieba</span><br></pre></td></tr></table></figure></li></ol><h2 id="1-2-ç›®å½•ç»“æ„ä¸åˆå§‹åŒ–"><a href="#1-2-ç›®å½•ç»“æ„ä¸åˆå§‹åŒ–" class="headerlink" title="1.2 ç›®å½•ç»“æ„ä¸åˆå§‹åŒ–"></a>1.2 ç›®å½•ç»“æ„ä¸åˆå§‹åŒ–</h2><h3 id="1-2-1-ç›®å½•ç»“æ„"><a href="#1-2-1-ç›®å½•ç»“æ„" class="headerlink" title="1.2.1 ç›®å½•ç»“æ„"></a>1.2.1 ç›®å½•ç»“æ„</h3><p>æå‰ç»„ç»‡ä¸€ä¸ªç›®å½•ç»“æ„çš„å¥½å¤„æ˜¯å¯ä»¥è®©åé¢çš„ä¸€ç³»åˆ—æ“ä½œæ›´åŠ ç»Ÿä¸€ã€è§„èŒƒåŒ–ã€‚ä¸‹è¡¨ä¸­<code>~</code>ä»£è¡¨linuxç³»ç»Ÿä¸­<strong>æˆ‘çš„ç”¨æˆ·ç›®å½•</strong>, THUCNewsç›®å½•åä»£è¡¨æ­¤æ¬¡æˆ‘ä½¿ç”¨çš„æ•°æ®é›†åç§°</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">~</span><br><span class="line">â”œâ”€â”€ mosesdecoder</span><br><span class="line">â””â”€â”€ text-classify</span><br><span class="line">    â”œâ”€â”€ master</span><br><span class="line">    â”œâ”€â”€ THUCNews</span><br><span class="line">    â”œâ”€â”€ split_data.py   # ç”¨äºåˆ’åˆ†train,valid,test</span><br><span class="line">        â”œâ”€â”€ data            # ç”¨äºå­˜æ”¾æ•°æ®</span><br><span class="line">            â”œâ”€â”€ train.txt          </span><br><span class="line">            â”œâ”€â”€ train_long.txt</span><br><span class="line">            â”œâ”€â”€ dev.txt  </span><br><span class="line">            â”œâ”€â”€ dev_long.txt </span><br><span class="line">            â”œâ”€â”€ test.txt </span><br><span class="line">            â”œâ”€â”€ test_long.txt </span><br><span class="line">            â”œâ”€â”€ class.txt  </span><br><span class="line">            â”œâ”€â”€ embedding_SougouNews.npz  </span><br><span class="line">            â”œâ”€â”€ embedding_Tencent.npz  </span><br><span class="line">            â””â”€â”€ vocab.pkl</span><br><span class="line">            â””â”€â”€ saved_dict      # ç”¨äºå­˜æ”¾ç¿»è¯‘ç»“æœ</span><br><span class="line">    â”œâ”€â”€ models                  </span><br><span class="line">        â”œâ”€â”€ Bert.py  </span><br><span class="line">        â”œâ”€â”€ TextCNN.py  </span><br><span class="line">        â”œâ”€â”€ TextRNN_Att.py  </span><br><span class="line">        â””â”€â”€ Transformer.py</span><br><span class="line">    â”œâ”€â”€ pytorch_pretrained_bert</span><br><span class="line">    â”œâ”€â”€ scripts                 # ä¸€äº›è„šæœ¬</span><br><span class="line">    â”œâ”€â”€ train_bert.sh  </span><br><span class="line">    â”œâ”€â”€ train_bilstm_att.sh  </span><br><span class="line">    â”œâ”€â”€ train_cnn.sh  </span><br><span class="line">    â””â”€â”€ train_transformer.sh</span><br><span class="line">    â”œâ”€â”€ utils.py                # ä¸€äº›å…¶ä»–å·¥å…·</span><br><span class="line">    â”œâ”€â”€ utils_bert.py           </span><br><span class="line">    â”œâ”€â”€ run.py# æ¨¡å‹è¿è¡Œ</span><br><span class="line">    â”œâ”€â”€ run_bert.py</span><br><span class="line">    â”œâ”€â”€ train_eval.py</span><br><span class="line">    â””â”€â”€ train_eval_bert.py</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="2-æ•°æ®çš„å‡†å¤‡"><a href="#2-æ•°æ®çš„å‡†å¤‡" class="headerlink" title="2 æ•°æ®çš„å‡†å¤‡"></a>2 æ•°æ®çš„å‡†å¤‡</h1><h2 id="2-1-THUCNews"><a href="#2-1-THUCNews" class="headerlink" title="2.1 THUCNews"></a>2.1 THUCNews</h2><p>æœ¬æ–‡é‡‡ç”¨ <a href="http://thuctc.thunlp.org/">THUCNewsä¸­æ–‡æ–‡æœ¬å¼€æºè¯­æ–™</a> ï¼ŒTHUCNewsæ˜¯æ ¹æ®æ–°æµªæ–°é—»RSSè®¢é˜…é¢‘é“2005~2011å¹´é—´çš„å†å²æ•°æ®ç­›é€‰è¿‡æ»¤ç”Ÿæˆï¼ŒåŒ…å«74ä¸‡ç¯‡æ–°é—»æ–‡æ¡£ï¼ˆ2.19 GBï¼‰ï¼Œå‡ä¸ºUTF-8çº¯æ–‡æœ¬æ ¼å¼ã€‚å…±åˆ†ä¸º14ä¸ªå€™é€‰åˆ†ç±»ç±»åˆ«ï¼šè´¢ç»ã€å½©ç¥¨ã€æˆ¿äº§ã€è‚¡ç¥¨ã€å®¶å±…ã€æ•™è‚²ã€ç§‘æŠ€ã€ç¤¾ä¼šã€æ—¶å°šã€æ—¶æ”¿ã€ä½“è‚²ã€æ˜Ÿåº§ã€æ¸¸æˆã€å¨±ä¹ã€‚</p><p><strong>åŸå§‹æ•°æ®ç»Ÿè®¡ï¼š</strong></p><p>æ€»æ•°é‡ï¼š836075æ¡ï¼ˆç§‘æŠ€ï¼š162929ï¼›è‚¡ç¥¨ï¼š154398ï¼›ä½“è‚²ï¼š131604ï¼›å¨±ä¹ï¼š92632ï¼›æ—¶æ”¿ï¼š63086ï¼›ç¤¾ä¼šï¼š50849ï¼›æ•™è‚²ï¼š41936ï¼›è´¢ç»ï¼š37098ï¼›å®¶å±…ï¼š32586ï¼›æ¸¸æˆï¼š24373ï¼›æˆ¿äº§ï¼š20050ï¼›æ—¶å°šï¼š13368ï¼›å½©ç¥¨ï¼š7588ï¼›æ˜Ÿåº§ï¼š3578ï¼‰</p><h2 id="2-2-æ•°æ®é¢„å¤„ç†"><a href="#2-2-æ•°æ®é¢„å¤„ç†" class="headerlink" title="2.2 æ•°æ®é¢„å¤„ç†"></a>2.2 æ•°æ®é¢„å¤„ç†</h2><h3 id="2-2-1-åŸå§‹æ•°æ®æ ¼å¼"><a href="#2-2-1-åŸå§‹æ•°æ®æ ¼å¼" class="headerlink" title="2.2.1 åŸå§‹æ•°æ®æ ¼å¼"></a>2.2.1 åŸå§‹æ•°æ®æ ¼å¼</h3><p>åˆ†ç±»æ”¾ç½®ï¼Œæ¯ä¸ªæ–‡æ¡£åŒ…å«ä¸€ç¯‡æ–°é—»æ–‡æœ¬</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">â””â”€â”€ THUCNews</span><br><span class="line">        â””â”€â”€ ä½“è‚²     </span><br><span class="line">            â””â”€â”€ 29016.txt</span><br><span class="line">        â””â”€â”€ è´¢ç»     </span><br><span class="line">            â””â”€â”€ 11016.txt</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>æ–‡æ¡£æ ¼å¼å¦‚ä¸‹ï¼šç”±æ ‡é¢˜å’Œæ­£æ–‡ä¸¤éƒ¨åˆ†ç»„æˆ</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ç»„å›¾ï¼š9æœˆå…¨çƒæŠ˜æ‰£æ˜æ˜Ÿå¸¦ä½ å»è¡€æ‹¼</span><br><span class="line">ã€€ã€€å¯¼è¯»ï¼šæ¯å¹´çš„8ï¼Œ9ä¸¤æœˆï¼Œéƒ½æ˜¯æ™®å¤©ä¸‹è¡€æ‹¼ç‹‚äººå¤§å¼€æ€æˆ’çš„æ—¥å­ã€‚å› ä¸ºå…¨çƒæ€§çš„æŠ˜æ‰£å­£èŠ‚å·²æ­£å¼å¯åŠ¨ã€‚ä»¥æŠ˜æ‰£ç‡æœ€ç–¯ç‹‚çš„ç¾å›½æ¥è¯´ï¼Œæ— è®ºä¸€çº¿å¤§ç‰Œè¿˜æ˜¯æ—¶å°šæ½®ç‰©ï¼Œç»Ÿç»Ÿä¸º5 æŠ˜ä¸ºèµ·ç‚¹ï¼Œä¸€è·¯ç‹‚é£™åˆ°2æŠ˜å·¦å³ã€‚å»å¹´8æœˆï¼ŒSamiå°±æ›¾ä»¥0.5æŠ˜çš„å¤¸å¼ æ‰£ç‡æŠ¢åˆ°ä¸€æ¡MiuMiuè¿è¡£è£™ã€‚æ­¤ç•ªSamiç‰¹åˆ«è¯·åˆ°20ä½ç¾å›½æœ¬åœŸå¥³æ˜Ÿï¼Œå¥¹ä»¬è®©ç°èº«è¯´æ³•ï¼Œå¸¦ä½ æéæŠ˜æ‰£å­£èŠ‚æœ€å€¼å¾—å…¥è´§çš„é«˜æ€§ä»·æ¯”è¶…å€¼å•å“ã€‚</span><br><span class="line">ã€€ã€€Heidi Montagæ¨èè¶…å€¼æŠ˜æ‰£å•å“ï¼šGUCCIå‡‰é‹</span><br><span class="line">ã€€ã€€Ashley Tisdaleæ¨èè¶…å€¼æŠ˜æ‰£å•å“ï¼šç ´æ´ç‰›ä»”å°è„šè£¤</span><br></pre></td></tr></table></figure><h3 id="2-2-2-æ•°æ®é›†ç”Ÿæˆ"><a href="#2-2-2-æ•°æ®é›†ç”Ÿæˆ" class="headerlink" title="2.2.2 æ•°æ®é›†ç”Ÿæˆ"></a>2.2.2 æ•°æ®é›†ç”Ÿæˆ</h3><p>ä»ä¸­æŠ½å–10ä¸ªç±»åˆ«ï¼ˆè´¢ç»ã€æˆ¿äº§ã€è‚¡ç¥¨ã€æ•™è‚²ã€ç§‘æŠ€ã€ç¤¾ä¼šã€æ—¶æ”¿ã€ä½“è‚²ã€æ¸¸æˆã€å¨±ä¹ï¼‰éšæœºæŠ½å–å…±20ä¸‡æ¡æ•°æ®ï¼Œå…¶ä¸­è®­ç»ƒé›†18ä¸‡æ•°æ®ï¼ŒéªŒè¯é›†1ä¸‡æ•°æ®ï¼Œæµ‹è¯•é›†1ä¸‡æ•°æ®ã€‚</p><p>é¦–å…ˆï¼Œä»åŸå§‹æ•°æ®é›†ä¸­é€‰æ‹©10ä¸ªç±»åˆ«æŠ½å–éƒ¨åˆ†æ•°æ®ï¼Œæ¯ä¸ªç±»åˆ«éšæœºæŠ½å–18000æ¡æ•°æ®ä½œä¸ºè®­ç»ƒé›†ï¼Œ1000æ¡æ•°æ®ä½œä¸ºéªŒè¯é›†ï¼Œ1000æ¡æ•°æ®ä½œä¸ºæµ‹è¯•é›†ï¼Œä½¿ç”¨split_data.pyåˆ’åˆ†ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python split_data.py</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨shuffle.pyæ‰“ä¹±é¡ºåºï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python shuffle.py</span><br></pre></td></tr></table></figure><p>çŸ­æ–‡æœ¬ï¼ˆæ ‡é¢˜ï¼‰æ•ˆæœå¦‚ä¸‹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ä¸­å›½äººå¯¿æ‰¿è¯ºä¸è£å‘˜ä¸å‡è–ª        0</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>é•¿æ–‡æœ¬ï¼ˆæ ‡é¢˜+æ­£æ–‡ï¼‰æ•ˆæœå¦‚ä¸‹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">å››æ–°è‚¡å†»ç»“èµ„é‡‘4112äº¿å…ƒ ç‹äºšä¼Ÿé’çä¹å®‰åŒ»ç–—\ã€€ã€€âŠ™è§ä¹ è®°è€…æ–¹ä¿Šâ—‹ç¼–è¾‘æœ±ç»å‹‡ã€€ã€€æ®ä»Šæ—¥å…¬å‘ŠæŠ«éœ²ï¼Œæœ¬å‘¨ä¸€å‘è¡Œçš„ä¸­å°æ¿æ–°è‚¡å…†é©°è‚¡ä»½ã€æ­æ°§è‚¡ä»½ã€ä¹å®‰åŒ»ç–—ã€æ£•æ¦ˆå›­æ—åˆè®¡å†»ç»“èµ„é‡‘4112.5äº¿å…ƒï¼Œè€Œæ•´ä½“æ¥çœ‹æ‰“æ–°èµ„é‡‘å¯¹ä¸ªè‚¡çš„é€‰æ‹©å‡ºç°äº†ä¸¥é‡åˆ†åŒ–ï¼Œå…¶ä¸­å…†é©°è‚¡ä»½å’Œä¹å®‰åŒ»ç–—çš„ä¸­ç­¾ç‡åˆ†åˆ«ä¸º2.445%å’Œ0.487%ï¼Œç›¸å·®è¿‘5å€ã€‚ã€€ã€€å…¬å‘Šæ˜¾ç¤ºï¼Œå…†é©°è‚¡ä»½ç½‘ä¸Šå®šä»·å‘è¡Œä¸­ç­¾ç‡ä¸º2.445%ï¼Œä»…æ¬¡äºæ­¤å‰ç§‘ä¼¦è¯ä¸š3.1%ä¸­ç­¾ç‡ï¼Œè¶…é¢è®¤è´­å€æ•°ä¸º41å€ï¼Œå†»ç»“èµ„é‡‘549.68äº¿å…ƒï¼Œç½‘ä¸‹æœ‰æ•ˆç”³è´­èµ„é‡‘ä¸º53.37äº¿å…ƒã€‚æ­æ°§è‚¡ä»½ç½‘ä¸Šä¸­ç­¾ç‡ä¸º1.1%ï¼Œè¶…é¢è®¤è´­å€æ•°ä¸º90å€ï¼Œå†»ç»“èµ„é‡‘924.58äº¿å…ƒï¼Œç½‘ä¸‹æœ‰æ•ˆç”³è´­èµ„é‡‘ä¸º80.65äº¿å…ƒã€‚æ£•æ¦ˆå›­æ—ç½‘ä¸Šä¸­ç­¾ç‡ä¸º0.88%ï¼Œè¶…é¢è®¤è´­å€æ•°ä¸º113å€ï¼Œå†»ç»“èµ„é‡‘1219.26äº¿å…ƒï¼Œç½‘ä¸‹æœ‰æ•ˆç”³è´­èµ„é‡‘ä¸º196.47äº¿å…ƒã€‚ã€€ã€€ä¹å®‰åŒ»ç–—ç½‘ä¸Šä¸­ç­¾ç‡ä¸º0.487%ï¼Œè¶…é¢è®¤è´­å€æ•°ä¸º205å€ï¼Œå†»ç»“èµ„é‡‘986.79äº¿å…ƒï¼Œç½‘ä¸‹æœ‰æ•ˆç”³è´­èµ„é‡‘ä¸º101.7äº¿å…ƒã€‚è€Œç½‘ä¸‹é…å”®ç»“æœæ˜¾ç¤ºï¼Œä¹å®‰åŒ»ç–—ä¹Ÿå—åˆ°äº†127å®¶é…å”®å¯¹è±¡çš„é’çï¼Œå…¶ä¸­åŒ…æ‹¬ç‹äºšä¼Ÿæ‰§æŒçš„åå¤å¤§ç›˜å’Œåå¤ç­–ç•¥ã€‚0</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>æœ€åï¼ŒTHUCNews/dataç›®å½•ä¸­æœ‰å¦‚ä¸‹æ•°æ®ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">â”œâ”€â”€ THUCNews</span><br><span class="line">    â””â”€â”€ data</span><br><span class="line">        â”œâ”€â”€ train.txt</span><br><span class="line">        â”œâ”€â”€ train_long.txt</span><br><span class="line">        â”œâ”€â”€ dev.txt</span><br><span class="line">        â”œâ”€â”€ dev_long.txt</span><br><span class="line">        â”œâ”€â”€ test.txt</span><br><span class="line">        â””â”€â”€ test_long.txt</span><br></pre></td></tr></table></figure><h1 id="3-è®­ç»ƒè¿‡ç¨‹"><a href="#3-è®­ç»ƒè¿‡ç¨‹" class="headerlink" title="3 è®­ç»ƒè¿‡ç¨‹"></a>3 è®­ç»ƒè¿‡ç¨‹</h1><h2 id="3-1-bertæ¨¡å‹"><a href="#3-1-bertæ¨¡å‹" class="headerlink" title="3.1 bertæ¨¡å‹"></a>3.1 bertæ¨¡å‹</h2><p>1.è¿è¡Œè„šæœ¬</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_VISIBLE_DEVICES=0,1 </span><br><span class="line">nohup python run_bert.py --model bert &gt; nohup.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>2.è¿è¡Œlog</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">Loading data...</span><br><span class="line">180000it [00:35, 5049.92it&#x2F;s]</span><br><span class="line">10000it [00:02, 4529.50it&#x2F;s]</span><br><span class="line">10000it [00:02, 3977.26it&#x2F;s]</span><br><span class="line">Time usage: 0:00:40</span><br><span class="line">model to cpu</span><br><span class="line">model to train</span><br><span class="line">no error -1</span><br><span class="line">no error 0</span><br><span class="line">no error 1</span><br><span class="line">no error 2</span><br><span class="line">Epoch [1&#x2F;3]</span><br><span class="line">&#x2F;data&#x2F;yyfxu&#x2F;text-classify&#x2F;tmp&#x2F;pytorch_pretrained_bert&#x2F;optimization.py:275: UserWarning: This overload of add_ is deprecated:</span><br><span class="line">add_(Number alpha, Tensor other)</span><br><span class="line">Consider using one of the following signatures instead:</span><br><span class="line">add_(Tensor other, *, Number alpha) (Triggered internally at  &#x2F;opt&#x2F;conda&#x2F;conda-bld&#x2F;pytorch_1595629403081&#x2F;work&#x2F;torch&#x2F;csrc&#x2F;utils&#x2F;python_arg_parser.cpp:766.)</span><br><span class="line">  next_m.mul_(beta1).add_(1 - beta1, grad)</span><br><span class="line">Iter:      0,  Train Loss:   2.5,  Train Acc:  6.25%,  Val Loss:   2.3,  Val Acc: 10.13%,  Time: 0:00:24 *</span><br><span class="line">Iter:    100,  Train Loss:  0.88,  Train Acc: 75.00%,  Val Loss:  0.73,  Val Acc: 81.03%,  Time: 0:01:24 *</span><br><span class="line">Iter:    200,  Train Loss:  0.44,  Train Acc: 81.25%,  Val Loss:  0.41,  Val Acc: 87.58%,  Time: 0:02:18 *</span><br><span class="line">Iter:    300,  Train Loss:   0.7,  Train Acc: 81.25%,  Val Loss:   0.4,  Val Acc: 88.25%,  Time: 0:03:13 *</span><br><span class="line">Iter:    400,  Train Loss:   1.0,  Train Acc: 81.25%,  Val Loss:  0.38,  Val Acc: 88.62%,  Time: 0:04:07 *</span><br><span class="line">Iter:    500,  Train Loss:  0.69,  Train Acc: 75.00%,  Val Loss:  0.39,  Val Acc: 88.75%,  Time: 0:05:02 </span><br><span class="line">Iter:    600,  Train Loss:  0.31,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 89.58%,  Time: 0:05:57 *</span><br><span class="line">Iter:    700,  Train Loss:  0.29,  Train Acc: 93.75%,  Val Loss:  0.37,  Val Acc: 89.25%,  Time: 0:06:52 </span><br><span class="line">Iter:    800,  Train Loss:  0.35,  Train Acc: 93.75%,  Val Loss:  0.41,  Val Acc: 88.22%,  Time: 0:07:46 </span><br><span class="line">Iter:    900,  Train Loss: 0.036,  Train Acc: 100.00%,  Val Loss:  0.35,  Val Acc: 89.76%,  Time: 0:08:42 *</span><br><span class="line">Iter:   1000,  Train Loss:  0.57,  Train Acc: 87.50%,  Val Loss:  0.42,  Val Acc: 89.01%,  Time: 0:09:38 </span><br><span class="line">Iter:   1100,  Train Loss: 0.017,  Train Acc: 100.00%,  Val Loss:   0.4,  Val Acc: 88.69%,  Time: 0:10:32 </span><br><span class="line">Iter:   1200,  Train Loss:  0.97,  Train Acc: 81.25%,  Val Loss:   0.4,  Val Acc: 88.91%,  Time: 0:11:27 </span><br><span class="line">Iter:   1300,  Train Loss:  0.69,  Train Acc: 75.00%,  Val Loss:  0.38,  Val Acc: 88.72%,  Time: 0:12:19 </span><br><span class="line">Iter:   1400,  Train Loss:  0.69,  Train Acc: 81.25%,  Val Loss:  0.44,  Val Acc: 87.96%,  Time: 0:13:11 </span><br><span class="line">Iter:   1500,  Train Loss:  0.52,  Train Acc: 87.50%,  Val Loss:  0.37,  Val Acc: 88.91%,  Time: 0:14:05 </span><br><span class="line">Iter:   1600,  Train Loss:   0.4,  Train Acc: 87.50%,  Val Loss:  0.52,  Val Acc: 86.66%,  Time: 0:14:57 </span><br><span class="line">Iter:   1700,  Train Loss:  0.12,  Train Acc: 93.75%,  Val Loss:  0.41,  Val Acc: 89.22%,  Time: 0:15:52 </span><br><span class="line">Iter:   1800,  Train Loss: 0.054,  Train Acc: 100.00%,  Val Loss:  0.37,  Val Acc: 88.87%,  Time: 0:16:44 </span><br><span class="line">Iter:   1900,  Train Loss:  0.12,  Train Acc: 100.00%,  Val Loss:  0.38,  Val Acc: 88.96%,  Time: 0:17:38 </span><br><span class="line">No optimization for a long time, auto-stopping...</span><br><span class="line">Test Loss:  0.34,  Test Acc: 90.05%</span><br><span class="line">Precision, Recall and F1-Score...</span><br><span class="line">               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">      finance     0.8957    0.8670    0.8811      1000</span><br><span class="line">       realty     0.9262    0.9290    0.9276      1000</span><br><span class="line">       stocks     0.8510    0.8170    0.8337      1000</span><br><span class="line">    education     0.9732    0.9430    0.9578      1000</span><br><span class="line">      science     0.7790    0.9130    0.8407      1000</span><br><span class="line">      society     0.9564    0.8550    0.9029      1000</span><br><span class="line">     politics     0.8578    0.9290    0.8920      1000</span><br><span class="line">       sports     0.9092    0.9710    0.9391      1000</span><br><span class="line">         game     0.9383    0.9130    0.9255      1000</span><br><span class="line">entertainment     0.9538    0.8680    0.9089      1000</span><br><span class="line"></span><br><span class="line">     accuracy                         0.9005     10000</span><br><span class="line">    macro avg     0.9041    0.9005    0.9009     10000</span><br><span class="line"> weighted avg     0.9041    0.9005    0.9009     10000</span><br><span class="line"></span><br><span class="line">Confusion Matrix...</span><br><span class="line">[[867  13  84   2  19   1   9   5   0   0]</span><br><span class="line"> [ 17 929   6   0  16   4  12   7   5   4]</span><br><span class="line"> [ 40  29 817   0  74   0  33   4   3   0]</span><br><span class="line"> [  5   2   3 943   8   9  15   6   2   7]</span><br><span class="line"> [  3   3  17   2 913  10  18   4  24   6]</span><br><span class="line"> [ 18  16   0  12  41 855  41   6   2   9]</span><br><span class="line"> [  8   3  25   6  17   6 929   3   0   3]</span><br><span class="line"> [  3   2   3   2   8   0   4 971   2   5]</span><br><span class="line"> [  2   0   4   0  52   6   7   8 913   8]</span><br><span class="line"> [  5   6   1   2  24   3  15  54  22 868]]</span><br><span class="line">Time usage: 0:00:21</span><br><span class="line">model finish</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨äº†é¢„è®­ç»ƒçš„bertæ¨¡å‹ï¼Œé•¿æ–‡æœ¬è¶…å‡ºé•¿åº¦é™åˆ¶ï¼ˆ512ï¼‰ï¼Œbertæ²¡æœ‰è¿›è¡Œé•¿æ–‡æœ¬å®éªŒã€‚</p><h2 id="3-2-bilstm-attentionæ¨¡å‹"><a href="#3-2-bilstm-attentionæ¨¡å‹" class="headerlink" title="3.2 bilstm+attentionæ¨¡å‹"></a>3.2 bilstm+attentionæ¨¡å‹</h2><p>1.è¿è¡Œè„šæœ¬</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_VISIBLE_DEVICES=0,1 </span><br><span class="line">nohup python run.py --model TextRNN_Att &gt; nohup.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>2.è¿è¡Œlog</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">Loading data...</span><br><span class="line">Vocab size:4762</span><br><span class="line">180000it [00:02, 70404.96it/s]</span><br><span class="line">10000it [00:00, 90716.68it/s]</span><br><span class="line">10000it [00:00, 92472.73it/s]</span><br><span class="line">Time usage: 0:00:03</span><br><span class="line">start train</span><br><span class="line">start model</span><br><span class="line">start network</span><br><span class="line">&lt;bound method Module.parameters of Model(</span><br><span class="line">  (embedding): Embedding(4762, 300)</span><br><span class="line">  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)</span><br><span class="line">  (tanh1): Tanh()</span><br><span class="line">  (tanh2): Tanh()</span><br><span class="line">  (fc1): Linear(in_features=256, out_features=64, bias=True)</span><br><span class="line">  (fc): Linear(in_features=64, out_features=10, bias=True)</span><br><span class="line"><span class="meta">)&gt;</span></span><br><span class="line"><span class="bash">start train</span></span><br><span class="line">Epoch [1/10]</span><br><span class="line">Iter:      0,  Train Loss:   2.3,  Train Acc:  6.25%,  Val Loss:   2.3,  Val Acc: 10.01%,  Time: 0:00:01 *</span><br><span class="line">Iter:    100,  Train Loss:  0.75,  Train Acc: 75.00%,  Val Loss:  0.78,  Val Acc: 73.34%,  Time: 0:00:05 *</span><br><span class="line">Iter:    200,  Train Loss:  0.76,  Train Acc: 72.66%,  Val Loss:  0.58,  Val Acc: 81.38%,  Time: 0:00:07 *</span><br><span class="line">Iter:    300,  Train Loss:   0.4,  Train Acc: 88.28%,  Val Loss:  0.53,  Val Acc: 83.07%,  Time: 0:00:10 *</span><br><span class="line">Iter:    400,  Train Loss:  0.53,  Train Acc: 84.38%,  Val Loss:  0.47,  Val Acc: 84.44%,  Time: 0:00:14 *</span><br><span class="line">Iter:    500,  Train Loss:  0.44,  Train Acc: 85.94%,  Val Loss:  0.44,  Val Acc: 85.70%,  Time: 0:00:18 *</span><br><span class="line">Iter:    600,  Train Loss:  0.48,  Train Acc: 82.81%,  Val Loss:  0.42,  Val Acc: 86.46%,  Time: 0:00:22 *</span><br><span class="line">Iter:    700,  Train Loss:  0.41,  Train Acc: 85.94%,  Val Loss:  0.41,  Val Acc: 86.79%,  Time: 0:00:25 *</span><br><span class="line">Iter:    800,  Train Loss:  0.35,  Train Acc: 88.28%,  Val Loss:  0.38,  Val Acc: 87.86%,  Time: 0:00:29 *</span><br><span class="line">Iter:    900,  Train Loss:  0.44,  Train Acc: 88.28%,  Val Loss:  0.38,  Val Acc: 87.53%,  Time: 0:00:33 </span><br><span class="line">Iter:   1000,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.37,  Val Acc: 88.04%,  Time: 0:00:36 *</span><br><span class="line">Iter:   1100,  Train Loss:  0.29,  Train Acc: 92.19%,  Val Loss:  0.39,  Val Acc: 86.97%,  Time: 0:00:40 </span><br><span class="line">Iter:   1200,  Train Loss:  0.32,  Train Acc: 88.28%,  Val Loss:  0.36,  Val Acc: 88.41%,  Time: 0:00:43 *</span><br><span class="line">Iter:   1300,  Train Loss:  0.34,  Train Acc: 85.94%,  Val Loss:  0.36,  Val Acc: 88.54%,  Time: 0:00:47 </span><br><span class="line">Iter:   1400,  Train Loss:  0.43,  Train Acc: 85.94%,  Val Loss:  0.36,  Val Acc: 88.44%,  Time: 0:00:50 </span><br><span class="line">Epoch [2/10]</span><br><span class="line">Iter:   1500,  Train Loss:  0.43,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 88.15%,  Time: 0:00:54 </span><br><span class="line">Iter:   1600,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.37,  Val Acc: 88.53%,  Time: 0:00:57 </span><br><span class="line">Iter:   1700,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.63%,  Time: 0:01:00 *</span><br><span class="line">Iter:   1800,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.31%,  Time: 0:01:03 *</span><br><span class="line">Iter:   1900,  Train Loss:  0.33,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.55%,  Time: 0:01:07 *</span><br><span class="line">Iter:   2000,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.12%,  Time: 0:01:10 </span><br><span class="line">Iter:   2100,  Train Loss:  0.34,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 89.42%,  Time: 0:01:14 </span><br><span class="line">Iter:   2200,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 89.52%,  Time: 0:01:17 </span><br><span class="line">Iter:   2300,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.31%,  Time: 0:01:21 *</span><br><span class="line">Iter:   2400,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.97%,  Time: 0:01:24 </span><br><span class="line">Iter:   2500,  Train Loss:  0.22,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 89.67%,  Time: 0:01:28 *</span><br><span class="line">Iter:   2600,  Train Loss:  0.26,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.74%,  Time: 0:01:31 </span><br><span class="line">Iter:   2700,  Train Loss:  0.25,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 89.83%,  Time: 0:01:35 *</span><br><span class="line">Iter:   2800,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 89.59%,  Time: 0:01:39 </span><br><span class="line">Epoch [3/10]</span><br><span class="line">Iter:   2900,  Train Loss:  0.32,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.21%,  Time: 0:01:42 </span><br><span class="line">Iter:   3000,  Train Loss:  0.21,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.80%,  Time: 0:01:45 </span><br><span class="line">Iter:   3100,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.29%,  Time: 0:01:50 </span><br><span class="line">Iter:   3200,  Train Loss:  0.33,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.51%,  Time: 0:01:53 </span><br><span class="line">Iter:   3300,  Train Loss:  0.31,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.85%,  Time: 0:01:57 </span><br><span class="line">Iter:   3400,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 89.98%,  Time: 0:02:01 </span><br><span class="line">Iter:   3500,  Train Loss:  0.12,  Train Acc: 95.31%,  Val Loss:  0.34,  Val Acc: 89.42%,  Time: 0:02:04 </span><br><span class="line">Iter:   3600,  Train Loss:  0.17,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 90.14%,  Time: 0:02:08 </span><br><span class="line">Iter:   3700,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:  0.31,  Val Acc: 89.92%,  Time: 0:02:11 </span><br><span class="line">No optimization for a long time, auto-stopping...</span><br><span class="line">Test Loss:   0.3,  Test Acc: 89.75%</span><br><span class="line">Precision, Recall and F1-Score...</span><br><span class="line">               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">      finance     0.9120    0.8600    0.8852      1000</span><br><span class="line">       realty     0.9037    0.9200    0.9118      1000</span><br><span class="line">       stocks     0.8652    0.7960    0.8292      1000</span><br><span class="line">    education     0.9660    0.9080    0.9361      1000</span><br><span class="line">      science     0.7947    0.8750    0.8329      1000</span><br><span class="line">      society     0.8610    0.9290    0.8937      1000</span><br><span class="line">     politics     0.8918    0.8740    0.8828      1000</span><br><span class="line">       sports     0.9777    0.9660    0.9718      1000</span><br><span class="line">         game     0.9430    0.8930    0.9173      1000</span><br><span class="line">entertainment     0.8801    0.9540    0.9155      1000</span><br><span class="line"></span><br><span class="line">     accuracy                         0.8975     10000</span><br><span class="line">    macro avg     0.8995    0.8975    0.8976     10000</span><br><span class="line"> weighted avg     0.8995    0.8975    0.8976     10000</span><br><span class="line"></span><br><span class="line">Confusion Matrix...</span><br><span class="line">[[860  24  59   4  20  13  11   3   1   5]</span><br><span class="line"> [  8 920  16   0  11  15   7   4   4  15]</span><br><span class="line"> [ 53  29 796   1  77   3  32   1   6   2]</span><br><span class="line"> [  2   4   2 908  10  43  13   1   3  14]</span><br><span class="line"> [ 11  10  12   5 875  15  20   3  28  21]</span><br><span class="line"> [  0  15   1  10   8 929  16   1   3  17]</span><br><span class="line"> [  5   6  26   8  19  40 874   1   2  19]</span><br><span class="line"> [  1   1   2   0   1   5   3 966   0  21]</span><br><span class="line"> [  1   4   5   1  69   6   3   2 893  16]</span><br><span class="line"> [  2   5   1   3  11  10   1   6   7 954]]</span><br><span class="line">Time usage: 0:00:00</span><br><span class="line">finish train</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>é•¿æ–‡æœ¬ï¼ˆæ ‡é¢˜+æ­£æ–‡ï¼‰ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">Loading data...</span><br><span class="line">Vocab size:4762</span><br><span class="line">180000it [00:12, 14699.32it&#x2F;s]</span><br><span class="line">10000it [00:00, 12818.24it&#x2F;s]</span><br><span class="line">10000it [00:00, 16106.52it&#x2F;s]</span><br><span class="line">Time usage: 0:00:14</span><br><span class="line">start train</span><br><span class="line">start model</span><br><span class="line">start network</span><br><span class="line">&lt;bound method Module.parameters of Model(</span><br><span class="line">(base) yyfxu@cip57:~&#x2F;text-classify&#x2F;master$ vim nohup_bi_long.log </span><br><span class="line">(base) yyfxu@cip57:~&#x2F;text-classify&#x2F;master$ head -n 20 nohup_bi_long.log </span><br><span class="line">Loading data...</span><br><span class="line">Vocab size:4762</span><br><span class="line">180000it [00:12, 14699.32it&#x2F;s]</span><br><span class="line">10000it [00:00, 12818.24it&#x2F;s]</span><br><span class="line">10000it [00:00, 16106.52it&#x2F;s]</span><br><span class="line">Time usage: 0:00:14</span><br><span class="line">start train</span><br><span class="line">start model</span><br><span class="line">start network</span><br><span class="line">&lt;bound method Module.parameters of Model(</span><br><span class="line">  (embedding): Embedding(4762, 300)</span><br><span class="line">  (lstm): LSTM(300, 128, num_layers&#x3D;2, batch_first&#x3D;True, dropout&#x3D;0.5, bidirectional&#x3D;True)</span><br><span class="line">  (tanh1): Tanh()</span><br><span class="line">  (tanh2): Tanh()</span><br><span class="line">  (fc1): Linear(in_features&#x3D;256, out_features&#x3D;64, bias&#x3D;True)</span><br><span class="line">  (fc): Linear(in_features&#x3D;64, out_features&#x3D;10, bias&#x3D;True)</span><br><span class="line">)&gt;</span><br><span class="line">start train</span><br><span class="line">Epoch [1&#x2F;10]</span><br><span class="line">Iter:      0,  Train Loss:   2.3,  Train Acc: 18.75%,  Val Loss:   2.3,  Val Acc: 10.03%,  Time: 0:00:00 *</span><br><span class="line">Iter:    100,  Train Loss:  0.55,  Train Acc: 85.16%,  Val Loss:  0.55,  Val Acc: 82.30%,  Time: 0:00:02 *</span><br><span class="line">Iter:    200,  Train Loss:  0.41,  Train Acc: 85.16%,  Val Loss:  0.44,  Val Acc: 85.91%,  Time: 0:00:04 *</span><br><span class="line">Iter:    300,  Train Loss:  0.57,  Train Acc: 82.03%,  Val Loss:  0.41,  Val Acc: 86.64%,  Time: 0:00:06 *</span><br><span class="line">Iter:    400,  Train Loss:  0.45,  Train Acc: 85.94%,  Val Loss:  0.37,  Val Acc: 87.85%,  Time: 0:00:07 *</span><br><span class="line">Iter:    500,  Train Loss:   0.3,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.41%,  Time: 0:00:09 *</span><br><span class="line">Iter:    600,  Train Loss:  0.34,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.66%,  Time: 0:00:11 *</span><br><span class="line">Iter:    700,  Train Loss:  0.21,  Train Acc: 94.53%,  Val Loss:  0.33,  Val Acc: 89.61%,  Time: 0:00:12</span><br><span class="line">Iter:    800,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:   0.3,  Val Acc: 90.31%,  Time: 0:00:14 *</span><br><span class="line">Iter:    900,  Train Loss:  0.55,  Train Acc: 85.94%,  Val Loss:  0.28,  Val Acc: 91.13%,  Time: 0:00:15 *</span><br><span class="line">Iter:   1000,  Train Loss:  0.29,  Train Acc: 88.28%,  Val Loss:  0.28,  Val Acc: 91.06%,  Time: 0:00:17 *</span><br><span class="line">Iter:   1100,  Train Loss:  0.27,  Train Acc: 91.41%,  Val Loss:  0.26,  Val Acc: 91.70%,  Time: 0:00:19 *</span><br><span class="line">Iter:   1200,  Train Loss:  0.31,  Train Acc: 91.41%,  Val Loss:  0.26,  Val Acc: 91.70%,  Time: 0:00:21 *</span><br><span class="line">Iter:   1300,  Train Loss:  0.24,  Train Acc: 93.75%,  Val Loss:  0.28,  Val Acc: 91.10%,  Time: 0:00:22</span><br><span class="line">Iter:   1400,  Train Loss:  0.27,  Train Acc: 89.84%,  Val Loss:  0.25,  Val Acc: 91.79%,  Time: 0:00:24 *</span><br><span class="line">Epoch [2&#x2F;10]</span><br><span class="line">Iter:   1500,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:  0.28,  Val Acc: 90.45%,  Time: 0:00:26</span><br><span class="line">Iter:   1600,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.26,  Val Acc: 91.70%,  Time: 0:00:27</span><br><span class="line">Iter:   1700,  Train Loss:  0.22,  Train Acc: 93.75%,  Val Loss:  0.27,  Val Acc: 91.42%,  Time: 0:00:29</span><br><span class="line">Iter:   1800,  Train Loss:  0.14,  Train Acc: 95.31%,  Val Loss:  0.26,  Val Acc: 91.92%,  Time: 0:00:31</span><br><span class="line">Iter:   1900,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.24,  Val Acc: 92.33%,  Time: 0:00:32 *</span><br><span class="line">Iter:   2000,  Train Loss:  0.24,  Train Acc: 89.06%,  Val Loss:  0.24,  Val Acc: 92.20%,  Time: 0:00:34</span><br><span class="line">Iter:   2100,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:  0.25,  Val Acc: 91.82%,  Time: 0:00:36</span><br><span class="line">Iter:   2200,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.25,  Val Acc: 92.04%,  Time: 0:00:38</span><br><span class="line">Iter:   2300,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.24,  Val Acc: 92.06%,  Time: 0:00:42</span><br><span class="line">Iter:   2400,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.24,  Val Acc: 92.40%,  Time: 0:00:45 *</span><br><span class="line">Iter:   2500,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:  0.22,  Val Acc: 92.59%,  Time: 0:00:48 *</span><br><span class="line">Iter:   2600,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.22,  Val Acc: 92.81%,  Time: 0:00:51 *</span><br><span class="line">Iter:   2700,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.24,  Val Acc: 92.30%,  Time: 0:00:54</span><br><span class="line">Iter:   2800,  Train Loss:  0.17,  Train Acc: 95.31%,  Val Loss:  0.23,  Val Acc: 92.73%,  Time: 0:00:57</span><br><span class="line">Epoch [3&#x2F;10]</span><br><span class="line">Iter:   2900,  Train Loss:  0.17,  Train Acc: 93.75%,  Val Loss:  0.26,  Val Acc: 91.74%,  Time: 0:01:01</span><br><span class="line">Iter:   3000,  Train Loss:  0.22,  Train Acc: 94.53%,  Val Loss:  0.23,  Val Acc: 92.44%,  Time: 0:01:04</span><br><span class="line">Iter:   3100,  Train Loss:  0.18,  Train Acc: 94.53%,  Val Loss:  0.23,  Val Acc: 92.74%,  Time: 0:01:07</span><br><span class="line">Iter:   3200,  Train Loss:   0.1,  Train Acc: 96.88%,  Val Loss:  0.22,  Val Acc: 92.83%,  Time: 0:01:11</span><br><span class="line">Iter:   3300,  Train Loss:  0.17,  Train Acc: 95.31%,  Val Loss:  0.23,  Val Acc: 92.88%,  Time: 0:01:14</span><br><span class="line">Iter:   3400,  Train Loss:  0.19,  Train Acc: 95.31%,  Val Loss:  0.24,  Val Acc: 92.12%,  Time: 0:01:17</span><br><span class="line">Iter:   3500,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.23,  Val Acc: 92.45%,  Time: 0:01:21</span><br><span class="line">Iter:   3600,  Train Loss:  0.26,  Train Acc: 93.75%,  Val Loss:  0.24,  Val Acc: 92.20%,  Time: 0:01:24</span><br><span class="line">No optimization for a long time, auto-stopping...</span><br><span class="line">Test Loss:  0.22,  Test Acc: 92.82%</span><br><span class="line">Precision, Recall and F1-Score...</span><br><span class="line">               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">      finance     0.9044    0.9080    0.9062      1000</span><br><span class="line">       realty     0.9308    0.9410    0.9359      1000</span><br><span class="line">       stocks     0.8939    0.8850    0.8894      1000</span><br><span class="line">    education     0.9541    0.9560    0.9550      1000</span><br><span class="line">      science     0.9121    0.8610    0.8858      1000</span><br><span class="line">      society     0.8962    0.9240    0.9099      1000</span><br><span class="line">     politics     0.9086    0.9340    0.9211      1000</span><br><span class="line">       sports     0.9869    0.9830    0.9850      1000</span><br><span class="line">         game     0.9336    0.9560    0.9447      1000</span><br><span class="line">entertainment     0.9629    0.9340    0.9482      1000</span><br><span class="line"></span><br><span class="line">     accuracy                         0.9282     10000</span><br><span class="line">    macro avg     0.9283    0.9282    0.9281     10000</span><br><span class="line"> weighted avg     0.9283    0.9282    0.9281     10000</span><br><span class="line"></span><br><span class="line">Confusion Matrix...</span><br><span class="line">[[908  17  49   0   2  13   7   1   1   2]</span><br><span class="line"> [  7 941  14   4   8  14   6   0   3   3]</span><br><span class="line"> [ 51  17 885   3  18   3  17   0   5   1]</span><br><span class="line"> [  4   4   2 956   2  17   8   0   1   6]</span><br><span class="line"> [ 13   8  23   5 861  23  22   1  40   4]</span><br><span class="line"> [  5   9   3  15   6 924  27   1   2   8]</span><br><span class="line"> [  6   7   6  14   7  18 934   0   2   6]</span><br><span class="line"> [  3   1   1   0   1   3   2 983   1   5]</span><br><span class="line"> [  3   2   4   0  30   2   2   0 956   1]</span><br><span class="line"> [  4   5   3   5   9  14   3  10  13 934]]</span><br><span class="line">Time usage: 0:00:01</span><br><span class="line">finish train</span><br></pre></td></tr></table></figure><h2 id="3-3-transformeræ¨¡å‹ï¼ˆencoderï¼‰"><a href="#3-3-transformeræ¨¡å‹ï¼ˆencoderï¼‰" class="headerlink" title="3.3 transformeræ¨¡å‹ï¼ˆencoderï¼‰"></a>3.3 transformeræ¨¡å‹ï¼ˆencoderï¼‰</h2><p>1.è¿è¡Œè„šæœ¬</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_VISIBLE_DEVICES=0,1 </span><br><span class="line">nohup python run.py --model Transformer &gt; nohup.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>2.è¿è¡Œlog</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br></pre></td><td class="code"><pre><span class="line">Loading data...</span><br><span class="line">Vocab size:4762</span><br><span class="line">180000it [00:02, 71756.33it&#x2F;s]</span><br><span class="line">10000it [00:00, 91902.35it&#x2F;s]</span><br><span class="line">10000it [00:00, 89357.25it&#x2F;s]</span><br><span class="line">Time usage: 0:00:03</span><br><span class="line">start train</span><br><span class="line">start model</span><br><span class="line">start network</span><br><span class="line">&lt;bound method Module.parameters of Model(</span><br><span class="line">  (embedding): Embedding(4762, 300)</span><br><span class="line">  (postion_embedding): Positional_Encoding(</span><br><span class="line">    (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">  )</span><br><span class="line">  (encoder): Encoder(</span><br><span class="line">    (attention): Multi_Head_Attention(</span><br><span class="line">      (fc_Q): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">      (fc_K): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">      (fc_V): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">      (attention): Scaled_Dot_Product_Attention()</span><br><span class="line">      (fc): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">      (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">      (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">    )</span><br><span class="line">    (feed_forward): Position_wise_Feed_Forward(</span><br><span class="line">      (fc1): Linear(in_features&#x3D;300, out_features&#x3D;1024, bias&#x3D;True)</span><br><span class="line">      (fc2): Linear(in_features&#x3D;1024, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">      (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">      (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (encoders): ModuleList(</span><br><span class="line">    (0): Encoder(</span><br><span class="line">      (attention): Multi_Head_Attention(</span><br><span class="line">        (fc_Q): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (fc_K): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (fc_V): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (attention): Scaled_Dot_Product_Attention()</span><br><span class="line">        (fc): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">        (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">      )</span><br><span class="line">      (feed_forward): Position_wise_Feed_Forward(</span><br><span class="line">        (fc1): Linear(in_features&#x3D;300, out_features&#x3D;1024, bias&#x3D;True)</span><br><span class="line">        (fc2): Linear(in_features&#x3D;1024, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">        (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): Encoder(</span><br><span class="line">      (attention): Multi_Head_Attention(</span><br><span class="line">        (fc_Q): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (fc_K): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (fc_V): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (attention): Scaled_Dot_Product_Attention()</span><br><span class="line">        (fc): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">        (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">      )</span><br><span class="line">      (feed_forward): Position_wise_Feed_Forward(</span><br><span class="line">        (fc1): Linear(in_features&#x3D;300, out_features&#x3D;1024, bias&#x3D;True)</span><br><span class="line">        (fc2): Linear(in_features&#x3D;1024, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">        (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (fc1): Linear(in_features&#x3D;9600, out_features&#x3D;10, bias&#x3D;True)</span><br><span class="line">)&gt;</span><br><span class="line">start train</span><br><span class="line">Epoch [1&#x2F;20]</span><br><span class="line">Iter:      0,  Train Loss:   2.4,  Train Acc: 10.16%,  Val Loss:   4.6,  Val Acc: 10.02%,  Time: 0:00:01 *</span><br><span class="line">Iter:    100,  Train Loss:   1.4,  Train Acc: 53.12%,  Val Loss:   1.4,  Val Acc: 57.23%,  Time: 0:00:03 *</span><br><span class="line">Iter:    200,  Train Loss:   1.3,  Train Acc: 55.47%,  Val Loss:   1.0,  Val Acc: 68.83%,  Time: 0:00:05 *</span><br><span class="line">Iter:    300,  Train Loss:  0.82,  Train Acc: 67.97%,  Val Loss:   0.9,  Val Acc: 74.19%,  Time: 0:00:07 *</span><br><span class="line">Iter:    400,  Train Loss:  0.84,  Train Acc: 75.00%,  Val Loss:  0.83,  Val Acc: 76.70%,  Time: 0:00:09 *</span><br><span class="line">Iter:    500,  Train Loss:  0.65,  Train Acc: 78.12%,  Val Loss:  0.76,  Val Acc: 78.63%,  Time: 0:00:12 *</span><br><span class="line">Iter:    600,  Train Loss:  0.76,  Train Acc: 75.78%,  Val Loss:  0.76,  Val Acc: 79.15%,  Time: 0:00:15 *</span><br><span class="line">Iter:    700,  Train Loss:  0.63,  Train Acc: 78.12%,  Val Loss:  0.78,  Val Acc: 79.21%,  Time: 0:00:17 </span><br><span class="line">Iter:    800,  Train Loss:  0.59,  Train Acc: 81.25%,  Val Loss:  0.63,  Val Acc: 82.16%,  Time: 0:00:19 *</span><br><span class="line">Iter:    900,  Train Loss:   0.7,  Train Acc: 76.56%,  Val Loss:  0.69,  Val Acc: 80.84%,  Time: 0:00:21 </span><br><span class="line">Iter:   1000,  Train Loss:  0.48,  Train Acc: 82.81%,  Val Loss:  0.69,  Val Acc: 80.87%,  Time: 0:00:23 </span><br><span class="line">Iter:   1100,  Train Loss:  0.52,  Train Acc: 83.59%,  Val Loss:  0.62,  Val Acc: 82.61%,  Time: 0:00:26 *</span><br><span class="line">Iter:   1200,  Train Loss:  0.63,  Train Acc: 82.81%,  Val Loss:  0.63,  Val Acc: 82.48%,  Time: 0:00:28 </span><br><span class="line">Iter:   1300,  Train Loss:  0.59,  Train Acc: 80.47%,  Val Loss:  0.55,  Val Acc: 85.06%,  Time: 0:00:32 *</span><br><span class="line">Iter:   1400,  Train Loss:  0.76,  Train Acc: 74.22%,  Val Loss:  0.56,  Val Acc: 84.04%,  Time: 0:00:35 </span><br><span class="line">Epoch [2&#x2F;20]</span><br><span class="line">Iter:   1500,  Train Loss:  0.63,  Train Acc: 79.69%,  Val Loss:  0.57,  Val Acc: 84.12%,  Time: 0:00:38 </span><br><span class="line">Iter:   1600,  Train Loss:  0.52,  Train Acc: 78.91%,  Val Loss:  0.65,  Val Acc: 82.71%,  Time: 0:00:41 </span><br><span class="line">Iter:   1700,  Train Loss:  0.59,  Train Acc: 82.81%,  Val Loss:  0.58,  Val Acc: 83.98%,  Time: 0:00:44 </span><br><span class="line">Iter:   1800,  Train Loss:  0.46,  Train Acc: 87.50%,  Val Loss:  0.54,  Val Acc: 85.62%,  Time: 0:00:47 *</span><br><span class="line">Iter:   1900,  Train Loss:  0.53,  Train Acc: 81.25%,  Val Loss:  0.53,  Val Acc: 85.76%,  Time: 0:00:50 *</span><br><span class="line">Iter:   2000,  Train Loss:  0.58,  Train Acc: 82.81%,  Val Loss:  0.58,  Val Acc: 84.32%,  Time: 0:00:53 </span><br><span class="line">Iter:   2100,  Train Loss:  0.56,  Train Acc: 86.72%,  Val Loss:  0.55,  Val Acc: 84.90%,  Time: 0:00:56 </span><br><span class="line">Iter:   2200,  Train Loss:  0.36,  Train Acc: 89.84%,  Val Loss:  0.52,  Val Acc: 85.77%,  Time: 0:01:00 *</span><br><span class="line">Iter:   2300,  Train Loss:  0.43,  Train Acc: 86.72%,  Val Loss:  0.55,  Val Acc: 84.77%,  Time: 0:01:03 </span><br><span class="line">Iter:   2400,  Train Loss:  0.55,  Train Acc: 81.25%,  Val Loss:  0.56,  Val Acc: 85.17%,  Time: 0:01:06 </span><br><span class="line">Iter:   2500,  Train Loss:   0.4,  Train Acc: 85.94%,  Val Loss:  0.56,  Val Acc: 84.99%,  Time: 0:01:10 </span><br><span class="line">Iter:   2600,  Train Loss:  0.57,  Train Acc: 79.69%,  Val Loss:  0.55,  Val Acc: 84.93%,  Time: 0:01:13 </span><br><span class="line">Iter:   2700,  Train Loss:  0.44,  Train Acc: 87.50%,  Val Loss:  0.48,  Val Acc: 86.88%,  Time: 0:01:16 *</span><br><span class="line">Iter:   2800,  Train Loss:  0.57,  Train Acc: 82.81%,  Val Loss:   0.5,  Val Acc: 86.41%,  Time: 0:01:20 </span><br><span class="line">Epoch [3&#x2F;20]</span><br><span class="line">Iter:   2900,  Train Loss:  0.59,  Train Acc: 79.69%,  Val Loss:  0.59,  Val Acc: 84.07%,  Time: 0:01:23 </span><br><span class="line">Iter:   3000,  Train Loss:  0.47,  Train Acc: 86.72%,  Val Loss:  0.52,  Val Acc: 86.12%,  Time: 0:01:27 </span><br><span class="line">Iter:   3100,  Train Loss:  0.48,  Train Acc: 85.16%,  Val Loss:  0.48,  Val Acc: 86.31%,  Time: 0:01:29 </span><br><span class="line">Iter:   3200,  Train Loss:  0.71,  Train Acc: 83.59%,  Val Loss:  0.51,  Val Acc: 86.09%,  Time: 0:01:33 </span><br><span class="line">Iter:   3300,  Train Loss:  0.46,  Train Acc: 85.94%,  Val Loss:  0.48,  Val Acc: 87.24%,  Time: 0:01:36 *</span><br><span class="line">Iter:   3400,  Train Loss:  0.51,  Train Acc: 82.03%,  Val Loss:  0.47,  Val Acc: 87.28%,  Time: 0:01:39 *</span><br><span class="line">Iter:   3500,  Train Loss:  0.45,  Train Acc: 84.38%,  Val Loss:  0.54,  Val Acc: 86.01%,  Time: 0:01:42 </span><br><span class="line">Iter:   3600,  Train Loss:  0.35,  Train Acc: 86.72%,  Val Loss:  0.49,  Val Acc: 87.23%,  Time: 0:01:46 </span><br><span class="line">Iter:   3700,  Train Loss:  0.59,  Train Acc: 80.47%,  Val Loss:  0.48,  Val Acc: 86.53%,  Time: 0:01:49 </span><br><span class="line">Iter:   3800,  Train Loss:  0.53,  Train Acc: 84.38%,  Val Loss:  0.52,  Val Acc: 86.27%,  Time: 0:01:52 </span><br><span class="line">Iter:   3900,  Train Loss:  0.51,  Train Acc: 83.59%,  Val Loss:  0.51,  Val Acc: 86.02%,  Time: 0:01:56 </span><br><span class="line">Iter:   4000,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.48,  Val Acc: 87.14%,  Time: 0:02:01 </span><br><span class="line">Iter:   4100,  Train Loss:  0.47,  Train Acc: 84.38%,  Val Loss:  0.48,  Val Acc: 87.02%,  Time: 0:02:04 </span><br><span class="line">Iter:   4200,  Train Loss:  0.52,  Train Acc: 84.38%,  Val Loss:  0.49,  Val Acc: 86.53%,  Time: 0:02:08 </span><br><span class="line">Epoch [4&#x2F;20]</span><br><span class="line">Iter:   4300,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.47,  Val Acc: 87.06%,  Time: 0:02:11 </span><br><span class="line">Iter:   4400,  Train Loss:  0.26,  Train Acc: 93.75%,  Val Loss:  0.47,  Val Acc: 87.44%,  Time: 0:02:14 *</span><br><span class="line">Iter:   4500,  Train Loss:  0.47,  Train Acc: 88.28%,  Val Loss:  0.46,  Val Acc: 87.48%,  Time: 0:02:17 *</span><br><span class="line">Iter:   4600,  Train Loss:  0.38,  Train Acc: 88.28%,  Val Loss:  0.45,  Val Acc: 87.91%,  Time: 0:02:21 *</span><br><span class="line">Iter:   4700,  Train Loss:  0.52,  Train Acc: 82.81%,  Val Loss:  0.45,  Val Acc: 87.24%,  Time: 0:02:25 </span><br><span class="line">Iter:   4800,  Train Loss:  0.33,  Train Acc: 88.28%,  Val Loss:  0.46,  Val Acc: 87.63%,  Time: 0:02:28 </span><br><span class="line">Iter:   4900,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.46,  Val Acc: 87.85%,  Time: 0:02:30 </span><br><span class="line">Iter:   5000,  Train Loss:  0.39,  Train Acc: 85.94%,  Val Loss:  0.47,  Val Acc: 87.79%,  Time: 0:02:33 </span><br><span class="line">Iter:   5100,  Train Loss:  0.53,  Train Acc: 80.47%,  Val Loss:  0.45,  Val Acc: 87.48%,  Time: 0:02:36 </span><br><span class="line">Iter:   5200,  Train Loss:  0.58,  Train Acc: 85.16%,  Val Loss:  0.47,  Val Acc: 87.18%,  Time: 0:02:40 </span><br><span class="line">Iter:   5300,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.48,  Val Acc: 86.80%,  Time: 0:02:43 </span><br><span class="line">Iter:   5400,  Train Loss:  0.67,  Train Acc: 82.03%,  Val Loss:  0.45,  Val Acc: 87.63%,  Time: 0:02:46 </span><br><span class="line">Iter:   5500,  Train Loss:  0.42,  Train Acc: 85.16%,  Val Loss:  0.44,  Val Acc: 87.70%,  Time: 0:02:48 *</span><br><span class="line">Iter:   5600,  Train Loss:  0.38,  Train Acc: 89.84%,  Val Loss:  0.43,  Val Acc: 88.02%,  Time: 0:02:51 *</span><br><span class="line">Epoch [5&#x2F;20]</span><br><span class="line">Iter:   5700,  Train Loss:  0.41,  Train Acc: 86.72%,  Val Loss:  0.42,  Val Acc: 88.50%,  Time: 0:02:54 *</span><br><span class="line">Iter:   5800,  Train Loss:  0.22,  Train Acc: 89.84%,  Val Loss:  0.43,  Val Acc: 88.11%,  Time: 0:02:57 </span><br><span class="line">Iter:   5900,  Train Loss:  0.39,  Train Acc: 91.41%,  Val Loss:  0.44,  Val Acc: 88.15%,  Time: 0:03:00 </span><br><span class="line">Iter:   6000,  Train Loss:  0.44,  Train Acc: 83.59%,  Val Loss:  0.41,  Val Acc: 88.30%,  Time: 0:03:03 *</span><br><span class="line">Iter:   6100,  Train Loss:  0.44,  Train Acc: 85.16%,  Val Loss:  0.44,  Val Acc: 88.09%,  Time: 0:03:07 </span><br><span class="line">Iter:   6200,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.42,  Val Acc: 88.42%,  Time: 0:03:09 </span><br><span class="line">Iter:   6300,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:  0.43,  Val Acc: 88.17%,  Time: 0:03:12 </span><br><span class="line">Iter:   6400,  Train Loss:  0.21,  Train Acc: 94.53%,  Val Loss:  0.41,  Val Acc: 88.25%,  Time: 0:03:15 *</span><br><span class="line">Iter:   6500,  Train Loss:  0.44,  Train Acc: 87.50%,  Val Loss:  0.41,  Val Acc: 88.49%,  Time: 0:03:19 </span><br><span class="line">Iter:   6600,  Train Loss:  0.38,  Train Acc: 89.84%,  Val Loss:  0.43,  Val Acc: 88.01%,  Time: 0:03:22 </span><br><span class="line">Iter:   6700,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.41,  Val Acc: 88.09%,  Time: 0:03:25 </span><br><span class="line">Iter:   6800,  Train Loss:  0.35,  Train Acc: 89.84%,  Val Loss:  0.45,  Val Acc: 88.01%,  Time: 0:03:28 </span><br><span class="line">Iter:   6900,  Train Loss:  0.35,  Train Acc: 86.72%,  Val Loss:  0.41,  Val Acc: 88.16%,  Time: 0:03:32 </span><br><span class="line">Iter:   7000,  Train Loss:  0.41,  Train Acc: 84.38%,  Val Loss:   0.4,  Val Acc: 88.43%,  Time: 0:03:36 *</span><br><span class="line">Epoch [6&#x2F;20]</span><br><span class="line">Iter:   7100,  Train Loss:  0.41,  Train Acc: 83.59%,  Val Loss:   0.4,  Val Acc: 88.95%,  Time: 0:03:39 *</span><br><span class="line">Iter:   7200,  Train Loss:  0.48,  Train Acc: 82.81%,  Val Loss:  0.42,  Val Acc: 88.71%,  Time: 0:03:41 </span><br><span class="line">Iter:   7300,  Train Loss:  0.37,  Train Acc: 86.72%,  Val Loss:  0.42,  Val Acc: 88.67%,  Time: 0:03:44 </span><br><span class="line">Iter:   7400,  Train Loss:   0.6,  Train Acc: 77.34%,  Val Loss:  0.43,  Val Acc: 87.97%,  Time: 0:03:47 </span><br><span class="line">Iter:   7500,  Train Loss:  0.34,  Train Acc: 84.38%,  Val Loss:  0.42,  Val Acc: 88.02%,  Time: 0:03:50 </span><br><span class="line">Iter:   7600,  Train Loss:  0.29,  Train Acc: 89.06%,  Val Loss:  0.47,  Val Acc: 87.11%,  Time: 0:03:54 </span><br><span class="line">Iter:   7700,  Train Loss:   0.4,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 89.16%,  Time: 0:03:57 *</span><br><span class="line">Iter:   7800,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.41,  Val Acc: 88.64%,  Time: 0:04:00 </span><br><span class="line">Iter:   7900,  Train Loss:  0.37,  Train Acc: 86.72%,  Val Loss:   0.4,  Val Acc: 88.47%,  Time: 0:04:03 </span><br><span class="line">Iter:   8000,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:   0.4,  Val Acc: 89.05%,  Time: 0:04:06 </span><br><span class="line">Iter:   8100,  Train Loss:  0.26,  Train Acc: 92.97%,  Val Loss:  0.42,  Val Acc: 88.54%,  Time: 0:04:09 </span><br><span class="line">Iter:   8200,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 89.00%,  Time: 0:04:13 </span><br><span class="line">Iter:   8300,  Train Loss:  0.33,  Train Acc: 89.84%,  Val Loss:  0.41,  Val Acc: 87.85%,  Time: 0:04:16 </span><br><span class="line">Iter:   8400,  Train Loss:  0.53,  Train Acc: 78.91%,  Val Loss:  0.37,  Val Acc: 88.97%,  Time: 0:04:20 *</span><br><span class="line">Epoch [7&#x2F;20]</span><br><span class="line">Iter:   8500,  Train Loss:   0.5,  Train Acc: 85.16%,  Val Loss:  0.43,  Val Acc: 88.20%,  Time: 0:04:22 </span><br><span class="line">Iter:   8600,  Train Loss:  0.25,  Train Acc: 92.19%,  Val Loss:  0.42,  Val Acc: 88.93%,  Time: 0:04:26 </span><br><span class="line">Iter:   8700,  Train Loss:  0.35,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 89.48%,  Time: 0:04:29 </span><br><span class="line">Iter:   8800,  Train Loss:  0.44,  Train Acc: 82.81%,  Val Loss:  0.39,  Val Acc: 88.89%,  Time: 0:04:33 </span><br><span class="line">Iter:   8900,  Train Loss:  0.34,  Train Acc: 88.28%,  Val Loss:  0.39,  Val Acc: 89.18%,  Time: 0:04:36 </span><br><span class="line">Iter:   9000,  Train Loss:  0.23,  Train Acc: 91.41%,  Val Loss:  0.39,  Val Acc: 89.37%,  Time: 0:04:39 </span><br><span class="line">Iter:   9100,  Train Loss:   0.5,  Train Acc: 84.38%,  Val Loss:  0.39,  Val Acc: 89.34%,  Time: 0:04:43 </span><br><span class="line">Iter:   9200,  Train Loss:   0.4,  Train Acc: 90.62%,  Val Loss:   0.4,  Val Acc: 88.81%,  Time: 0:04:46 </span><br><span class="line">Iter:   9300,  Train Loss:  0.41,  Train Acc: 85.16%,  Val Loss:  0.39,  Val Acc: 89.10%,  Time: 0:04:50 </span><br><span class="line">Iter:   9400,  Train Loss:  0.45,  Train Acc: 85.94%,  Val Loss:  0.43,  Val Acc: 88.22%,  Time: 0:04:54 </span><br><span class="line">Iter:   9500,  Train Loss:  0.34,  Train Acc: 88.28%,  Val Loss:   0.4,  Val Acc: 89.02%,  Time: 0:04:57 </span><br><span class="line">Iter:   9600,  Train Loss:  0.47,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 89.25%,  Time: 0:05:01 </span><br><span class="line">Iter:   9700,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:  0.38,  Val Acc: 88.91%,  Time: 0:05:04 </span><br><span class="line">Iter:   9800,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:  0.39,  Val Acc: 89.03%,  Time: 0:05:07 </span><br><span class="line">Epoch [8&#x2F;20]</span><br><span class="line">Iter:   9900,  Train Loss:  0.51,  Train Acc: 78.91%,  Val Loss:  0.39,  Val Acc: 89.19%,  Time: 0:05:11 </span><br><span class="line">Iter:  10000,  Train Loss:  0.27,  Train Acc: 90.62%,  Val Loss:   0.4,  Val Acc: 88.75%,  Time: 0:05:14 </span><br><span class="line">Iter:  10100,  Train Loss:  0.45,  Train Acc: 84.38%,  Val Loss:  0.38,  Val Acc: 89.28%,  Time: 0:05:17 </span><br><span class="line">Iter:  10200,  Train Loss:  0.39,  Train Acc: 85.94%,  Val Loss:  0.38,  Val Acc: 89.17%,  Time: 0:05:20 </span><br><span class="line">Iter:  10300,  Train Loss:  0.38,  Train Acc: 87.50%,  Val Loss:  0.37,  Val Acc: 89.62%,  Time: 0:05:24 *</span><br><span class="line">Iter:  10400,  Train Loss:  0.35,  Train Acc: 88.28%,  Val Loss:  0.38,  Val Acc: 89.22%,  Time: 0:05:27 </span><br><span class="line">Iter:  10500,  Train Loss:  0.29,  Train Acc: 89.84%,  Val Loss:  0.41,  Val Acc: 88.86%,  Time: 0:05:31 </span><br><span class="line">Iter:  10600,  Train Loss:  0.36,  Train Acc: 89.06%,  Val Loss:   0.4,  Val Acc: 89.12%,  Time: 0:05:34 </span><br><span class="line">Iter:  10700,  Train Loss:  0.32,  Train Acc: 88.28%,  Val Loss:  0.39,  Val Acc: 88.98%,  Time: 0:05:37 </span><br><span class="line">Iter:  10800,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:  0.39,  Val Acc: 88.85%,  Time: 0:05:41 </span><br><span class="line">Iter:  10900,  Train Loss:  0.42,  Train Acc: 85.16%,  Val Loss:  0.38,  Val Acc: 89.07%,  Time: 0:05:45 </span><br><span class="line">Iter:  11000,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.38,  Val Acc: 89.04%,  Time: 0:05:48 </span><br><span class="line">Iter:  11100,  Train Loss:  0.38,  Train Acc: 89.84%,  Val Loss:  0.38,  Val Acc: 88.94%,  Time: 0:05:51 </span><br><span class="line">Iter:  11200,  Train Loss:  0.44,  Train Acc: 82.81%,  Val Loss:  0.38,  Val Acc: 89.17%,  Time: 0:05:54 </span><br><span class="line">Epoch [9&#x2F;20]</span><br><span class="line">Iter:  11300,  Train Loss:  0.33,  Train Acc: 86.72%,  Val Loss:  0.38,  Val Acc: 89.51%,  Time: 0:05:57 </span><br><span class="line">Iter:  11400,  Train Loss:  0.39,  Train Acc: 85.16%,  Val Loss:   0.4,  Val Acc: 88.89%,  Time: 0:06:01 </span><br><span class="line">Iter:  11500,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:   0.4,  Val Acc: 89.20%,  Time: 0:06:04 </span><br><span class="line">Iter:  11600,  Train Loss:  0.19,  Train Acc: 95.31%,  Val Loss:  0.37,  Val Acc: 89.70%,  Time: 0:06:06 </span><br><span class="line">Iter:  11700,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.37,  Val Acc: 89.89%,  Time: 0:06:11 *</span><br><span class="line">Iter:  11800,  Train Loss:  0.27,  Train Acc: 91.41%,  Val Loss:  0.38,  Val Acc: 89.17%,  Time: 0:06:14 </span><br><span class="line">Iter:  11900,  Train Loss:  0.27,  Train Acc: 91.41%,  Val Loss:  0.39,  Val Acc: 89.47%,  Time: 0:06:17 </span><br><span class="line">Iter:  12000,  Train Loss:  0.48,  Train Acc: 86.72%,  Val Loss:  0.39,  Val Acc: 89.43%,  Time: 0:06:20 </span><br><span class="line">Iter:  12100,  Train Loss:  0.37,  Train Acc: 86.72%,  Val Loss:  0.36,  Val Acc: 89.82%,  Time: 0:06:27 *</span><br><span class="line">Iter:  12200,  Train Loss:   0.3,  Train Acc: 92.97%,  Val Loss:  0.37,  Val Acc: 89.53%,  Time: 0:06:30 </span><br><span class="line">Iter:  12300,  Train Loss:   0.3,  Train Acc: 92.97%,  Val Loss:  0.39,  Val Acc: 88.93%,  Time: 0:06:33 </span><br><span class="line">Iter:  12400,  Train Loss:  0.23,  Train Acc: 89.84%,  Val Loss:  0.36,  Val Acc: 89.35%,  Time: 0:06:36 </span><br><span class="line">Iter:  12500,  Train Loss:  0.34,  Train Acc: 88.28%,  Val Loss:  0.39,  Val Acc: 89.21%,  Time: 0:06:39 </span><br><span class="line">Iter:  12600,  Train Loss:  0.29,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 89.75%,  Time: 0:06:44 *</span><br><span class="line">Epoch [10&#x2F;20]</span><br><span class="line">Iter:  12700,  Train Loss:  0.27,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 89.64%,  Time: 0:06:48 *</span><br><span class="line">Iter:  12800,  Train Loss:   0.2,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 89.23%,  Time: 0:06:51 </span><br><span class="line">Iter:  12900,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:  0.38,  Val Acc: 89.47%,  Time: 0:06:54 </span><br><span class="line">Iter:  13000,  Train Loss:  0.38,  Train Acc: 91.41%,  Val Loss:   0.4,  Val Acc: 89.49%,  Time: 0:06:58 </span><br><span class="line">Iter:  13100,  Train Loss:  0.41,  Train Acc: 88.28%,  Val Loss:  0.37,  Val Acc: 89.39%,  Time: 0:07:01 </span><br><span class="line">Iter:  13200,  Train Loss:  0.55,  Train Acc: 85.16%,  Val Loss:  0.37,  Val Acc: 89.49%,  Time: 0:07:06 </span><br><span class="line">Iter:  13300,  Train Loss:  0.29,  Train Acc: 89.84%,  Val Loss:  0.38,  Val Acc: 89.90%,  Time: 0:07:09 </span><br><span class="line">Iter:  13400,  Train Loss:  0.28,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 89.26%,  Time: 0:07:12 </span><br><span class="line">Iter:  13500,  Train Loss:   0.3,  Train Acc: 88.28%,  Val Loss:  0.38,  Val Acc: 89.65%,  Time: 0:07:15 </span><br><span class="line">Iter:  13600,  Train Loss:  0.34,  Train Acc: 91.41%,  Val Loss:  0.38,  Val Acc: 88.99%,  Time: 0:07:18 </span><br><span class="line">Iter:  13700,  Train Loss:  0.26,  Train Acc: 93.75%,  Val Loss:  0.37,  Val Acc: 89.44%,  Time: 0:07:21 </span><br><span class="line">Iter:  13800,  Train Loss:  0.43,  Train Acc: 83.59%,  Val Loss:  0.35,  Val Acc: 89.62%,  Time: 0:07:25 </span><br><span class="line">Iter:  13900,  Train Loss:  0.28,  Train Acc: 92.19%,  Val Loss:   0.4,  Val Acc: 88.97%,  Time: 0:07:29 </span><br><span class="line">Iter:  14000,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:  0.37,  Val Acc: 89.51%,  Time: 0:07:32 </span><br><span class="line">Epoch [11&#x2F;20]</span><br><span class="line">Iter:  14100,  Train Loss:  0.45,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 89.14%,  Time: 0:07:35 </span><br><span class="line">Iter:  14200,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.37,  Val Acc: 89.48%,  Time: 0:07:39 </span><br><span class="line">Iter:  14300,  Train Loss:  0.27,  Train Acc: 89.84%,  Val Loss:  0.37,  Val Acc: 89.69%,  Time: 0:07:42 </span><br><span class="line">Iter:  14400,  Train Loss:  0.23,  Train Acc: 90.62%,  Val Loss:  0.37,  Val Acc: 89.92%,  Time: 0:07:46 </span><br><span class="line">Iter:  14500,  Train Loss:  0.33,  Train Acc: 89.84%,  Val Loss:  0.36,  Val Acc: 89.72%,  Time: 0:07:49 </span><br><span class="line">Iter:  14600,  Train Loss:  0.24,  Train Acc: 92.97%,  Val Loss:  0.37,  Val Acc: 89.83%,  Time: 0:07:52 </span><br><span class="line">Iter:  14700,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.38,  Val Acc: 89.63%,  Time: 0:07:55 </span><br><span class="line">No optimization for a long time, auto-stopping...</span><br><span class="line">Test Loss:  0.34,  Test Acc: 89.88%</span><br><span class="line">Precision, Recall and F1-Score...</span><br><span class="line">               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">      finance     0.8745    0.8710    0.8727      1000</span><br><span class="line">       realty     0.9173    0.9210    0.9192      1000</span><br><span class="line">       stocks     0.8308    0.8350    0.8329      1000</span><br><span class="line">    education     0.9356    0.9450    0.9403      1000</span><br><span class="line">      science     0.8395    0.8160    0.8276      1000</span><br><span class="line">      society     0.9097    0.9070    0.9084      1000</span><br><span class="line">     politics     0.8994    0.8760    0.8875      1000</span><br><span class="line">       sports     0.9896    0.9530    0.9710      1000</span><br><span class="line">         game     0.9312    0.9070    0.9189      1000</span><br><span class="line">entertainment     0.8661    0.9570    0.9093      1000</span><br><span class="line"></span><br><span class="line">     accuracy                         0.8988     10000</span><br><span class="line">    macro avg     0.8994    0.8988    0.8988     10000</span><br><span class="line"> weighted avg     0.8994    0.8988    0.8988     10000</span><br><span class="line"></span><br><span class="line">Confusion Matrix...</span><br><span class="line">[[871  18  74   6  13   7   5   1   0   5]</span><br><span class="line"> [ 16 921  21   1   9  15   4   1   1  11]</span><br><span class="line"> [ 59  22 835   1  38   4  25   1  10   5]</span><br><span class="line"> [  3   4   0 945   8  11   8   1   4  16]</span><br><span class="line"> [ 15  10  40   9 816  15  24   1  38  32]</span><br><span class="line"> [  5  12   1  21   7 907  22   0   7  18]</span><br><span class="line"> [ 15   3  24  12  21  26 876   0   2  21]</span><br><span class="line"> [  1   2   2   3   5   3   6 953   0  25]</span><br><span class="line"> [  6   5   5   6  47   4   3   2 907  15]</span><br><span class="line"> [  5   7   3   6   8   5   1   3   5 957]]</span><br><span class="line">Time usage: 0:00:00</span><br><span class="line">finish train</span><br></pre></td></tr></table></figure><p>é•¿æ–‡æœ¬ï¼ˆæ ‡é¢˜+æ­£æ–‡ï¼‰ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br></pre></td><td class="code"><pre><span class="line">Loading data...</span><br><span class="line">Vocab size:4762</span><br><span class="line">180000it [00:12, 14883.19it&#x2F;s]</span><br><span class="line">10000it [00:00, 12805.79it&#x2F;s]</span><br><span class="line">10000it [00:00, 14804.58it&#x2F;s]Time usage: 0:00:14</span><br><span class="line">start train</span><br><span class="line">start model</span><br><span class="line">start network</span><br><span class="line">&lt;bound method Module.parameters of Model(</span><br><span class="line">  (embedding): Embedding(4762, 300)</span><br><span class="line">  (postion_embedding): Positional_Encoding(</span><br><span class="line">    (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">  )</span><br><span class="line">  (encoder): Encoder(</span><br><span class="line">    (attention): Multi_Head_Attention(</span><br><span class="line">      (fc_Q): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">      (fc_K): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">      (fc_V): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">      (attention): Scaled_Dot_Product_Attention()</span><br><span class="line">      (fc): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">      (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">      (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">    )</span><br><span class="line">    (feed_forward): Position_wise_Feed_Forward(</span><br><span class="line">      (fc1): Linear(in_features&#x3D;300, out_features&#x3D;1024, bias&#x3D;True)</span><br><span class="line">      (fc2): Linear(in_features&#x3D;1024, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">      (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">      (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (encoders): ModuleList(</span><br><span class="line">    (0): Encoder(</span><br><span class="line">      (attention): Multi_Head_Attention(</span><br><span class="line">        (fc_Q): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (fc_K): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (fc_V): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (attention): Scaled_Dot_Product_Attention()</span><br><span class="line">        (fc): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">        (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">      )</span><br><span class="line">      (feed_forward): Position_wise_Feed_Forward(</span><br><span class="line">        (fc1): Linear(in_features&#x3D;300, out_features&#x3D;1024, bias&#x3D;True)</span><br><span class="line">        (fc2): Linear(in_features&#x3D;1024, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">        (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): Encoder(</span><br><span class="line">      (attention): Multi_Head_Attention(</span><br><span class="line">        (fc_Q): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (fc_K): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (fc_V): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (attention): Scaled_Dot_Product_Attention()</span><br><span class="line">        (fc): Linear(in_features&#x3D;300, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">        (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">      )</span><br><span class="line">      (feed_forward): Position_wise_Feed_Forward(</span><br><span class="line">        (fc1): Linear(in_features&#x3D;300, out_features&#x3D;1024, bias&#x3D;True)</span><br><span class="line">        (fc2): Linear(in_features&#x3D;1024, out_features&#x3D;300, bias&#x3D;True)</span><br><span class="line">        (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">        (layer_norm): LayerNorm((300,), eps&#x3D;1e-05, elementwise_affine&#x3D;True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (fc1): Linear(in_features&#x3D;9600, out_features&#x3D;10, bias&#x3D;True)</span><br><span class="line">)&gt;</span><br><span class="line">start train</span><br><span class="line">Epoch [1&#x2F;20]</span><br><span class="line">Iter:      0,  Train Loss:   2.5,  Train Acc:  8.59%,  Val Loss:   5.1,  Val Acc: 10.00%,  Time: 0:00:01 *</span><br><span class="line">Iter:    100,  Train Loss:   1.2,  Train Acc: 54.69%,  Val Loss:   1.4,  Val Acc: 59.11%,  Time: 0:00:05 *</span><br><span class="line">Iter:    200,  Train Loss:  0.91,  Train Acc: 64.06%,  Val Loss:  0.91,  Val Acc: 73.32%,  Time: 0:00:08 *</span><br><span class="line">Iter:    300,  Train Loss:  0.93,  Train Acc: 66.41%,  Val Loss:  0.67,  Val Acc: 80.04%,  Time: 0:00:11 *</span><br><span class="line">Iter:    400,  Train Loss:  0.94,  Train Acc: 68.75%,  Val Loss:  0.67,  Val Acc: 81.33%,  Time: 0:00:14</span><br><span class="line">Iter:    500,  Train Loss:   0.7,  Train Acc: 75.00%,  Val Loss:  0.59,  Val Acc: 83.27%,  Time: 0:00:18 *</span><br><span class="line">Iter:    600,  Train Loss:  0.53,  Train Acc: 84.38%,  Val Loss:  0.56,  Val Acc: 84.59%,  Time: 0:00:21 *</span><br><span class="line">Iter:    700,  Train Loss:  0.59,  Train Acc: 79.69%,  Val Loss:  0.53,  Val Acc: 85.44%,  Time: 0:00:24 *</span><br><span class="line">Iter:    800,  Train Loss:  0.47,  Train Acc: 85.16%,  Val Loss:  0.66,  Val Acc: 82.96%,  Time: 0:00:27</span><br><span class="line">Iter:    900,  Train Loss:  0.71,  Train Acc: 81.25%,  Val Loss:  0.54,  Val Acc: 85.88%,  Time: 0:00:30</span><br><span class="line">Iter:   1000,  Train Loss:  0.47,  Train Acc: 84.38%,  Val Loss:  0.48,  Val Acc: 86.87%,  Time: 0:00:34 *</span><br><span class="line">Iter:   1100,  Train Loss:  0.51,  Train Acc: 84.38%,  Val Loss:   0.5,  Val Acc: 86.69%,  Time: 0:00:37</span><br><span class="line">Iter:   1200,  Train Loss:  0.63,  Train Acc: 82.03%,  Val Loss:   0.5,  Val Acc: 87.30%,  Time: 0:00:40</span><br><span class="line">Iter:   1300,  Train Loss:  0.48,  Train Acc: 83.59%,  Val Loss:  0.48,  Val Acc: 87.17%,  Time: 0:00:43</span><br><span class="line">Iter:   1400,  Train Loss:  0.52,  Train Acc: 83.59%,  Val Loss:  0.49,  Val Acc: 87.48%,  Time: 0:00:46</span><br><span class="line">Epoch [2&#x2F;20]</span><br><span class="line">Iter:   1500,  Train Loss:   0.6,  Train Acc: 79.69%,  Val Loss:  0.48,  Val Acc: 87.80%,  Time: 0:00:49 *</span><br><span class="line">Iter:   1600,  Train Loss:  0.46,  Train Acc: 86.72%,  Val Loss:  0.48,  Val Acc: 87.64%,  Time: 0:00:50</span><br><span class="line">Iter:   1700,  Train Loss:  0.43,  Train Acc: 85.16%,  Val Loss:  0.56,  Val Acc: 85.89%,  Time: 0:00:52</span><br><span class="line">Iter:   1800,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.43,  Val Acc: 88.56%,  Time: 0:00:54 *</span><br><span class="line">Iter:   1900,  Train Loss:  0.53,  Train Acc: 84.38%,  Val Loss:  0.43,  Val Acc: 89.19%,  Time: 0:00:56</span><br><span class="line">Iter:   2000,  Train Loss:  0.43,  Train Acc: 88.28%,  Val Loss:  0.46,  Val Acc: 88.27%,  Time: 0:00:57</span><br><span class="line">Iter:   2100,  Train Loss:  0.58,  Train Acc: 82.81%,  Val Loss:  0.42,  Val Acc: 88.74%,  Time: 0:00:59 *</span><br><span class="line">Iter:   2200,  Train Loss:  0.61,  Train Acc: 81.25%,  Val Loss:  0.45,  Val Acc: 88.39%,  Time: 0:01:01</span><br><span class="line">Iter:   2300,  Train Loss:  0.43,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 89.75%,  Time: 0:01:02 *</span><br><span class="line">Iter:   2400,  Train Loss:  0.46,  Train Acc: 85.94%,  Val Loss:  0.47,  Val Acc: 88.05%,  Time: 0:01:04</span><br><span class="line">Iter:   2500,  Train Loss:  0.55,  Train Acc: 82.03%,  Val Loss:  0.45,  Val Acc: 88.85%,  Time: 0:01:05</span><br><span class="line">Iter:   2600,  Train Loss:  0.44,  Train Acc: 83.59%,  Val Loss:  0.44,  Val Acc: 89.37%,  Time: 0:01:07</span><br><span class="line">Iter:   2700,  Train Loss:  0.52,  Train Acc: 85.16%,  Val Loss:  0.44,  Val Acc: 89.23%,  Time: 0:01:09</span><br><span class="line">Iter:   2800,  Train Loss:   0.5,  Train Acc: 82.03%,  Val Loss:  0.41,  Val Acc: 89.03%,  Time: 0:01:11</span><br><span class="line">Epoch [3&#x2F;20]</span><br><span class="line">Iter:   2900,  Train Loss:  0.26,  Train Acc: 92.97%,  Val Loss:  0.41,  Val Acc: 89.40%,  Time: 0:01:12</span><br><span class="line">Iter:   3000,  Train Loss:  0.38,  Train Acc: 86.72%,  Val Loss:  0.41,  Val Acc: 89.39%,  Time: 0:01:14</span><br><span class="line">Iter:   3100,  Train Loss:  0.26,  Train Acc: 87.50%,  Val Loss:  0.45,  Val Acc: 89.05%,  Time: 0:01:15</span><br><span class="line">Iter:   3200,  Train Loss:  0.39,  Train Acc: 85.94%,  Val Loss:  0.38,  Val Acc: 90.10%,  Time: 0:01:17 *</span><br><span class="line">Iter:   3300,  Train Loss:  0.37,  Train Acc: 91.41%,  Val Loss:   0.4,  Val Acc: 90.25%,  Time: 0:01:19</span><br><span class="line">Iter:   3400,  Train Loss:  0.43,  Train Acc: 88.28%,  Val Loss:  0.45,  Val Acc: 89.23%,  Time: 0:01:20</span><br><span class="line">Iter:   3500,  Train Loss:  0.38,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 90.79%,  Time: 0:01:22 *</span><br><span class="line">Iter:   3600,  Train Loss:  0.51,  Train Acc: 87.50%,  Val Loss:   0.4,  Val Acc: 89.65%,  Time: 0:01:24</span><br><span class="line">Iter:   3700,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 90.74%,  Time: 0:01:26 *</span><br><span class="line">Iter:   3800,  Train Loss:  0.45,  Train Acc: 85.16%,  Val Loss:  0.38,  Val Acc: 90.38%,  Time: 0:01:27</span><br><span class="line">Iter:   3900,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.41,  Val Acc: 89.36%,  Time: 0:01:29</span><br><span class="line">Iter:   4000,  Train Loss:  0.47,  Train Acc: 85.94%,  Val Loss:  0.36,  Val Acc: 90.55%,  Time: 0:01:31</span><br><span class="line">Iter:   4100,  Train Loss:  0.44,  Train Acc: 81.25%,  Val Loss:  0.36,  Val Acc: 90.73%,  Time: 0:01:33</span><br><span class="line">Iter:   4200,  Train Loss:  0.31,  Train Acc: 92.97%,  Val Loss:  0.45,  Val Acc: 88.83%,  Time: 0:01:35</span><br><span class="line">Epoch [4&#x2F;20]</span><br><span class="line">Iter:   4300,  Train Loss:   0.2,  Train Acc: 93.75%,  Val Loss:   0.4,  Val Acc: 89.56%,  Time: 0:01:37</span><br><span class="line">Iter:   4400,  Train Loss:  0.34,  Train Acc: 86.72%,  Val Loss:  0.34,  Val Acc: 90.85%,  Time: 0:01:38 *</span><br><span class="line">Iter:   4500,  Train Loss:  0.29,  Train Acc: 89.84%,  Val Loss:  0.45,  Val Acc: 89.03%,  Time: 0:01:40</span><br><span class="line">Iter:   4600,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.36,  Val Acc: 90.92%,  Time: 0:01:42</span><br><span class="line">Iter:   4700,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.38,  Val Acc: 90.14%,  Time: 0:01:44</span><br><span class="line">Iter:   4800,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 90.78%,  Time: 0:01:46</span><br><span class="line">Iter:   4900,  Train Loss:  0.49,  Train Acc: 85.16%,  Val Loss:  0.36,  Val Acc: 90.53%,  Time: 0:01:47</span><br><span class="line">Iter:   5000,  Train Loss:  0.29,  Train Acc: 89.84%,  Val Loss:  0.36,  Val Acc: 90.31%,  Time: 0:01:49</span><br><span class="line">Iter:   5100,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 90.70%,  Time: 0:01:51 *</span><br><span class="line">Iter:   5200,  Train Loss:  0.35,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 90.89%,  Time: 0:01:53 *</span><br><span class="line">Iter:   5300,  Train Loss:  0.29,  Train Acc: 89.06%,  Val Loss:  0.32,  Val Acc: 91.47%,  Time: 0:01:54 *</span><br><span class="line">Iter:   5400,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 91.17%,  Time: 0:01:56</span><br><span class="line">Iter:   5500,  Train Loss:  0.26,  Train Acc: 92.97%,  Val Loss:  0.32,  Val Acc: 90.96%,  Time: 0:01:58 *</span><br><span class="line">Iter:   5600,  Train Loss:  0.35,  Train Acc: 87.50%,  Val Loss:  0.31,  Val Acc: 91.41%,  Time: 0:02:00 *</span><br><span class="line">Epoch [5&#x2F;20]</span><br><span class="line">Iter:   5700,  Train Loss:  0.38,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 90.82%,  Time: 0:02:02</span><br><span class="line">Iter:   5800,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 91.13%,  Time: 0:02:03</span><br><span class="line">Iter:   5900,  Train Loss:  0.28,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 90.78%,  Time: 0:02:05</span><br><span class="line">Iter:   6000,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.31,  Val Acc: 91.33%,  Time: 0:02:07</span><br><span class="line">Iter:   6100,  Train Loss:  0.18,  Train Acc: 95.31%,  Val Loss:  0.36,  Val Acc: 90.30%,  Time: 0:02:08</span><br><span class="line">Iter:   6200,  Train Loss:  0.46,  Train Acc: 84.38%,  Val Loss:  0.35,  Val Acc: 90.57%,  Time: 0:02:10</span><br><span class="line">Iter:   6300,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:   0.3,  Val Acc: 91.65%,  Time: 0:02:12 *</span><br><span class="line">Iter:   6400,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:   0.3,  Val Acc: 91.65%,  Time: 0:02:14</span><br><span class="line">Iter:   6500,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 91.30%,  Time: 0:02:16</span><br><span class="line">Iter:   6600,  Train Loss:  0.32,  Train Acc: 86.72%,  Val Loss:   0.3,  Val Acc: 91.93%,  Time: 0:02:18</span><br><span class="line">Iter:   6700,  Train Loss:   0.2,  Train Acc: 94.53%,  Val Loss:  0.31,  Val Acc: 91.30%,  Time: 0:02:20</span><br><span class="line">Iter:   6800,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.29,  Val Acc: 91.71%,  Time: 0:02:21 *</span><br><span class="line">Iter:   6900,  Train Loss:  0.21,  Train Acc: 91.41%,  Val Loss:  0.29,  Val Acc: 91.89%,  Time: 0:02:23</span><br><span class="line">Iter:   7000,  Train Loss:  0.44,  Train Acc: 85.94%,  Val Loss:   0.3,  Val Acc: 91.50%,  Time: 0:02:25</span><br><span class="line">Epoch [6&#x2F;20]</span><br><span class="line">Iter:   7100,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.28,  Val Acc: 91.57%,  Time: 0:02:27 *</span><br><span class="line">Iter:   7200,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.29,  Val Acc: 91.81%,  Time: 0:02:29</span><br><span class="line">Iter:   7300,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:  0.34,  Val Acc: 90.86%,  Time: 0:02:31</span><br><span class="line">Iter:   7400,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:  0.29,  Val Acc: 91.68%,  Time: 0:02:33</span><br><span class="line">Iter:   7500,  Train Loss:  0.21,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 92.08%,  Time: 0:02:35</span><br><span class="line">Iter:   7600,  Train Loss:  0.26,  Train Acc: 89.06%,  Val Loss:   0.3,  Val Acc: 91.82%,  Time: 0:02:36</span><br><span class="line">Iter:   7700,  Train Loss:  0.23,  Train Acc: 90.62%,  Val Loss:   0.3,  Val Acc: 91.81%,  Time: 0:02:38</span><br><span class="line">Iter:   7800,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:  0.28,  Val Acc: 91.81%,  Time: 0:02:40 *</span><br><span class="line">Iter:   7900,  Train Loss:  0.34,  Train Acc: 91.41%,  Val Loss:  0.27,  Val Acc: 92.38%,  Time: 0:02:42 *</span><br><span class="line">Iter:   8000,  Train Loss:  0.51,  Train Acc: 82.81%,  Val Loss:  0.28,  Val Acc: 92.01%,  Time: 0:02:44</span><br><span class="line">Iter:   8100,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 91.69%,  Time: 0:02:46</span><br><span class="line">Iter:   8200,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.31,  Val Acc: 91.31%,  Time: 0:02:48</span><br><span class="line">Iter:   8300,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.32,  Val Acc: 91.25%,  Time: 0:02:49</span><br><span class="line">Iter:   8400,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:  0.28,  Val Acc: 92.02%,  Time: 0:02:51</span><br><span class="line">Epoch [7&#x2F;20]</span><br><span class="line">Iter:   8500,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.29,  Val Acc: 91.79%,  Time: 0:02:53</span><br><span class="line">Iter:   8600,  Train Loss:  0.26,  Train Acc: 89.84%,  Val Loss:  0.28,  Val Acc: 92.21%,  Time: 0:02:55</span><br><span class="line">Iter:   8700,  Train Loss:  0.25,  Train Acc: 89.84%,  Val Loss:  0.29,  Val Acc: 91.82%,  Time: 0:02:57</span><br><span class="line">Iter:   8800,  Train Loss:  0.23,  Train Acc: 92.97%,  Val Loss:  0.27,  Val Acc: 91.80%,  Time: 0:02:59</span><br><span class="line">Iter:   8900,  Train Loss:  0.29,  Train Acc: 92.19%,  Val Loss:  0.29,  Val Acc: 91.47%,  Time: 0:03:01</span><br><span class="line">Iter:   9000,  Train Loss:  0.17,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 91.84%,  Time: 0:03:03</span><br><span class="line">Iter:   9100,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.89%,  Time: 0:03:05</span><br><span class="line">Iter:   9200,  Train Loss:  0.18,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 91.57%,  Time: 0:03:07</span><br><span class="line">Iter:   9300,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.27,  Val Acc: 91.93%,  Time: 0:03:08</span><br><span class="line">Iter:   9400,  Train Loss:  0.27,  Train Acc: 91.41%,  Val Loss:  0.27,  Val Acc: 92.09%,  Time: 0:03:10</span><br><span class="line">Iter:   9500,  Train Loss:  0.25,  Train Acc: 92.19%,  Val Loss:  0.29,  Val Acc: 92.05%,  Time: 0:03:12</span><br><span class="line">Iter:   9600,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.28,  Val Acc: 92.03%,  Time: 0:03:13</span><br><span class="line">Iter:   9700,  Train Loss:  0.26,  Train Acc: 89.84%,  Val Loss:   0.3,  Val Acc: 91.83%,  Time: 0:03:15</span><br><span class="line">Iter:   9800,  Train Loss:  0.19,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 91.76%,  Time: 0:03:17</span><br><span class="line">Epoch [8&#x2F;20]</span><br><span class="line">Iter:   9900,  Train Loss:  0.29,  Train Acc: 88.28%,  Val Loss:  0.28,  Val Acc: 91.96%,  Time: 0:03:18</span><br><span class="line">No optimization for a long time, auto-stopping...</span><br><span class="line">Test Loss:  0.26,  Test Acc: 92.28%</span><br><span class="line">Precision, Recall and F1-Score...</span><br><span class="line">               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">      finance     0.9250    0.8760    0.8998      1000</span><br><span class="line">       realty     0.9103    0.9340    0.9220      1000</span><br><span class="line">       stocks     0.8696    0.9000    0.8845      1000</span><br><span class="line">    education     0.9550    0.9330    0.9439      1000</span><br><span class="line">      science     0.9078    0.8660    0.8864      1000</span><br><span class="line">      society     0.9214    0.8790    0.8997      1000</span><br><span class="line">     politics     0.8917    0.9300    0.9104      1000</span><br><span class="line">       sports     0.9879    0.9820    0.9850      1000</span><br><span class="line">         game     0.9367    0.9620    0.9492      1000</span><br><span class="line">entertainment     0.9262    0.9660    0.9457      1000</span><br><span class="line"></span><br><span class="line">     accuracy                         0.9228     10000</span><br><span class="line">    macro avg     0.9231    0.9228    0.9227     10000</span><br><span class="line"> weighted avg     0.9231    0.9228    0.9227     10000</span><br><span class="line"></span><br><span class="line">Confusion Matrix...</span><br><span class="line">[[876  19  72   1   8   9   7   0   0   8]</span><br><span class="line"> [  9 934  19   2  10  11   8   0   2   5]</span><br><span class="line"> [ 36  12 900   2  22   2  17   1   6   2]</span><br><span class="line"> [  1  12   4 933   2  12  24   1   3   8]</span><br><span class="line"> [ 12   8  22   5 866  10  15   1  43  18]</span><br><span class="line"> [  4  19   5  24  17 879  33   2   3  14]</span><br><span class="line"> [  4   9   7   5  10  23 930   1   2   9]</span><br><span class="line"> [  1   2   2   0   2   2   2 982   0   7]</span><br><span class="line"> [  4   6   4   1  13   2   2   0 962   6]</span><br><span class="line"> [  0   5   0   4   4   4   5   6   6 966]]</span><br><span class="line">Time usage: 0:00:00</span><br><span class="line">finish train</span><br></pre></td></tr></table></figure><h2 id="3-4-cnnæ¨¡å‹"><a href="#3-4-cnnæ¨¡å‹" class="headerlink" title="3.4 cnnæ¨¡å‹"></a>3.4 cnnæ¨¡å‹</h2><p>1.è¿è¡Œè„šæœ¬</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_VISIBLE_DEVICES=0,1 </span><br><span class="line">nohup python run.py --model TextCNN &gt; nohup_cnn.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>2.è¿è¡Œlog</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line">Loading data...</span><br><span class="line">Vocab size:4762</span><br><span class="line">180000it [00:03, 47432.48it&#x2F;s]</span><br><span class="line">10000it [00:00, 46997.85it&#x2F;s]</span><br><span class="line">10000it [00:00, 48451.14it&#x2F;s]Time usage: 0:00:04</span><br><span class="line">start train</span><br><span class="line">start model</span><br><span class="line">start network</span><br><span class="line">&lt;bound method Module.parameters of Model(</span><br><span class="line">  (embedding): Embedding(4762, 300)</span><br><span class="line">  (convs): ModuleList(</span><br><span class="line">    (0): Conv2d(1, 256, kernel_size&#x3D;(2, 300), stride&#x3D;(1, 1))</span><br><span class="line">    (1): Conv2d(1, 256, kernel_size&#x3D;(3, 300), stride&#x3D;(1, 1))</span><br><span class="line">    (2): Conv2d(1, 256, kernel_size&#x3D;(4, 300), stride&#x3D;(1, 1))</span><br><span class="line">  )</span><br><span class="line">  (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">  (fc): Linear(in_features&#x3D;768, out_features&#x3D;10, bias&#x3D;True)</span><br><span class="line">)&gt;</span><br><span class="line">start train</span><br><span class="line">Epoch [1&#x2F;20]</span><br><span class="line">Iter:      0,  Train Loss:   2.3,  Train Acc: 14.84%,  Val Loss:   2.7,  Val Acc: 10.70%,  Time: 0:00:02 *</span><br><span class="line">Iter:    100,  Train Loss:  0.77,  Train Acc: 70.31%,  Val Loss:   0.7,  Val Acc: 78.36%,  Time: 0:00:07 *</span><br><span class="line">Iter:    200,  Train Loss:  0.74,  Train Acc: 74.22%,  Val Loss:  0.55,  Val Acc: 83.18%,  Time: 0:00:12 *</span><br><span class="line">Iter:    300,  Train Loss:  0.45,  Train Acc: 85.16%,  Val Loss:  0.49,  Val Acc: 84.72%,  Time: 0:00:16 *</span><br><span class="line">Iter:    400,  Train Loss:  0.72,  Train Acc: 79.69%,  Val Loss:  0.48,  Val Acc: 85.10%,  Time: 0:00:20 *</span><br><span class="line">Iter:    500,  Train Loss:  0.35,  Train Acc: 89.06%,  Val Loss:  0.44,  Val Acc: 86.10%,  Time: 0:00:24 *</span><br><span class="line">Iter:    600,  Train Loss:  0.49,  Train Acc: 84.38%,  Val Loss:  0.42,  Val Acc: 86.77%,  Time: 0:00:27 *</span><br><span class="line">Iter:    700,  Train Loss:  0.49,  Train Acc: 83.59%,  Val Loss:  0.41,  Val Acc: 87.15%,  Time: 0:00:31 *</span><br><span class="line">Iter:    800,  Train Loss:  0.43,  Train Acc: 86.72%,  Val Loss:   0.4,  Val Acc: 87.80%,  Time: 0:00:36 *</span><br><span class="line">Iter:    900,  Train Loss:  0.47,  Train Acc: 85.16%,  Val Loss:  0.38,  Val Acc: 88.04%,  Time: 0:00:40 *</span><br><span class="line">Iter:   1000,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.38,  Val Acc: 88.54%,  Time: 0:00:45 *</span><br><span class="line">Iter:   1100,  Train Loss:  0.38,  Train Acc: 91.41%,  Val Loss:  0.38,  Val Acc: 88.64%,  Time: 0:00:50 *</span><br><span class="line">Iter:   1200,  Train Loss:  0.38,  Train Acc: 86.72%,  Val Loss:  0.37,  Val Acc: 88.99%,  Time: 0:00:55 *</span><br><span class="line">Iter:   1300,  Train Loss:  0.43,  Train Acc: 85.94%,  Val Loss:  0.36,  Val Acc: 88.81%,  Time: 0:01:00 *</span><br><span class="line">Iter:   1400,  Train Loss:  0.52,  Train Acc: 82.81%,  Val Loss:  0.35,  Val Acc: 88.96%,  Time: 0:01:04 *</span><br><span class="line">Epoch [2&#x2F;20]</span><br><span class="line">Iter:   1500,  Train Loss:   0.4,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 89.09%,  Time: 0:01:10 *</span><br><span class="line">Iter:   1600,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 89.15%,  Time: 0:01:14</span><br><span class="line">Iter:   1700,  Train Loss:   0.4,  Train Acc: 86.72%,  Val Loss:  0.35,  Val Acc: 89.68%,  Time: 0:01:18 *</span><br><span class="line">Iter:   1800,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.36,  Val Acc: 88.90%,  Time: 0:01:22</span><br><span class="line">Iter:   1900,  Train Loss:  0.36,  Train Acc: 89.84%,  Val Loss:  0.34,  Val Acc: 89.37%,  Time: 0:01:27 *</span><br><span class="line">Iter:   2000,  Train Loss:  0.35,  Train Acc: 85.16%,  Val Loss:  0.35,  Val Acc: 89.47%,  Time: 0:01:31</span><br><span class="line">Iter:   2100,  Train Loss:  0.36,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.40%,  Time: 0:01:35 *</span><br><span class="line">Iter:   2200,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.43%,  Time: 0:01:40</span><br><span class="line">Iter:   2300,  Train Loss:  0.31,  Train Acc: 93.75%,  Val Loss:  0.34,  Val Acc: 89.67%,  Time: 0:01:44 *</span><br><span class="line">Iter:   2400,  Train Loss:  0.27,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.90%,  Time: 0:01:49 *</span><br><span class="line">Iter:   2500,  Train Loss:  0.16,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 90.18%,  Time: 0:01:53 *</span><br><span class="line">Iter:   2600,  Train Loss:   0.4,  Train Acc: 83.59%,  Val Loss:  0.33,  Val Acc: 90.04%,  Time: 0:01:58</span><br><span class="line">Iter:   2700,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.90%,  Time: 0:02:02</span><br><span class="line">Iter:   2800,  Train Loss:  0.36,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.67%,  Time: 0:02:06</span><br><span class="line">Epoch [3&#x2F;20]</span><br><span class="line">Iter:   2900,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.80%,  Time: 0:02:11</span><br><span class="line">Iter:   3000,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.71%,  Time: 0:02:15</span><br><span class="line">Iter:   3100,  Train Loss:  0.24,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.98%,  Time: 0:02:19</span><br><span class="line">Iter:   3200,  Train Loss:  0.39,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.88%,  Time: 0:02:24</span><br><span class="line">Iter:   3300,  Train Loss:  0.29,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 90.11%,  Time: 0:02:28 *</span><br><span class="line">Iter:   3400,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.97%,  Time: 0:02:33</span><br><span class="line">Iter:   3500,  Train Loss:  0.16,  Train Acc: 94.53%,  Val Loss:  0.33,  Val Acc: 90.13%,  Time: 0:02:38</span><br><span class="line">Iter:   3600,  Train Loss:  0.17,  Train Acc: 95.31%,  Val Loss:  0.33,  Val Acc: 89.95%,  Time: 0:02:42</span><br><span class="line">Iter:   3700,  Train Loss:  0.36,  Train Acc: 86.72%,  Val Loss:  0.33,  Val Acc: 90.08%,  Time: 0:02:47</span><br><span class="line">Iter:   3800,  Train Loss:  0.36,  Train Acc: 84.38%,  Val Loss:  0.32,  Val Acc: 90.17%,  Time: 0:02:52 *</span><br><span class="line">Iter:   3900,  Train Loss:  0.36,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 90.20%,  Time: 0:02:56</span><br><span class="line">Iter:   4000,  Train Loss:  0.24,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 90.23%,  Time: 0:03:01</span><br><span class="line">Iter:   4100,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.95%,  Time: 0:03:05</span><br><span class="line">Iter:   4200,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 89.95%,  Time: 0:03:11</span><br><span class="line">Epoch [4&#x2F;20]</span><br><span class="line">Iter:   4300,  Train Loss:  0.19,  Train Acc: 92.97%,  Val Loss:  0.32,  Val Acc: 90.27%,  Time: 0:03:15 *</span><br><span class="line">Iter:   4400,  Train Loss:  0.19,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.37%,  Time: 0:03:19</span><br><span class="line">Iter:   4500,  Train Loss:  0.37,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 90.21%,  Time: 0:03:24</span><br><span class="line">Iter:   4600,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 90.02%,  Time: 0:03:29</span><br><span class="line">Iter:   4700,  Train Loss:  0.48,  Train Acc: 87.50%,  Val Loss:  0.32,  Val Acc: 90.25%,  Time: 0:03:34</span><br><span class="line">Iter:   4800,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 90.34%,  Time: 0:03:38</span><br><span class="line">Iter:   4900,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 90.26%,  Time: 0:03:41</span><br><span class="line">Iter:   5000,  Train Loss:  0.21,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.88%,  Time: 0:03:46</span><br><span class="line">Iter:   5100,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 90.21%,  Time: 0:03:50</span><br><span class="line">Iter:   5200,  Train Loss:  0.32,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 90.12%,  Time: 0:03:55</span><br><span class="line">Iter:   5300,  Train Loss:  0.19,  Train Acc: 96.09%,  Val Loss:  0.32,  Val Acc: 90.46%,  Time: 0:04:00 *</span><br><span class="line">Iter:   5400,  Train Loss:  0.47,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 90.17%,  Time: 0:04:04</span><br><span class="line">Iter:   5500,  Train Loss:  0.27,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 90.41%,  Time: 0:04:08</span><br><span class="line">Iter:   5600,  Train Loss:  0.13,  Train Acc: 95.31%,  Val Loss:  0.33,  Val Acc: 90.17%,  Time: 0:04:13</span><br><span class="line">Epoch [5&#x2F;20]</span><br><span class="line">Iter:   5700,  Train Loss:  0.24,  Train Acc: 94.53%,  Val Loss:  0.34,  Val Acc: 90.07%,  Time: 0:04:18</span><br><span class="line">Iter:   5800,  Train Loss:  0.16,  Train Acc: 93.75%,  Val Loss:  0.34,  Val Acc: 90.14%,  Time: 0:04:22</span><br><span class="line">Iter:   5900,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 90.52%,  Time: 0:04:28</span><br><span class="line">Iter:   6000,  Train Loss:  0.15,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 90.45%,  Time: 0:04:32</span><br><span class="line">Iter:   6100,  Train Loss:  0.26,  Train Acc: 89.06%,  Val Loss:  0.32,  Val Acc: 90.58%,  Time: 0:04:36</span><br><span class="line">Iter:   6200,  Train Loss:  0.13,  Train Acc: 94.53%,  Val Loss:  0.33,  Val Acc: 90.46%,  Time: 0:04:41</span><br><span class="line">Iter:   6300,  Train Loss:  0.12,  Train Acc: 96.88%,  Val Loss:  0.33,  Val Acc: 90.56%,  Time: 0:04:45</span><br><span class="line">No optimization for a long time, auto-stopping...</span><br><span class="line">Test Loss:  0.29,  Test Acc: 91.34%</span><br><span class="line">Precision, Recall and F1-Score...</span><br><span class="line">               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">      finance     0.9193    0.8890    0.9039      1000</span><br><span class="line">       realty     0.9134    0.9490    0.9308      1000</span><br><span class="line">       stocks     0.8363    0.8790    0.8571      1000</span><br><span class="line">    education     0.9540    0.9550    0.9545      1000</span><br><span class="line">      science     0.8800    0.8580    0.8689      1000</span><br><span class="line">      society     0.9067    0.9140    0.9104      1000</span><br><span class="line">     politics     0.9054    0.8900    0.8976      1000</span><br><span class="line">       sports     0.9578    0.9540    0.9559      1000</span><br><span class="line">         game     0.9383    0.9130    0.9255      1000</span><br><span class="line">entertainment     0.9265    0.9330    0.9297      1000</span><br><span class="line"></span><br><span class="line">     accuracy                         0.9134     10000</span><br><span class="line">    macro avg     0.9138    0.9134    0.9134     10000</span><br><span class="line"> weighted avg     0.9138    0.9134    0.9134     10000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Confusion Matrix...</span><br><span class="line">[[889  17  59   4  10   9   7   3   0   2]</span><br><span class="line"> [  9 949  13   2   4   8   4   2   3   6]</span><br><span class="line"> [ 40  24 879   3  21   0  25   3   4   1]</span><br><span class="line"> [  2   2   1 955   6  13   5   2   1  13]</span><br><span class="line"> [  8   8  38   6 858  15  16   5  36  10]</span><br><span class="line"> [  4  22   3  11  10 914  26   2   2   6]</span><br><span class="line"> [  9   7  32  10  15  27 890   4   0   6]</span><br><span class="line"> [  3   2   7   1   3   8   4 954   2  16]</span><br><span class="line"> [  2   1  15   4  36   4   3   8 913  14]</span><br><span class="line"> [  1   7   4   5  12  10   3  13  12 933]]</span><br><span class="line">Time usage: 0:00:00</span><br><span class="line">finish train</span><br></pre></td></tr></table></figure><p>é•¿æ–‡æœ¬ï¼ˆæ ‡é¢˜+æ­£æ–‡ï¼‰ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line">Loading data...</span><br><span class="line">Vocab size:4762</span><br><span class="line">180000it [00:12, 14970.72it&#x2F;s]</span><br><span class="line">10000it [00:00, 13435.87it&#x2F;s]</span><br><span class="line">10000it [00:00, 16773.90it&#x2F;s]</span><br><span class="line">Time usage: 0:00:13</span><br><span class="line">start train</span><br><span class="line">start model</span><br><span class="line">start network</span><br><span class="line">&lt;bound method Module.parameters of Model(</span><br><span class="line">  (embedding): Embedding(4762, 300)</span><br><span class="line">  (convs): ModuleList(</span><br><span class="line">    (0): Conv2d(1, 256, kernel_size&#x3D;(2, 300), stride&#x3D;(1, 1))</span><br><span class="line">    (1): Conv2d(1, 256, kernel_size&#x3D;(3, 300), stride&#x3D;(1, 1))</span><br><span class="line">    (2): Conv2d(1, 256, kernel_size&#x3D;(4, 300), stride&#x3D;(1, 1))</span><br><span class="line">  )</span><br><span class="line">  (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">  (fc): Linear(in_features&#x3D;768, out_features&#x3D;10, bias&#x3D;True)</span><br><span class="line">)&gt;</span><br><span class="line">start train</span><br><span class="line">start model</span><br><span class="line">start network</span><br><span class="line">&lt;bound method Module.parameters of Model(</span><br><span class="line">  (embedding): Embedding(4762, 300)</span><br><span class="line">  (convs): ModuleList(</span><br><span class="line">    (0): Conv2d(1, 256, kernel_size&#x3D;(2, 300), stride&#x3D;(1, 1))</span><br><span class="line">    (1): Conv2d(1, 256, kernel_size&#x3D;(3, 300), stride&#x3D;(1, 1))</span><br><span class="line">    (2): Conv2d(1, 256, kernel_size&#x3D;(4, 300), stride&#x3D;(1, 1))</span><br><span class="line">  )</span><br><span class="line">  (dropout): Dropout(p&#x3D;0.5, inplace&#x3D;False)</span><br><span class="line">  (fc): Linear(in_features&#x3D;768, out_features&#x3D;10, bias&#x3D;True)</span><br><span class="line">)&gt;</span><br><span class="line">start train</span><br><span class="line">Epoch [1&#x2F;20]</span><br><span class="line">Iter:      0,  Train Loss:   2.3,  Train Acc: 11.72%,  Val Loss:   2.5,  Val Acc: 10.00%,  Time: 0:00:01 *</span><br><span class="line">Iter:    100,  Train Loss:  0.53,  Train Acc: 83.59%,  Val Loss:  0.53,  Val Acc: 84.06%,  Time: 0:00:07 *</span><br><span class="line">Iter:    200,  Train Loss:  0.48,  Train Acc: 85.16%,  Val Loss:  0.42,  Val Acc: 87.16%,  Time: 0:00:13 *</span><br><span class="line">Iter:    300,  Train Loss:  0.57,  Train Acc: 80.47%,  Val Loss:  0.37,  Val Acc: 88.62%,  Time: 0:00:17 *</span><br><span class="line">Iter:    400,  Train Loss:  0.43,  Train Acc: 88.28%,  Val Loss:  0.34,  Val Acc: 89.45%,  Time: 0:00:23 *</span><br><span class="line">Iter:    500,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 89.96%,  Time: 0:00:29 *</span><br><span class="line">Iter:    600,  Train Loss:  0.36,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 89.63%,  Time: 0:00:33</span><br><span class="line">Iter:    700,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:   0.3,  Val Acc: 90.63%,  Time: 0:00:39 *</span><br><span class="line">Iter:    800,  Train Loss:  0.26,  Train Acc: 91.41%,  Val Loss:  0.29,  Val Acc: 91.21%,  Time: 0:00:44 *</span><br><span class="line">Iter:    900,  Train Loss:  0.47,  Train Acc: 87.50%,  Val Loss:  0.28,  Val Acc: 91.13%,  Time: 0:00:49 *</span><br><span class="line">Iter:   1000,  Train Loss:  0.28,  Train Acc: 89.84%,  Val Loss:  0.27,  Val Acc: 91.50%,  Time: 0:00:55 *</span><br><span class="line">Iter:   1100,  Train Loss:  0.33,  Train Acc: 90.62%,  Val Loss:  0.26,  Val Acc: 92.00%,  Time: 0:01:01 *</span><br><span class="line">Iter:   1200,  Train Loss:  0.51,  Train Acc: 86.72%,  Val Loss:  0.26,  Val Acc: 91.98%,  Time: 0:01:06</span><br><span class="line">Iter:   1300,  Train Loss:  0.28,  Train Acc: 88.28%,  Val Loss:  0.26,  Val Acc: 91.88%,  Time: 0:01:12 *</span><br><span class="line">Iter:   1400,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.26,  Val Acc: 91.82%,  Time: 0:01:16 *</span><br><span class="line">Epoch [2&#x2F;20]</span><br><span class="line">Iter:   1500,  Train Loss:   0.4,  Train Acc: 89.84%,  Val Loss:  0.25,  Val Acc: 92.30%,  Time: 0:01:22 *</span><br><span class="line">Iter:   1600,  Train Loss:  0.35,  Train Acc: 92.19%,  Val Loss:  0.25,  Val Acc: 92.14%,  Time: 0:01:28 *</span><br><span class="line">Iter:   1700,  Train Loss:  0.31,  Train Acc: 93.75%,  Val Loss:  0.25,  Val Acc: 92.26%,  Time: 0:01:33</span><br><span class="line">Iter:   1800,  Train Loss:  0.23,  Train Acc: 89.84%,  Val Loss:  0.26,  Val Acc: 91.56%,  Time: 0:01:39</span><br><span class="line">Iter:   1900,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.24,  Val Acc: 92.49%,  Time: 0:01:43 *</span><br><span class="line">Iter:   2000,  Train Loss:  0.33,  Train Acc: 91.41%,  Val Loss:  0.25,  Val Acc: 92.26%,  Time: 0:01:49</span><br><span class="line">Iter:   2100,  Train Loss:  0.31,  Train Acc: 92.97%,  Val Loss:  0.24,  Val Acc: 92.43%,  Time: 0:01:55 *</span><br><span class="line">Iter:   2200,  Train Loss:  0.27,  Train Acc: 93.75%,  Val Loss:  0.24,  Val Acc: 92.63%,  Time: 0:01:59 *</span><br><span class="line">Iter:   2300,  Train Loss:  0.22,  Train Acc: 93.75%,  Val Loss:  0.24,  Val Acc: 92.51%,  Time: 0:02:06</span><br><span class="line">Iter:   2400,  Train Loss:  0.26,  Train Acc: 91.41%,  Val Loss:  0.24,  Val Acc: 92.71%,  Time: 0:02:12</span><br><span class="line">Iter:   2500,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:  0.25,  Val Acc: 92.40%,  Time: 0:02:17</span><br><span class="line">Iter:   2600,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:  0.23,  Val Acc: 92.69%,  Time: 0:02:24 *</span><br><span class="line">Iter:   2700,  Train Loss:  0.23,  Train Acc: 93.75%,  Val Loss:  0.23,  Val Acc: 92.76%,  Time: 0:02:29</span><br><span class="line">Iter:   2800,  Train Loss:  0.24,  Train Acc: 92.97%,  Val Loss:  0.23,  Val Acc: 92.76%,  Time: 0:02:35 *</span><br><span class="line">Epoch [3&#x2F;20]</span><br><span class="line">Iter:   2900,  Train Loss:  0.13,  Train Acc: 96.09%,  Val Loss:  0.24,  Val Acc: 92.43%,  Time: 0:02:41</span><br><span class="line">Iter:   3000,  Train Loss:  0.17,  Train Acc: 92.19%,  Val Loss:  0.23,  Val Acc: 92.86%,  Time: 0:02:47</span><br><span class="line">Iter:   3100,  Train Loss:  0.21,  Train Acc: 94.53%,  Val Loss:  0.23,  Val Acc: 92.68%,  Time: 0:02:54</span><br><span class="line">Iter:   3200,  Train Loss:  0.14,  Train Acc: 95.31%,  Val Loss:  0.23,  Val Acc: 92.91%,  Time: 0:02:58 *</span><br><span class="line">Iter:   3300,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.24,  Val Acc: 92.83%,  Time: 0:03:05</span><br><span class="line">Iter:   3400,  Train Loss:  0.17,  Train Acc: 93.75%,  Val Loss:  0.24,  Val Acc: 92.75%,  Time: 0:03:10</span><br><span class="line">Iter:   3500,  Train Loss:  0.18,  Train Acc: 92.97%,  Val Loss:  0.23,  Val Acc: 93.05%,  Time: 0:03:16</span><br><span class="line">Iter:   3600,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.24,  Val Acc: 92.68%,  Time: 0:03:22</span><br><span class="line">Iter:   3700,  Train Loss:  0.13,  Train Acc: 96.09%,  Val Loss:  0.23,  Val Acc: 92.89%,  Time: 0:03:28</span><br><span class="line">Iter:   3800,  Train Loss:  0.21,  Train Acc: 92.19%,  Val Loss:  0.24,  Val Acc: 92.93%,  Time: 0:03:34</span><br><span class="line">Iter:   3900,  Train Loss:  0.13,  Train Acc: 95.31%,  Val Loss:  0.23,  Val Acc: 93.03%,  Time: 0:03:39</span><br><span class="line">Iter:   4000,  Train Loss:  0.26,  Train Acc: 92.97%,  Val Loss:  0.23,  Val Acc: 93.02%,  Time: 0:03:46</span><br><span class="line">Iter:   4100,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.24,  Val Acc: 92.72%,  Time: 0:03:52</span><br><span class="line">Iter:   4200,  Train Loss:  0.15,  Train Acc: 93.75%,  Val Loss:  0.24,  Val Acc: 92.88%,  Time: 0:03:58</span><br><span class="line">No optimization for a long time, auto-stopping...</span><br><span class="line">Test Loss:  0.23,  Test Acc: 92.71%</span><br><span class="line">Precision, Recall and F1-Score...</span><br><span class="line">               precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">      finance     0.9365    0.9000    0.9179      1000</span><br><span class="line">       realty     0.9260    0.9380    0.9319      1000</span><br><span class="line">       stocks     0.8817    0.9170    0.8990      1000</span><br><span class="line">    education     0.9568    0.9520    0.9544      1000</span><br><span class="line">      science     0.9192    0.8760    0.8971      1000</span><br><span class="line">      society     0.8951    0.8960    0.8956      1000</span><br><span class="line">     politics     0.9204    0.9130    0.9167      1000</span><br><span class="line">       sports     0.9732    0.9810    0.9771      1000</span><br><span class="line">         game     0.9360    0.9510    0.9435      1000</span><br><span class="line">entertainment     0.9275    0.9470    0.9372      1000</span><br><span class="line"></span><br><span class="line">     accuracy                         0.9271     10000</span><br><span class="line">    macro avg     0.9272    0.9271    0.9270     10000</span><br><span class="line"> weighted avg     0.9272    0.9271    0.9270     10000</span><br><span class="line"></span><br><span class="line">Confusion Matrix...</span><br><span class="line">[[900  18  57   0   5   9   7   0   0   4]</span><br><span class="line"> [  5 938  16   2   9  10   7   2   6   5]</span><br><span class="line"> [ 32  14 917   4  11   0  15   0   4   3]</span><br><span class="line"> [  1   2   3 952   1  20   9   0   0  12]</span><br><span class="line"> [  5   6  32   5 876  20  11   2  34   9]</span><br><span class="line"> [  5  18   0  19  18 896  20   3   3  18]</span><br><span class="line"> [  8   8   9   9   5  29 913   5   4  10]</span><br><span class="line"> [  2   3   1   0   2   1   2 981   0   8]</span><br><span class="line"> [  1   4   4   0  20   4   2   9 951   5]</span><br><span class="line"> [  2   2   1   4   6  12   6   6  14 947]]</span><br><span class="line">Time usage: 0:00:01</span><br><span class="line">finish train</span><br></pre></td></tr></table></figure><h1 id="4-è¯„ä»·"><a href="#4-è¯„ä»·" class="headerlink" title="4 è¯„ä»·"></a>4 è¯„ä»·</h1><h2 id="4-1-è¯„ä»·æŒ‡æ ‡"><a href="#4-1-è¯„ä»·æŒ‡æ ‡" class="headerlink" title="4.1 è¯„ä»·æŒ‡æ ‡"></a>4.1 è¯„ä»·æŒ‡æ ‡</h2><h2 id="4-2-ç»“æœæ±‡æ€»"><a href="#4-2-ç»“æœæ±‡æ€»" class="headerlink" title="4.2 ç»“æœæ±‡æ€»"></a>4.2 ç»“æœæ±‡æ€»</h2><blockquote><p>å‚è€ƒï¼š</p><p>[1] Convolutional Neural Networks for Sentence Classification<br>[2] Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification<br>[3] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding<br>[4] Attention Is All You Need</p><p><a href="https://github.com/649453932/Chinese-Text-Classification-Pytorch">https://github.com/649453932/Chinese-Text-Classification-Pytorch</a></p><p><a href="https://github.com/649453932/Bert-Chinese-Text-Classification-Pytorch">https://github.com/649453932/Bert-Chinese-Text-Classification-Pytorch</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;ä¸­æ–‡æ–‡æœ¬åˆ†ç±»æµç¨‹&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="research" scheme="http://example.com/categories/research/"/>
    
    <category term="text_classify" scheme="http://example.com/categories/research/text-classify/"/>
    
    
  </entry>
  
  <entry>
    <title>data_preprocess</title>
    <link href="http://example.com/2021/11/27/data-preprocess/"/>
    <id>http://example.com/2021/11/27/data-preprocess/</id>
    <published>2021-11-27T15:35:07.000Z</published>
    <updated>2021-11-27T15:57:49.457Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ä¸­è‹±æœºå™¨ç¿»è¯‘çš„æ•°æ®é¢„å¤„ç†æµç¨‹ï¼Œæš‚å­˜ä¸€ä¸‹çœ‹åˆ°çš„ä¼˜ç§€åšæ–‡ï¼Œè¿‡æ®µæ—¶é—´æ”¹æˆè‡ªç”¨ç‰ˆæœ¬ã€‚</p></blockquote><span id="more"></span><h1 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h1><p>æœ¬æ–‡åœ¨news-commentary-v15è¯­æ–™ä¸Šè®­ç»ƒäº†<strong>ä¸­è‹±NMTæ¨¡å‹</strong>ï¼Œå¹¶å°†æ•´ä¸ªæµç¨‹ï¼ŒåŒ…æ‹¬å·¥å…·å’Œæ•°æ®çš„å‡†å¤‡ã€æ•°æ®çš„é¢„å¤„ç†ã€è®­ç»ƒåŠè§£ç ï¼Œä»¥åŠä¸­é€”é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆè®°å½•åœ¨æ­¤ï¼Œå¸Œæœ›èƒ½å¤Ÿç»™äºˆåˆ«äººä¸€äº›å¸®åŠ©ã€‚</p><h1 id="1-ç›¸å…³å·¥å…·åŠç›®å½•ç»“æ„"><a href="#1-ç›¸å…³å·¥å…·åŠç›®å½•ç»“æ„" class="headerlink" title="1 ç›¸å…³å·¥å…·åŠç›®å½•ç»“æ„"></a>1 ç›¸å…³å·¥å…·åŠç›®å½•ç»“æ„</h1><h2 id="1-1-ç›¸å…³å·¥å…·"><a href="#1-1-ç›¸å…³å·¥å…·" class="headerlink" title="1.1 ç›¸å…³å·¥å…·"></a>1.1 ç›¸å…³å·¥å…·</h2><p>é™¤<strong>jieba</strong>æ˜¯ä½¿ç”¨<code>pip install</code>å®‰è£…å¤–ï¼Œå…¶ä»–å‡ ä¸ªå·¥å…·éƒ½æ˜¯å»ºè®®ç›´æ¥å…‹éš†åº“åˆ°è‡ªå·±çš„ç”¨æˆ·ç›®å½•ä¸­ï¼Œæ–¹ä¾¿ä½¿ç”¨å…¶è„šæœ¬(<strong>moses</strong>/<strong>subword-nmt</strong>)ï¼Œæˆ–æœªæ¥å¯èƒ½è¦è‡ªå·±æ‹“å±•å…¶ä¸­çš„æ¨¡å‹(<strong>fairseq</strong>)</p><ol><li><p>Moses (ä¸€ä¸ªSMTå·¥å…·ï¼Œåœ¨è¿™é‡Œåªä¼šç”¨åˆ°ä¸€äº›é¢„å¤„ç†è„šæœ¬ï¼Œå¦‚ï¼štokenisation,  truecasing, cleaning)ï¼Œå®‰è£…æŒ‡ä»¤å¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;moses-smt&#x2F;mosesdecoder.git</span><br></pre></td></tr></table></figure></li><li><p>subword-nmt (ä½¿ç”¨BPEç®—æ³•ç”Ÿæˆå­è¯çš„é¢„å¤„ç†è„šæœ¬)ï¼Œå®‰è£…æŒ‡ä»¤å¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;rsennrich&#x2F;subword-nmt.git</span><br></pre></td></tr></table></figure></li><li><p>jieba (ä¸­æ–‡åˆ†è¯ç»„ä»¶)ï¼Œå®‰è£…æŒ‡ä»¤å¦‚ä¸‹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install jieba</span><br></pre></td></tr></table></figure></li><li><p>fairseq (ä¸€ä¸ªåŸºäºPyTorchçš„åºåˆ—å»ºæ¨¡å·¥å…·)ï¼Œå®‰è£…æŒ‡ä»¤å¦‚ä¸‹ï¼š</p><p>fairseqå®‰è£…å‚è€ƒï¼š<a href="https://zhuanlan.zhihu.com/p/194176917">https://zhuanlan.zhihu.com/p/194176917</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;pytorch&#x2F;fairseq</span><br><span class="line">cd fairseq</span><br><span class="line">pip install --editable .&#x2F;</span><br></pre></td></tr></table></figure></li></ol><h2 id="1-2-ç›®å½•ç»“æ„ä¸åˆå§‹åŒ–"><a href="#1-2-ç›®å½•ç»“æ„ä¸åˆå§‹åŒ–" class="headerlink" title="1.2 ç›®å½•ç»“æ„ä¸åˆå§‹åŒ–"></a>1.2 ç›®å½•ç»“æ„ä¸åˆå§‹åŒ–</h2><h3 id="1-2-1-ç›®å½•ç»“æ„"><a href="#1-2-1-ç›®å½•ç»“æ„" class="headerlink" title="1.2.1 ç›®å½•ç»“æ„"></a>1.2.1 ç›®å½•ç»“æ„</h3><p>æå‰ç»„ç»‡ä¸€ä¸ªç›®å½•ç»“æ„çš„å¥½å¤„æ˜¯å¯ä»¥è®©åé¢çš„ä¸€ç³»åˆ—æ“ä½œæ›´åŠ ç»Ÿä¸€ã€è§„èŒƒåŒ–ã€‚ä¸‹è¡¨ä¸­<code>~</code>ä»£è¡¨linuxç³»ç»Ÿä¸­<strong>æˆ‘çš„ç”¨æˆ·ç›®å½•</strong>, v15newsç›®å½•åä»£è¡¨æ­¤æ¬¡æˆ‘ä½¿ç”¨çš„æ•°æ®é›†åç§°</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">~</span><br><span class="line">â”œâ”€â”€ mosesdecoder</span><br><span class="line">â”œâ”€â”€ subword-nmt</span><br><span class="line">â”œâ”€â”€ fairseq</span><br><span class="line">â””â”€â”€ nmt</span><br><span class="line">    â”œâ”€â”€ data</span><br><span class="line">        â””â”€â”€ v15news</span><br><span class="line">            â”œâ”€â”€ result          # ç”¨äºå­˜æ”¾ç¿»è¯‘ç»“æœ</span><br><span class="line">            â””â”€â”€ data-bin        # ç”¨äºå­˜æ”¾äºŒè¿›åˆ¶æ–‡ä»¶</span><br><span class="line">    â”œâ”€â”€ models                  # ç”¨äºä¿å­˜è¿‡ç¨‹ä¸­çš„modelæ–‡ä»¶å’Œcheckpoint</span><br><span class="line">        â””â”€â”€ v15news</span><br><span class="line">            â””â”€â”€ checkpoints     # ä¿å­˜checkpoints</span><br><span class="line">    â”œâ”€â”€ utils                   # ä¸€äº›å…¶ä»–å·¥å…·</span><br><span class="line">        â”œâ”€â”€ split.py            # ç”¨äºåˆ’åˆ†train,valid,test</span><br><span class="line">        â””â”€â”€ cut2.py             # ç”¨äºåˆ’åˆ†src,tgt</span><br><span class="line">    â””â”€â”€ scripts                 # ä¸€äº›è„šæœ¬</span><br></pre></td></tr></table></figure><h3 id="1-2-2-ç”¨äºåˆå§‹åŒ–çš„bashæ–‡ä»¶"><a href="#1-2-2-ç”¨äºåˆå§‹åŒ–çš„bashæ–‡ä»¶" class="headerlink" title="1.2.2 ç”¨äºåˆå§‹åŒ–çš„bashæ–‡ä»¶"></a>1.2.2 ç”¨äºåˆå§‹åŒ–çš„bashæ–‡ä»¶</h3><p>è¿™ä¸ªæ–‡ä»¶æ˜¯åœ¨ä¸Šè¿°ç›®å½•ç»“æ„çš„åŸºç¡€ä¸‹ï¼Œå®šä¹‰äº†ä¸€äº›åé¢éœ€è¦ç”¨åˆ°çš„å˜é‡(ä¸»è¦æ˜¯<strong>å„ç§è„šæœ¬çš„è·¯å¾„</strong>)ï¼ŒåŒ…æ‹¬tokenizer.perl, truecase.perlç­‰ï¼Œå¯ä»¥åœ¨linuxä¸­ä½¿ç”¨bash xx.shè¿è¡Œï¼Œä¹Ÿå¯ä»¥æŠŠè¿™äº›å†…å®¹ç›´æ¥å…¨éƒ¨å¤åˆ¶åˆ°linuxå‘½ä»¤è¡Œä¸­æŒ‰å›è½¦</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line"></span><br><span class="line">src&#x3D;zh</span><br><span class="line">tgt&#x3D;en</span><br><span class="line"></span><br><span class="line">SCRIPTS&#x3D;~&#x2F;mosesdecoder&#x2F;scripts</span><br><span class="line">TOKENIZER&#x3D;$&#123;SCRIPTS&#125;&#x2F;tokenizer&#x2F;tokenizer.perl</span><br><span class="line">DETOKENIZER&#x3D;$&#123;SCRIPTS&#125;&#x2F;tokenizer&#x2F;detokenizer.perl</span><br><span class="line">LC&#x3D;$&#123;SCRIPTS&#125;&#x2F;tokenizer&#x2F;lowercase.perl</span><br><span class="line">TRAIN_TC&#x3D;$&#123;SCRIPTS&#125;&#x2F;recaser&#x2F;train-truecaser.perl</span><br><span class="line">TC&#x3D;$&#123;SCRIPTS&#125;&#x2F;recaser&#x2F;truecase.perl</span><br><span class="line">DETC&#x3D;$&#123;SCRIPTS&#125;&#x2F;recaser&#x2F;detruecase.perl</span><br><span class="line">NORM_PUNC&#x3D;$&#123;SCRIPTS&#125;&#x2F;tokenizer&#x2F;normalize-punctuation.perl</span><br><span class="line">CLEAN&#x3D;$&#123;SCRIPTS&#125;&#x2F;training&#x2F;clean-corpus-n.perl</span><br><span class="line">BPEROOT&#x3D;~&#x2F;subword-nmt&#x2F;subword_nmt</span><br><span class="line">MULTI_BLEU&#x3D;$&#123;SCRIPTS&#125;&#x2F;generic&#x2F;multi-bleu.perl</span><br><span class="line">MTEVAL_V14&#x3D;$&#123;SCRIPTS&#125;&#x2F;generic&#x2F;mteval-v14.pl</span><br><span class="line"></span><br><span class="line">data_dir&#x3D;~&#x2F;nmt&#x2F;data&#x2F;v15news</span><br><span class="line">model_dir&#x3D;~&#x2F;nmt&#x2F;models&#x2F;v15news</span><br><span class="line">utils&#x3D;~&#x2F;nmt&#x2F;utils</span><br></pre></td></tr></table></figure><h1 id="2-æ•°æ®çš„å‡†å¤‡"><a href="#2-æ•°æ®çš„å‡†å¤‡" class="headerlink" title="2 æ•°æ®çš„å‡†å¤‡"></a>2 æ•°æ®çš„å‡†å¤‡</h1><h2 id="2-1-å¹³è¡Œè¯­æ–™"><a href="#2-1-å¹³è¡Œè¯­æ–™" class="headerlink" title="2.1 å¹³è¡Œè¯­æ–™"></a>2.1 å¹³è¡Œè¯­æ–™</h2><p>å¯¹äºæœ‰ç›‘ç£ç¥ç»æœºå™¨ç¿»è¯‘ï¼Œèƒ½å¤Ÿæ‰¾åˆ°çš„ä¸­è‹±å¹³è¡Œè¯­æ–™å¦‚ä¸‹ï¼š</p><ol><li><a href="https://github.com/NiuTrans/NiuTrans.SMT/tree/master/sample-data">NEU nlp lab å¼€æºè¯­æ–™</a> (10wï¼Œå›½å†…æ”¿æ²»æ–°é—»é¢†åŸŸ)</li><li><a href="http://www.statmt.org/wmt20/translation-task.html">WMTæ–°é—»ç¿»è¯‘ä»»åŠ¡News Commentaryè¯­æ–™</a> (32wå·¦å³ï¼Œå›½é™…æ–°é—»é¢†åŸŸã€‚å…¶å®News Commentaryæ¯å¹´éƒ½æœ‰æ–°é—»æ•°æ®é›†ï¼Œä½†æ˜¯åŸºæœ¬æ²¡å•¥å˜åŒ–ï¼Œæ¯æ¬¡åœ¨å‰ä¸€å¹´çš„åŸºç¡€ä¸ŠåŠ å‡ ç™¾å¥ï¼Œæ‰€ä»¥è¿™é‡Œçš„é“¾æ¥ç›´æ¥æŒ‡å‘æœ€æ–°çš„WMT20)</li><li><a href="https://catalog.ldc.upenn.edu/LDC2010T21">NISTæ•°æ®é›†</a> (200wå·¦å³ï¼Œéœ€è¦è´­ä¹°)</li><li><a href="https://conferences.unite.un.org/UNCORPUS/zh">United Nations Parallel Corpus</a> (1500wå·¦å³ï¼Œè”åˆå›½æ–‡ä»¶é¢†åŸŸ)</li></ol><p>æˆ‘æœ¬äººä½¿ç”¨è¿‡è¯­æ–™1ã€3ï¼Œå…¶ä¸­3æ˜¯è·Ÿå·²è´­ä¹°çš„å¸ˆå…„è¦çš„ï¼Œä¸å‘å¤–æä¾›ã€‚å…¶å®åˆæ¬¡è®­ç»ƒå»ºè®®ä½¿ç”¨è¯­æ–™1ï¼Œè§„æ¨¡å°è®­ç»ƒå¿«ï¼Œèƒ½å¤Ÿå¿«é€Ÿä½“éªŒæ•´ä¸ªæµç¨‹ã€‚å½“ç„¶ï¼Œä¸­è‹±è¿˜æœ‰å¾ˆå¤šå…¶ä»–è¯­æ–™ï¼Œè§<a href="https://chinesenlp.xyz/#/docs/machine_translation">å‚è€ƒèµ„æ–™1</a>, <a href="https://www.cluebenchmarks.com/dataSet_search.html">2</a></p><h2 id="2-2-æ•°æ®é¢„å¤„ç†"><a href="#2-2-æ•°æ®é¢„å¤„ç†" class="headerlink" title="2.2 æ•°æ®é¢„å¤„ç†"></a>2.2 æ•°æ®é¢„å¤„ç†</h2><h3 id="2-2-1-æ•°æ®æ ¼å¼"><a href="#2-2-1-æ•°æ®æ ¼å¼" class="headerlink" title="2.2.1 æ•°æ®æ ¼å¼"></a>2.2.1 æ•°æ®æ ¼å¼</h3><p>åœ¨æœ¬ç¯‡åšå®¢ä¸­ï¼Œæˆ‘å‡†å¤‡ä½¿ç”¨WMT20æ–°é—»ç¿»è¯‘ä»»åŠ¡çš„<strong>news-commentary-v15è¯­æ–™</strong>ï¼Œæ”¾äºä»¥ä¸‹ä½ç½®ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">â””â”€â”€ nmt</span><br><span class="line">    â”œâ”€â”€ data</span><br><span class="line">        â””â”€â”€ v15news     </span><br><span class="line">            â””â”€â”€ news-commentary-v15.en-zh.tsv</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>æ ¼å¼å¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1929 or 1989?1929å¹´è¿˜æ˜¯1989å¹´?</span><br><span class="line">PARIS â€“ As the economic crisis deepens and widens, the world has been searching for historical analogies to help us understand what has been happening.å·´é»-éšç€ç»æµå±æœºä¸æ–­åŠ æ·±å’Œè”“å»¶ï¼Œæ•´ä¸ªä¸–ç•Œä¸€ç›´åœ¨å¯»æ‰¾å†å²ä¸Šçš„ç±»ä¼¼äº‹ä»¶å¸Œæœ›æœ‰åŠ©äºæˆ‘ä»¬äº†è§£ç›®å‰æ­£åœ¨å‘ç”Ÿçš„æƒ…å†µã€‚</span><br><span class="line">At the start of the crisis, many people likened it to 1982 or 1973, which was reassuring, because both dates refer to classical cyclical downturns.ä¸€å¼€å§‹ï¼Œå¾ˆå¤šäººæŠŠè¿™æ¬¡å±æœºæ¯”ä½œ1982å¹´æˆ–1973å¹´æ‰€å‘ç”Ÿçš„æƒ…å†µï¼Œè¿™æ ·å¾—ç±»æ¯”æ˜¯ä»¤äººå®½å¿ƒçš„ï¼Œå› ä¸ºè¿™ä¸¤æ®µæ—¶æœŸæ„å‘³ç€å…¸å‹çš„å‘¨æœŸæ€§è¡°é€€ã€‚</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="2-2-2-åˆ‡åˆ†"><a href="#2-2-2-åˆ‡åˆ†" class="headerlink" title="2.2.2 åˆ‡åˆ†"></a>2.2.2 åˆ‡åˆ†</h3><p>é¦–å…ˆï¼Œéœ€è¦å°†ä¸€ä¸ªå•ç‹¬çš„æ•°æ®æ–‡ä»¶åˆ‡åˆ†æˆæ ‡å‡†æ ¼å¼ï¼Œå³æºè¯­è¨€(raw.zh)ã€ç›®æ ‡è¯­è¨€(raw.en)æ–‡ä»¶å„ä¸€ä¸ªï¼Œä¸€è¡Œä¸€å¥ï¼Œé™„è‡ªå·±å†™çš„è„šæœ¬(~/nmt/utils/cut2.py)ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">Usage: </span><br><span class="line">python cut2.py fpath new_data_dir</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">def cut2(fpath, new_data_dir, nsrc&#x3D;&#39;zh&#39;, ntgt&#x3D;&#39;en&#39;):</span><br><span class="line">    fp &#x3D; open(fpath, encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">    src_fp &#x3D; open(new_data_dir + &#39;raw.&#39; + nsrc, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">    tgt_fp &#x3D; open(new_data_dir + &#39;raw.&#39; + ntgt, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">    for line in fp.readlines():</span><br><span class="line">        tgt_line, src_line &#x3D; line.replace(&#39;\n&#39;, &#39;&#39;).split(&#39;\t&#39;)</span><br><span class="line">        src_fp.write(src_line + &#39;\n&#39;)</span><br><span class="line">        tgt_fp.write(tgt_line + &#39;\n&#39;)</span><br><span class="line">    src_fp.close()</span><br><span class="line">    tgt_fp.close()</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:      </span><br><span class="line">    cut2(fpath&#x3D;sys.argv[1], new_data_dir&#x3D;sys.argv[2], nsrc&#x3D;&#39;zh&#39;, ntgt&#x3D;&#39;en&#39;)</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python $&#123;utils&#125;&#x2F;cut2.py $&#123;data_dir&#125;&#x2F;news-commentary-v15.en-zh.tsv $&#123;data_dir&#125;&#x2F;</span><br></pre></td></tr></table></figure><p><strong>åæ³¨ï¼š</strong> åœ¨linuxé‡Œå¯ä»¥ç›´æ¥ç”¨cutå®ç° <code>cut -f 1 fpath &gt; new_data_dir/raw.en | cut -f 2 fpath &gt; new_data_dir/raw.zh</code></p><p>åˆ‡åˆ†åçš„æ–‡ä»¶åœ¨ç›®å½•ä¸­å¦‚ä¸‹æ ¼å¼å­˜æ”¾ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">â”œâ”€â”€ data</span><br><span class="line">    â””â”€â”€ v15news     </span><br><span class="line">        â”œâ”€â”€ news-commentary-v15.en-zh.tsv</span><br><span class="line">        â”œâ”€â”€ raw.zh</span><br><span class="line">        â””â”€â”€ raw.en</span><br></pre></td></tr></table></figure><h3 id="2-2-3-normalize-punctuation-å¯é€‰"><a href="#2-2-3-normalize-punctuation-å¯é€‰" class="headerlink" title="2.2.3 normalize-punctuation(å¯é€‰)"></a>2.2.3 normalize-punctuation(å¯é€‰)</h3><p>æ ‡ç‚¹ç¬¦å·çš„æ ‡å‡†åŒ–ï¼ŒåŒæ—¶å¯¹åŒè¯­æ–‡ä»¶(raw.en, raw.zh)å¤„ç†ï¼Œä½¿ç”¨å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">perl $&#123;NORM_PUNC&#125; -l en &lt; $&#123;data_dir&#125;&#x2F;raw.en &gt; $&#123;data_dir&#125;&#x2F;norm.en</span><br><span class="line">perl $&#123;NORM_PUNC&#125; -l zh &lt; $&#123;data_dir&#125;&#x2F;raw.zh &gt; $&#123;data_dir&#125;&#x2F;norm.zh</span><br></pre></td></tr></table></figure><p>å¤„ç†åçš„æ–‡ä»¶åœ¨ç›®å½•ä¸­å¦‚ä¸‹æ ¼å¼å­˜æ”¾ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">â”œâ”€â”€ data</span><br><span class="line">    â””â”€â”€ v15news     </span><br><span class="line">        ...</span><br><span class="line">        â”œâ”€â”€ norm.zh</span><br><span class="line">        â””â”€â”€ norm.en</span><br></pre></td></tr></table></figure><p>æ•ˆæœå¦‚ä¸‹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># raw.en</span><br><span class="line">â€œWe canâ€™t waste time,â€ he says.</span><br><span class="line">Yet, according to the political economist Moeletsi Mbeki, at his core, â€œZuma is a conservative.â€</span><br><span class="line"></span><br><span class="line"># norm.en</span><br><span class="line">&quot;We can&#39;t waste time,&quot; he says.</span><br><span class="line">Yet, according to the political economist Moeletsi Mbeki, at his core, &quot;Zuma is a conservative.&quot;</span><br></pre></td></tr></table></figure><h3 id="2-2-4-ä¸­æ–‡åˆ†è¯"><a href="#2-2-4-ä¸­æ–‡åˆ†è¯" class="headerlink" title="2.2.4 ä¸­æ–‡åˆ†è¯"></a>2.2.4 ä¸­æ–‡åˆ†è¯</h3><p>å¯¹æ ‡ç‚¹ç¬¦å·æ ‡å‡†åŒ–åçš„ä¸­æ–‡æ–‡ä»¶(norm.zh)è¿›è¡Œåˆ†è¯å¤„ç†ï¼Œä½¿ç”¨å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m jieba -d &quot; &quot; $&#123;data_dir&#125;&#x2F;norm.zh &gt; $&#123;data_dir&#125;&#x2F;norm.seg.zh</span><br></pre></td></tr></table></figure><p>å¤„ç†åçš„æ–‡ä»¶åœ¨ç›®å½•ä¸­å¦‚ä¸‹æ ¼å¼å­˜æ”¾ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">â”œâ”€â”€ data</span><br><span class="line">    â””â”€â”€ v15news     </span><br><span class="line">        ...</span><br><span class="line">        â””â”€â”€ norm.seg.zh</span><br></pre></td></tr></table></figure><p>æ•ˆæœå¦‚ä¸‹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># norm.zh</span><br><span class="line">1929å¹´è¿˜æ˜¯1989å¹´?</span><br><span class="line">å·´é»-éšç€ç»æµå±æœºä¸æ–­åŠ æ·±å’Œè”“å»¶ï¼Œæ•´ä¸ªä¸–ç•Œä¸€ç›´åœ¨å¯»æ‰¾å†å²ä¸Šçš„ç±»ä¼¼äº‹ä»¶å¸Œæœ›æœ‰åŠ©äºæˆ‘ä»¬äº†è§£ç›®å‰æ­£åœ¨å‘ç”Ÿçš„æƒ…å†µã€‚</span><br><span class="line">ä¸€å¼€å§‹ï¼Œå¾ˆå¤šäººæŠŠè¿™æ¬¡å±æœºæ¯”ä½œ1982å¹´æˆ–1973å¹´æ‰€å‘ç”Ÿçš„æƒ…å†µï¼Œè¿™æ ·å¾—ç±»æ¯”æ˜¯ä»¤äººå®½å¿ƒçš„ï¼Œå› ä¸ºè¿™ä¸¤æ®µæ—¶æœŸæ„å‘³ç€å…¸å‹çš„å‘¨æœŸæ€§è¡°é€€ã€‚</span><br><span class="line"></span><br><span class="line"># norm.seg.zh</span><br><span class="line">1929 å¹´ è¿˜æ˜¯ 1989 å¹´ ?</span><br><span class="line">å·´é» - éšç€ ç»æµå±æœº ä¸æ–­ åŠ æ·± å’Œ è”“å»¶ ï¼Œ æ•´ä¸ª ä¸–ç•Œ ä¸€ç›´ åœ¨ å¯»æ‰¾ å†å² ä¸Š çš„ ç±»ä¼¼ äº‹ä»¶ å¸Œæœ› æœ‰åŠ©äº æˆ‘ä»¬ äº†è§£ ç›®å‰ æ­£åœ¨ å‘ç”Ÿ çš„ æƒ…å†µ ã€‚</span><br><span class="line">ä¸€ å¼€å§‹ ï¼Œ å¾ˆå¤š äºº æŠŠ è¿™æ¬¡ å±æœº æ¯”ä½œ 1982 å¹´ æˆ– 1973 å¹´ æ‰€ å‘ç”Ÿ çš„ æƒ…å†µ ï¼Œ è¿™æ · å¾— ç±»æ¯” æ˜¯ ä»¤äºº å®½å¿ƒ çš„ ï¼Œ å› ä¸º è¿™ ä¸¤æ®µ æ—¶æœŸ æ„å‘³ç€ å…¸å‹ çš„ å‘¨æœŸæ€§ è¡°é€€ ã€‚</span><br></pre></td></tr></table></figure><h3 id="2-2-5-tokenize"><a href="#2-2-5-tokenize" class="headerlink" title="2.2.5 tokenize"></a>2.2.5 tokenize</h3><p>å¯¹ä¸Šè¿°å¤„ç†åçš„åŒè¯­æ–‡ä»¶(norm.en, norm.seg.zh)è¿›è¡Œæ ‡è®°åŒ–å¤„ç†ï¼Œæœ‰å¾ˆå¤šåŠŸèƒ½(1.å°†<strong>è‹±æ–‡å•è¯</strong>ä¸<strong>æ ‡ç‚¹ç¬¦å·</strong>ç”¨ç©ºæ ¼åˆ†å¼€ 2.å°†å¤šä¸ªè¿ç»­ç©ºæ ¼ç®€åŒ–ä¸ºä¸€ä¸ªç©ºæ ¼ 3.å°†å¾ˆå¤šç¬¦å·æ›¿æ¢æˆè½¬ä¹‰å­—ç¬¦ï¼Œå¦‚ï¼šæŠŠ<code>&quot;</code>æ›¿æ¢æˆ<code>&quot;</code>ã€æŠŠ<code>can&#39;t</code>æ›¿æ¢æˆ<code>can &#39;t</code>)ï¼Œä½¿ç”¨å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$&#123;TOKENIZER&#125; -l en &lt; $&#123;data_dir&#125;&#x2F;norm.en &gt; $&#123;data_dir&#125;&#x2F;norm.tok.en</span><br><span class="line">$&#123;TOKENIZER&#125; -l zh &lt; $&#123;data_dir&#125;&#x2F;norm.seg.zh &gt; $&#123;data_dir&#125;&#x2F;norm.seg.tok.zh</span><br></pre></td></tr></table></figure><p>å¤„ç†åçš„æ–‡ä»¶åœ¨ç›®å½•ä¸­å¦‚ä¸‹æ ¼å¼å­˜æ”¾ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">â”œâ”€â”€ data</span><br><span class="line">    â””â”€â”€ v15news     </span><br><span class="line">        ...</span><br><span class="line">        â”œâ”€â”€ norm.tok.en</span><br><span class="line">        â””â”€â”€ norm.seg.tok.zh</span><br></pre></td></tr></table></figure><p>æ•ˆæœå¦‚ä¸‹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># norm.seg.zh</span><br><span class="line">ç›®å‰ çš„ è¶‹åŠ¿ æ˜¯ ï¼Œ è¦ä¹ˆ æ˜¯ è¿‡åº¦ çš„ å…‹åˆ¶ ï¼ˆ æ¬§æ´²   ï¼‰   ï¼Œ   è¦ä¹ˆ æ˜¯ åŠªåŠ› çš„ æ‰©å±• ï¼ˆ ç¾å›½   ï¼‰   ã€‚</span><br><span class="line">è€Œ å†å² æ˜¯ ä¸ å…¬å¹³ çš„ ã€‚   å°½ç®¡ ç¾å›½ è¦ ä¸º å½“ä»Š çš„ å…¨çƒ å±æœº è´Ÿ æ›´ å¤§ çš„ è´£ä»» ï¼Œ ä½† ç¾å›½ å¯èƒ½ ä¼š æ¯” å¤§å¤šæ•° å›½å®¶ ä»¥ æ›´ è‰¯å¥½ çš„ åŠ¿æ€ èµ°å‡º å›°å¢ƒ ã€‚</span><br><span class="line"></span><br><span class="line"># norm.seg.tok.zh</span><br><span class="line">ç›®å‰ çš„ è¶‹åŠ¿ æ˜¯ ï¼Œ è¦ä¹ˆ æ˜¯ è¿‡åº¦ çš„ å…‹åˆ¶ ï¼ˆ æ¬§æ´² ï¼‰ ï¼Œ è¦ä¹ˆ æ˜¯ åŠªåŠ› çš„ æ‰©å±• ï¼ˆ ç¾å›½ ï¼‰ ã€‚</span><br><span class="line">è€Œ å†å² æ˜¯ ä¸ å…¬å¹³ çš„ ã€‚ å°½ç®¡ ç¾å›½ è¦ ä¸º å½“ä»Š çš„ å…¨çƒ å±æœº è´Ÿ æ›´ å¤§ çš„ è´£ä»» ï¼Œ ä½† ç¾å›½ å¯èƒ½ ä¼š æ¯” å¤§å¤šæ•° å›½å®¶ ä»¥ æ›´ è‰¯å¥½ çš„ åŠ¿æ€ èµ°å‡º å›°å¢ƒ ã€‚</span><br><span class="line"></span><br><span class="line"># norm.en</span><br><span class="line">&quot;We can&#39;t waste time,&quot; he says.</span><br><span class="line">Of course, the fall of the house of Lehman Brothers has nothing to do with the fall of the Berlin Wall.</span><br><span class="line">Second, Zoellick should ask why the Bank spends only 2.5% of its budget on the &quot;knowledge bank&quot; research function that it trumpets so proudly in its external relations materials, while it spends three times that amount on maintaining its executive board.</span><br><span class="line"></span><br><span class="line"># norm.tok.en</span><br><span class="line">&quot; We can &amp;apos;t waste time , &quot; he says .</span><br><span class="line">Of course , the fall of the house of Lehman Brothers has nothing to do with the fall of the Berlin Wall .</span><br><span class="line">Second , Zoellick should ask why the Bank spends only 2.5 % of its budget on the &quot; knowledge bank &quot; research function that it trumpets so proudly in its external relations materials , while it spends three times that amount on maintaining its executive board .</span><br></pre></td></tr></table></figure><h3 id="2-2-6-truecase"><a href="#2-2-6-truecase" class="headerlink" title="2.2.6 truecase"></a>2.2.6 truecase</h3><p>å¯¹ä¸Šè¿°å¤„ç†åçš„è‹±æ–‡æ–‡ä»¶(norm.tok.en)è¿›è¡Œå¤§å°å†™è½¬æ¢å¤„ç†(å¯¹äºå¥ä¸­çš„æ¯ä¸ªè‹±æ–‡å•è¯ï¼Œå°¤å…¶æ˜¯<strong>å¥é¦–å•è¯</strong>ï¼Œåœ¨æ•°æ®ä¸­<strong>å­¦ä¹ </strong>æœ€é€‚åˆå®ƒä»¬çš„å¤§å°å†™å½¢å¼)ï¼Œä½¿ç”¨å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$&#123;TRAIN_TC&#125; --model $&#123;model_dir&#125;&#x2F;truecase-model.en --corpus $&#123;data_dir&#125;&#x2F;norm.tok.en</span><br><span class="line">$&#123;TC&#125; --model $&#123;model_dir&#125;&#x2F;truecase-model.en &lt; $&#123;data_dir&#125;&#x2F;norm.tok.en &gt; $&#123;data_dir&#125;&#x2F;norm.tok.true.en</span><br></pre></td></tr></table></figure><p>å¤„ç†åçš„æ–‡ä»¶åœ¨ç›®å½•ä¸­å¦‚ä¸‹æ ¼å¼å­˜æ”¾ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">â”œâ”€â”€ data</span><br><span class="line">    â””â”€â”€ v15news</span><br><span class="line">        ...</span><br><span class="line">        â””â”€â”€ norm.tok.true.en</span><br><span class="line">â”œâ”€â”€ models</span><br><span class="line">    â””â”€â”€ v15news</span><br><span class="line">        â””â”€â”€ truecase-model.en</span><br></pre></td></tr></table></figure><p>æ•ˆæœå¦‚ä¸‹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># norm.tok.en</span><br><span class="line">PARIS - As the economic crisis deepens and widens , the world has been searching for historical analogies to help us understand what has been happening .</span><br><span class="line">At the start of the crisis , many people likened it to 1982 or 1973 , which was reassuring , because both dates refer to classical cyclical downturns .</span><br><span class="line">When the TTIP was first proposed , Europe seemed to recognize its value .</span><br><span class="line">Europe is being cautious in the name of avoiding debt and defending the euro , whereas the US has moved on many fronts in order not to waste an ideal opportunity to implement badly needed structural reforms .</span><br><span class="line"></span><br><span class="line"># norm.tok.true.en</span><br><span class="line">Paris - As the economic crisis deepens and widens , the world has been searching for historical analogies to help us understand what has been happening .</span><br><span class="line">at the start of the crisis , many people likened it to 1982 or 1973 , which was reassuring , because both dates refer to classical cyclical downturns .</span><br><span class="line">when the TTIP was first proposed , Europe seemed to recognize its value .</span><br><span class="line">Europe is being cautious in the name of avoiding debt and defending the euro , whereas the US has moved on many fronts in order not to waste an ideal opportunity to implement badly needed structural reforms .</span><br></pre></td></tr></table></figure><h3 id="2-2-7-bpe"><a href="#2-2-7-bpe" class="headerlink" title="2.2.7 bpe"></a>2.2.7 bpe</h3><p>å¯¹ä¸Šè¿°å¤„ç†åçš„åŒè¯­æ–‡ä»¶(norm.tok.true.en, norm.seg.tok.zh)è¿›è¡Œå­è¯å¤„ç†(å¯ä»¥ç†è§£ä¸ºæ›´ç»†ç²’åº¦çš„åˆ†è¯)ï¼Œä½¿ç”¨å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python $&#123;BPEROOT&#125;&#x2F;learn_joint_bpe_and_vocab.py --input $&#123;data_dir&#125;&#x2F;norm.tok.true.en  -s 32000 -o $&#123;model_dir&#125;&#x2F;bpecode.en --write-vocabulary $&#123;model_dir&#125;&#x2F;voc.en</span><br><span class="line">python $&#123;BPEROOT&#125;&#x2F;apply_bpe.py -c $&#123;model_dir&#125;&#x2F;bpecode.en --vocabulary $&#123;model_dir&#125;&#x2F;voc.en &lt; $&#123;data_dir&#125;&#x2F;norm.tok.true.en &gt; $&#123;data_dir&#125;&#x2F;norm.tok.true.bpe.en</span><br><span class="line"></span><br><span class="line">python $&#123;BPEROOT&#125;&#x2F;learn_joint_bpe_and_vocab.py --input $&#123;data_dir&#125;&#x2F;norm.seg.tok.zh  -s 32000 -o $&#123;model_dir&#125;&#x2F;bpecode.zh --write-vocabulary $&#123;model_dir&#125;&#x2F;voc.zh</span><br><span class="line">python $&#123;BPEROOT&#125;&#x2F;apply_bpe.py -c $&#123;model_dir&#125;&#x2F;bpecode.zh --vocabulary $&#123;model_dir&#125;&#x2F;voc.zh &lt; $&#123;data_dir&#125;&#x2F;norm.seg.tok.zh &gt; $&#123;data_dir&#125;&#x2F;norm.seg.tok.bpe.zh</span><br></pre></td></tr></table></figure><p>å¤„ç†åçš„æ–‡ä»¶åœ¨ç›®å½•ä¸­å¦‚ä¸‹æ ¼å¼å­˜æ”¾ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">â”œâ”€â”€ data</span><br><span class="line">    â””â”€â”€ v15news</span><br><span class="line">        ...</span><br><span class="line">        â”œâ”€â”€ norm.seg.tok.bpe.zh</span><br><span class="line">        â””â”€â”€ norm.tok.true.bpe.en</span><br><span class="line">â”œâ”€â”€ models</span><br><span class="line">    â””â”€â”€ v15news</span><br><span class="line">        ...</span><br><span class="line">        â”œâ”€â”€ voc.zh</span><br><span class="line">        â”œâ”€â”€ voc.en</span><br><span class="line">        â”œâ”€â”€ bpecode.zh</span><br><span class="line">        â””â”€â”€ bpecode.en</span><br></pre></td></tr></table></figure><p>æ•ˆæœå¦‚ä¸‹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># norm.seg.tok.zh</span><br><span class="line">ä» ä¸€æµ çš„ éº»çœç†å·¥å­¦é™¢ çš„ åª’ä½“ å®éªŒå®¤ åˆ° å“ˆä½›å¤§å­¦ çš„ æ•°å­¦ å’Œ ç»æµç³» ï¼Œ äºšæ´² äºº - å°¤å…¶ æ˜¯ ä¸­å›½ å’Œ å°åº¦äºº - åˆ°å¤„ éƒ½ æ˜¯ ï¼Œ çŠ¹å¦‚ å…¬å…ƒå‰ ä¸€ ä¸–çºª åœ¨ é›…å…¸ çš„ ç½—é©¬ äºº ä¸€æ · ï¼š ä»–ä»¬ å¯¹ é‚£é‡Œ å­¦åˆ° å¤ª å¤š ä¸œè¥¿ çš„ äººä»¬ å……æ»¡ äº† æ•¬ä½© ï¼Œ è€Œ ä»–ä»¬ å°† åœ¨ ä»Šå å‡ åå¹´ æ‰“è´¥ ä»–ä»¬ å­¦ä¹  çš„ å¯¹è±¡ ã€‚</span><br><span class="line">è¿™ ä¸ä»… åŠ å¤§ äº† é¢„é˜² å±æœº çš„ éš¾åº¦ - - å°¤å…¶ å› ä¸º å®ƒ ä¸º å‚ä¸è€… æä¾› äº† é’»ç©ºå­ å’Œ é€ƒé¿è´£ä»» çš„ æœºä¼š - - è¿˜ ä½¿å¾— äººä»¬ è¶Šæ¥è¶Š éš¾ä»¥ é‡‡å–æªæ–½ æ¥ åº”å¯¹ å±æœº ã€‚</span><br><span class="line">å®ƒä»¬ å°† é€šèƒ€ ç›®æ ‡ è®¾å®š åœ¨ 2 % å·¦å³ - - è¿™ æ„å‘³ç€ å½“ æ³¢æ¶›æ±¹æ¶Œ æ—¶ ä»–ä»¬ æ ¹æœ¬ æ²¡æœ‰ å¤šå°‘ æ–½å±• ç©ºé—´ ã€‚</span><br><span class="line"></span><br><span class="line"># norm.seg.tok.bpe.zh</span><br><span class="line">ä» ä¸€æµ çš„ éº»çœç†å·¥å­¦é™¢ çš„ åª’ä½“ å®éªŒå®¤ åˆ° å“ˆä½›å¤§å­¦ çš„ æ•°å­¦ å’Œ ç»æµ@@ ç³» ï¼Œ äºšæ´² äºº - å°¤å…¶ æ˜¯ ä¸­å›½ å’Œ å°åº¦äºº - åˆ°å¤„ éƒ½ æ˜¯ ï¼Œ çŠ¹å¦‚ å…¬å…ƒå‰ ä¸€ ä¸–çºª åœ¨ é›…å…¸ çš„ ç½—é©¬ äºº ä¸€æ · ï¼š ä»–ä»¬ å¯¹ é‚£é‡Œ å­¦åˆ° å¤ª å¤š ä¸œè¥¿ çš„ äººä»¬ å……æ»¡ äº† æ•¬ä½© ï¼Œ è€Œ ä»–ä»¬ å°† åœ¨ ä»Šå å‡ åå¹´ æ‰“è´¥ ä»–ä»¬ å­¦ä¹  çš„ å¯¹è±¡ ã€‚</span><br><span class="line">è¿™ ä¸ä»… åŠ å¤§ äº† é¢„é˜² å±æœº çš„ éš¾åº¦ - - å°¤å…¶ å› ä¸º å®ƒ ä¸º å‚ä¸è€… æä¾› äº† é’»@@ ç©ºå­ å’Œ é€ƒé¿@@ è´£ä»» çš„ æœºä¼š - - è¿˜ ä½¿å¾— äººä»¬ è¶Šæ¥è¶Š éš¾ä»¥ é‡‡å–æªæ–½ æ¥ åº”å¯¹ å±æœº ã€‚</span><br><span class="line">å®ƒä»¬ å°† é€šèƒ€ ç›®æ ‡ è®¾å®š åœ¨ 2 % å·¦å³ - - è¿™ æ„å‘³ç€ å½“ æ³¢@@ æ¶›@@ æ±¹æ¶Œ æ—¶ ä»–ä»¬ æ ¹æœ¬ æ²¡æœ‰ å¤šå°‘ æ–½å±• ç©ºé—´ ã€‚</span><br><span class="line"></span><br><span class="line"># norm.tok.true.en</span><br><span class="line">indeed , on the surface it seems to be its perfect antithesis : the collapse of a wall symbolizing oppression and artificial divisions versus the collapse of a seemingly indestructible and reassuring institution of financial capitalism .</span><br><span class="line">as a visiting professor at Harvard and MIT , I am getting a good preview of what the world could look like when the crisis finally passes .</span><br><span class="line">one senses something like the making of an American-Asian dominated universe .</span><br><span class="line"></span><br><span class="line"># norm.tok.true.bpe.en</span><br><span class="line">indeed , on the surface it seems to be its perfect anti@@ thesis : the collapse of a wall symboli@@ zing oppression and artificial divisions versus the collapse of a seemingly inde@@ struc@@ tible and reassuring institution of financial capitalism .</span><br><span class="line">as a visiting professor at Harvard and MIT , I am getting a good pre@@ view of what the world could look like when the crisis finally passes .</span><br><span class="line">one senses something like the making of an American-@@ Asian dominated universe .</span><br></pre></td></tr></table></figure><blockquote><p><strong>åæ³¨ï¼š</strong><br>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä¸ºäº†æ–¹ä¾¿ï¼Œæ­¥éª¤ä¸Šå¤±å»äº†ä¸€äº›æ­£ç¡®æ€§ã€‚æ­£ç¡®çš„åšæ³•åº”è¯¥æ˜¯åœ¨<strong>è®­ç»ƒé›†</strong>ä¸­å­¦ä¹ bpeæ¨¡å‹ï¼Œå†å°†bpeæ¨¡å‹åº”ç”¨åˆ°<strong>æµ‹è¯•é›†</strong>å’Œ<strong>éªŒè¯é›†</strong>ä¸­ã€‚è€Œæˆ‘æ˜¯ç›´æ¥åœ¨å…¨éƒ¨æ•°æ®ä¸­å­¦bpeæ¨¡å‹äº†ã€‚</p></blockquote><h3 id="2-2-8-clean"><a href="#2-2-8-clean" class="headerlink" title="2.2.8 clean"></a>2.2.8 clean</h3><p>å¯¹ä¸Šè¿°å¤„ç†åçš„åŒè¯­æ–‡ä»¶(norm.tok.true.bpe.en, norm.seg.tok.bpe.zh)è¿›è¡Œè¿‡æ»¤(å¯ä»¥è¿‡æ»¤<strong>æœ€å°é•¿åº¦</strong>å’Œ<strong>æœ€å¤§é•¿åº¦</strong>ä¹‹é—´çš„å¥å¯¹ï¼Œè¿™æ ·èƒ½å¤Ÿæœ‰æ•ˆè¿‡æ»¤ç©ºç™½è¡Œã€‚è¿˜å¯ä»¥è¿‡æ»¤<strong>é•¿åº¦æ¯”</strong>ä¸åˆç†çš„å¥å¯¹)ï¼Œä½¿ç”¨å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mv $&#123;data_dir&#125;&#x2F;norm.seg.tok.bpe.zh $&#123;data_dir&#125;&#x2F;toclean.zh</span><br><span class="line">mv $&#123;data_dir&#125;&#x2F;norm.tok.true.bpe.en $&#123;data_dir&#125;&#x2F;toclean.en </span><br><span class="line">$&#123;CLEAN&#125; $&#123;data_dir&#125;&#x2F;toclean zh en $&#123;data_dir&#125;&#x2F;clean 1 256</span><br></pre></td></tr></table></figure><p>å¤„ç†åçš„æ–‡ä»¶åœ¨ç›®å½•ä¸­å¦‚ä¸‹æ ¼å¼å­˜æ”¾ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">â”œâ”€â”€ data</span><br><span class="line">    â””â”€â”€ v15news</span><br><span class="line">        ...</span><br><span class="line">        â”œâ”€â”€ clean.zh</span><br><span class="line">        â””â”€â”€ clean.en</span><br></pre></td></tr></table></figure><p>æ•ˆæœå¦‚ä¸‹(æ¯è¡Œæœ€å¼€å§‹æ ‡å‡ºäº†<strong>è¡Œå·</strong>):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># norm.tok.true.bpe.en</span><br><span class="line">30 we can only hope that , in the end , the consequences of 2009 similarly prove to be far less dramatic than we now - intuitively and in our historical refle@@ xes - feel them to be .</span><br><span class="line">31</span><br><span class="line">32 one Hund@@ red Years of Ine@@ p@@ titude</span><br><span class="line"></span><br><span class="line"># clean.en</span><br><span class="line">30 we can only hope that , in the end , the consequences of 2009 similarly prove to be far less dramatic than we now - intuitively and in our historical refle@@ xes - feel them to be .</span><br><span class="line">31 one Hund@@ red Years of Ine@@ p@@ titude</span><br><span class="line">32 Berlin - The global financial and economic crisis that began in 2008 was the greatest economic stre@@ ss-@@ test since the Great Depression , and the greatest challenge to social and political systems since World War II .</span><br><span class="line"></span><br><span class="line"># norm.seg.tok.bpe.zh</span><br><span class="line">30 æˆ‘ä»¬ åªèƒ½ å¸Œæœ› 2009 å¹´ çš„ å±æœº åŒæ · åœ° æœ€å è¢« è¯æ˜ æ˜¯ è¿œè¿œ ä½äº æˆ‘ä»¬ ç°åœ¨ ä»¥ ç›´è§‰ å’Œ å†å² å›é¡¾ çš„ æ–¹å¼ ï¿½ ï¿½ æ„Ÿè§‰ åˆ° çš„ é‚£ä¹ˆ å‰§çƒˆ ã€‚</span><br><span class="line">31 </span><br><span class="line">32 ç™¾å¹´ æ„š@@ é¡½</span><br><span class="line"></span><br><span class="line"># clean.zh</span><br><span class="line">30 æˆ‘ä»¬ åªèƒ½ å¸Œæœ› 2009 å¹´ çš„ å±æœº åŒæ · åœ° æœ€å è¢« è¯æ˜ æ˜¯ è¿œè¿œ ä½äº æˆ‘ä»¬ ç°åœ¨ ä»¥ ç›´è§‰ å’Œ å†å² å›é¡¾ çš„ æ–¹å¼ ï¿½ ï¿½ æ„Ÿè§‰ åˆ° çš„ é‚£ä¹ˆ å‰§çƒˆ ã€‚</span><br><span class="line">31 ç™¾å¹´ æ„š@@ é¡½</span><br><span class="line">32 æŸæ— - - 2008 å¹´ çˆ†å‘ çš„ å…¨çƒ é‡‘è å’Œ ç»æµå±æœº æ˜¯ è‡ªå¤§ è§æ¡ ä»¥æ¥ æœ€ ä¸¥å³» çš„ ä¸€æ¬¡ ç»æµ å‹åŠ› æµ‹è¯• ï¼Œ ä¹Ÿ æ˜¯ è‡ª äºŒæˆ˜ ä»¥æ¥ ç¤¾ä¼š å’Œ æ”¿æ²» åˆ¶åº¦ æ‰€ é¢ä¸´ çš„ æœ€ ä¸¥é‡ æŒ‘æˆ˜ ã€‚</span><br></pre></td></tr></table></figure><h3 id="2-2-9-split"><a href="#2-2-9-split" class="headerlink" title="2.2.9 split"></a>2.2.9 split</h3><p>æœ€åï¼ŒåŒè¯­æ–‡ä»¶(clean.zh, clean.en)éƒ½éœ€è¦æŒ‰æ¯”ä¾‹åˆ’åˆ†å‡ºè®­ç»ƒé›†ã€æµ‹è¯•é›†ã€å¼€å‘é›†(æ‰€ä»¥å…±6ä¸ªæ–‡ä»¶ï¼Œä¸ºæ–¹ä¾¿åŒºåˆ†ï¼Œç›´æ¥ä»¥ â€˜train.enâ€™, â€˜valid.zhâ€™ è¿™æ ·çš„æ ¼å¼å‘½å)ï¼Œé™„è‡ªå·±å†™çš„è„šæœ¬(~/nmt/utils/split.py)ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">Usage:</span><br><span class="line">python split.py src_fpath tgt_fpath new_data_dir</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">def split(src_fpath, tgt_fpath, nsrc&#x3D;&#39;zh&#39;, ntgt&#x3D;&#39;en&#39;, ratio&#x3D;(0.9, 0.05, 0.05), new_data_dir&#x3D;&#39;&#39;):</span><br><span class="line">  src_fp &#x3D; open(src_fpath, encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">  tgt_fp &#x3D; open(tgt_fpath, encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">  </span><br><span class="line">  src_train, src_test, src_val &#x3D; open(new_data_dir + &#39;train.&#39; + nsrc, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;), \</span><br><span class="line">    open(new_data_dir + &#39;test.&#39; + nsrc, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;), open(new_data_dir + &#39;valid.&#39; + nsrc, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">  tgt_train, tgt_test, tgt_val &#x3D; open(new_data_dir + &#39;train.&#39; + ntgt, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;), \</span><br><span class="line">    open(new_data_dir + &#39;test.&#39; + ntgt, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;), open(new_data_dir + &#39;valid.&#39; + ntgt, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">  </span><br><span class="line">  src, tgt &#x3D; src_fp.readlines(), tgt_fp.readlines()</span><br><span class="line">  for s, t in zip(src, tgt):</span><br><span class="line">      rand &#x3D; random.random()</span><br><span class="line">      if 0 &lt; rand &lt;&#x3D; ratio[0]:</span><br><span class="line">        src_train.write(s)</span><br><span class="line">        tgt_train.write(t)</span><br><span class="line">      elif ratio[0] &lt; rand &lt;&#x3D; ratio[0] + ratio[1]:</span><br><span class="line">        src_test.write(s)</span><br><span class="line">        tgt_test.write(t)</span><br><span class="line">      else:</span><br><span class="line">        src_val.write(s)</span><br><span class="line">        tgt_val.write(t)</span><br><span class="line">  </span><br><span class="line">  src_fp.close()</span><br><span class="line">  tgt_fp.close()</span><br><span class="line">  src_train.close()</span><br><span class="line">  src_test.close()</span><br><span class="line">  src_val.close()</span><br><span class="line">  tgt_train.close()</span><br><span class="line">  tgt_test.close()</span><br><span class="line">  tgt_val.close()</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:      </span><br><span class="line">    split(src_fpath&#x3D;sys.argv[1], tgt_fpath&#x3D;sys.argv[2], nsrc&#x3D;&#39;zh&#39;, ntgt&#x3D;&#39;en&#39;, ratio&#x3D;(0.95, 0.025, 0.025), new_data_dir&#x3D;sys.argv[3])</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python $&#123;utils&#125;&#x2F;split.py $&#123;data_dir&#125;&#x2F;clean.zh $&#123;data_dir&#125;&#x2F;clean.en $&#123;data_dir&#125;&#x2F;</span><br></pre></td></tr></table></figure><p>æœ€åï¼Œdata/v15newsç›®å½•ä¸­æœ‰å¦‚ä¸‹æ•°æ®ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">â”œâ”€â”€ data</span><br><span class="line">    â””â”€â”€ v15news</span><br><span class="line">        ...</span><br><span class="line">        â”œâ”€â”€ test.en</span><br><span class="line">        â”œâ”€â”€ test.zh</span><br><span class="line">        â”œâ”€â”€ train.en</span><br><span class="line">        â”œâ”€â”€ train.zh</span><br><span class="line">        â”œâ”€â”€ valid.en</span><br><span class="line">        â””â”€â”€ valid.zh</span><br></pre></td></tr></table></figure><h1 id="3-è®­ç»ƒè¿‡ç¨‹"><a href="#3-è®­ç»ƒè¿‡ç¨‹" class="headerlink" title="3 è®­ç»ƒè¿‡ç¨‹"></a>3 è®­ç»ƒè¿‡ç¨‹</h1><h2 id="3-1-ç”Ÿæˆè¯è¡¨åŠäºŒè¿›åˆ¶æ–‡ä»¶"><a href="#3-1-ç”Ÿæˆè¯è¡¨åŠäºŒè¿›åˆ¶æ–‡ä»¶" class="headerlink" title="3.1 ç”Ÿæˆè¯è¡¨åŠäºŒè¿›åˆ¶æ–‡ä»¶"></a>3.1 ç”Ÿæˆè¯è¡¨åŠäºŒè¿›åˆ¶æ–‡ä»¶</h2><p>é¦–å…ˆç”¨é¢„å¤„ç†åçš„å…­ä¸ªæ–‡ä»¶(train.zh, valid.enç­‰)ï¼Œä½¿ç”¨<code>fairseq-preprocess</code>å‘½ä»¤ç”Ÿæˆ<strong>è¯è¡¨</strong>å’Œ<strong>è®­ç»ƒç”¨çš„äºŒè¿›åˆ¶æ–‡ä»¶</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fairseq-preprocess --source-lang $&#123;src&#125; --target-lang $&#123;tgt&#125; \</span><br><span class="line">    --trainpref $&#123;data_dir&#125;&#x2F;train --validpref $&#123;data_dir&#125;&#x2F;valid --testpref $&#123;data_dir&#125;&#x2F;test \</span><br><span class="line">    --destdir $&#123;data_dir&#125;&#x2F;data-bin</span><br></pre></td></tr></table></figure><p>ç”Ÿæˆçš„æ–‡ä»¶éƒ½ä¿å­˜åœ¨data-binç›®å½•ä¸­</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">â”œâ”€â”€ data</span><br><span class="line">    â””â”€â”€ v15news</span><br><span class="line">        ...</span><br><span class="line">        â””â”€â”€ data-bin</span><br><span class="line">            â”œâ”€â”€ dict.zh</span><br><span class="line">            â”œâ”€â”€ dict.en</span><br><span class="line">            â”œâ”€â”€ preprocess.log</span><br><span class="line">            â”œâ”€â”€ train.zh-en.zh.idx</span><br><span class="line">            ...</span><br><span class="line">            â””â”€â”€ valid.zh-en.en.bin</span><br></pre></td></tr></table></figure><p>éœ€è¦æé†’çš„æ˜¯ï¼šè®­ç»ƒé˜¶æ®µä½¿ç”¨çš„æ˜¯<strong>è®­ç»ƒé›†</strong>å’Œ<strong>éªŒè¯é›†</strong>ï¼Œè§£ç é˜¶æ®µä½¿ç”¨çš„æ˜¯<strong>æµ‹è¯•é›†</strong></p><h2 id="3-2-è®­ç»ƒ"><a href="#3-2-è®­ç»ƒ" class="headerlink" title="3.2 è®­ç»ƒ"></a>3.2 è®­ç»ƒ</h2><p>ä½¿ç”¨<code>fairseq-train</code>å‘½ä»¤è¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­æœ‰å¾ˆå¤šå¯ä»¥è‡ªç”±è®¾ç½®çš„è¶…å‚æ•°ï¼Œæ¯”å¦‚é€‰æ‹©ä½¿ç”¨ä»€ä¹ˆæ¨¡å‹ï¼Œæ¨¡å‹çš„å‚æ•°ç­‰ã€‚å…¶ä¸­ï¼Œ<code>--save-dir</code> è¿™ä¸ªå‚æ•°æ˜¯æŒ‡æ¯ä¸€ä¸ªepochç»“æŸåæ¨¡å‹ä¿å­˜çš„ä½ç½®</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES&#x3D;0,1,2,3 nohup fairseq-train $&#123;data_dir&#125;&#x2F;data-bin --arch transformer \</span><br><span class="line">--source-lang $&#123;src&#125; --target-lang $&#123;tgt&#125;  \</span><br><span class="line">    --optimizer adam  --lr 0.001 --adam-betas &#39;(0.9, 0.98)&#39; \</span><br><span class="line">    --lr-scheduler inverse_sqrt --max-tokens 4096  --dropout 0.3 \</span><br><span class="line">    --criterion label_smoothed_cross_entropy  --label-smoothing 0.1 \</span><br><span class="line">    --max-update 200000  --warmup-updates 4000 --warmup-init-lr &#39;1e-07&#39; \</span><br><span class="line">    --keep-last-epochs 10 --num-workers 8 \</span><br><span class="line">--save-dir $&#123;model_dir&#125;&#x2F;checkpoints &amp;</span><br></pre></td></tr></table></figure><p>æˆ‘è‡ªå·±è®­ç»ƒæ—¶æ˜¯åœ¨3å—GTX TITAN Xå¡ä¸Šè·‘äº†6ä¸ªå°æ—¶ï¼Œå…±è·‘äº†49ä¸ªepochï¼Œä½†æ˜¯åœ¨ç¬¬22ä¸ªepochçš„æ—¶å€™å·²ç»æ”¶æ•›(åªéœ€è¦çœ‹éªŒè¯é›†ä¸Šçš„pplçš„å˜åŒ–å³å¯)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">epoch 020 | valid on &#39;valid&#39; subset | loss 4.366 | nll_loss 2.652 | ppl 6.29 | wps 50387.3 | wpb 8026 | bsz 299.8 | num_updates 14400 | best_loss 4.366</span><br><span class="line">epoch 021 | valid on &#39;valid&#39; subset | loss 4.36 | nll_loss 2.647 | ppl 6.27 | wps 51992.7 | wpb 8026 | bsz 299.8 | num_updates 15120 | best_loss 4.36</span><br><span class="line">epoch 022 | valid on &#39;valid&#39; subset | loss 4.361 | nll_loss 2.644 | ppl 6.25 | wps 49009.9 | wpb 8026 | bsz 299.8 | num_updates 15840 | best_loss 4.36</span><br><span class="line">epoch 023 | valid on &#39;valid&#39; subset | loss 4.369 | nll_loss 2.65 | ppl 6.28 | wps 51878.9 | wpb 8026 | bsz 299.8 | num_updates 16560 | best_loss 4.36</span><br><span class="line">epoch 023 | valid on &#39;valid&#39; subset | loss 4.369 | nll_loss 2.65 | ppl 6.28 | wps 51878.9 | wpb 8026 | bsz 299.8 | num_updates 16560 | best_loss 4.36</span><br></pre></td></tr></table></figure><p>ç”±äº<code>--keep-last-epochs</code>è¿™ä¸ªå‚æ•°æˆ‘è®¾ä¸º10ï¼Œæ‰€ä»¥æˆ‘æœ€å10ä¸ªepochçš„æ¨¡å‹éƒ½ä¿å­˜åœ¨ä»¥ä¸‹ç›®å½•ä¸­ã€‚æ­¤å¤–ï¼Œè¿˜ä¼šé¢å¤–ä¿å­˜æ•ˆæœæœ€å¥½çš„æ¨¡å‹(å³ç¬¬22ä¸ªepoch)å’Œæœ€åä¸€ä¸ªæ¨¡å‹(å³ç¬¬49ä¸ªepochï¼Œå¯ä»¥ç”¨äºä¸‹ä¸€æ¬¡è®­ç»ƒ)ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">â”œâ”€â”€ models</span><br><span class="line">    â””â”€â”€ v15news</span><br><span class="line">        ...</span><br><span class="line">        â””â”€â”€ checkpoints</span><br><span class="line">            â”œâ”€â”€ checkpoint40.pt</span><br><span class="line">            ...</span><br><span class="line">            â”œâ”€â”€ checkpoint49.pt</span><br><span class="line">            â”œâ”€â”€ checkpoint_best.pt</span><br><span class="line">            â””â”€â”€ checkpoint_last.pt</span><br></pre></td></tr></table></figure><h2 id="3-3-è§£ç "><a href="#3-3-è§£ç " class="headerlink" title="3.3 è§£ç "></a>3.3 è§£ç </h2><p>fairseqä¸­æ”¯æŒä¸¤ç§è§£ç å‘½ä»¤<code>generate</code>å’Œ<code>interactive</code>ã€‚</p><p>å…¶åŒºåˆ«å¾ˆç®€å•ï¼Œ<code>generate</code>ä½¿ç”¨<strong>äºŒè¿›åˆ¶æ–‡ä»¶</strong>ï¼Œè¿™ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶æ˜¯åœ¨<code>fairseq-preprocess</code>è¿‡ç¨‹ç”Ÿæˆçš„ï¼Œå½“æ—¶æä¾›äº†ä¸€ä¸ª<code>testpref</code>å‚æ•°ã€‚ä¹Ÿå°±æ˜¯è¯´æµ‹è¯•é›†çš„srcå’Œtgtéƒ½æ˜¯å·²è·å¾—çš„ï¼Œè¿™ç§åœºæ™¯ç¬¦åˆè‡ªå·±åœ¨å…¬å¼€çš„æ•°æ®é›†ä¸Šåšå®éªŒï¼ˆå¦‚WMT14en-deï¼‰ï¼Œéœ€è¦åœ¨è®ºæ–‡ä¸­æŠ¥å‘Šæµ‹è¯•é›†ç»“æœã€‚</p><p>è€Œ<code>interactive</code>ç”¨äºæ–‡æœ¬æ–‡ä»¶ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸éœ€è¦äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œåœ¨<code>fairseq-preprocess</code>ä¸­ä¹Ÿå°±ä¸éœ€è¦æä¾›<code>testpref</code>å‚æ•°ã€‚è¿™ç§åœºæ™¯ç¬¦åˆåœ¨æ¯”èµ›ä¸­ï¼Œæ¯”èµ›æ–¹åªæä¾›æµ‹è¯•é›†ä¸­çš„srcéƒ¨åˆ†ï¼Œéœ€è¦è‡ªå·±æ¥è§£ç å¾—åˆ°tgtï¼Œå¹¶æœ€ç»ˆæäº¤ã€‚</p><h3 id="3-3-1-ç”Ÿæˆå¼è§£ç "><a href="#3-3-1-ç”Ÿæˆå¼è§£ç " class="headerlink" title="3.3.1 ç”Ÿæˆå¼è§£ç "></a>3.3.1 ç”Ÿæˆå¼è§£ç </h3><p>ä½¿ç”¨<code>fairseq-generate</code>å‘½ä»¤è¿›è¡Œç”Ÿæˆå¼è§£ç (<strong>ç”¨äºé¢„å¤„ç†åçš„äºŒè¿›åˆ¶æ–‡ä»¶</strong>)ï¼Œå¯ä»¥è‡ªè¡Œé€‰æ‹©æ˜¯å¦æ·»åŠ <code>--remove-bpe</code>å‚æ•°ï¼Œä½¿å¾—åœ¨ç”Ÿæˆæ—¶å°±å»æ‰bpeç¬¦å·(@@)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fairseq-generate $&#123;data_dir&#125;&#x2F;data-bin \</span><br><span class="line">    --path $&#123;model_dir&#125;&#x2F;checkpoints&#x2F;checkpoint_best.pt \</span><br><span class="line">    --batch-size 128 --beam 8 &gt; $&#123;data_dir&#125;&#x2F;result&#x2F;bestbeam8.txt</span><br></pre></td></tr></table></figure><p>é€‰å–ä¸€éƒ¨åˆ†ç»“æœå±•ç¤ºå¦‚ä¸‹ (<strong>S</strong>: æºå¥å­ï¼Œ<strong>T</strong>: ç›®æ ‡å¥å­ï¼Œ<strong>H/D</strong>: é¢„æµ‹çš„å¥å­åŠå…¶ç”Ÿæˆæ¦‚ç‡çš„logï¼Œå¥å­è´¨é‡è¶Šå¥½ï¼Œå…¶ç”Ÿæˆæ¦‚ç‡è¶Šæ¥è¿‘1ï¼Œå…¶logè¶Šæ¥è¿‘0ã€‚<strong>P</strong>: æ¯ä¸€ä¸ªè¯çš„ç”Ÿæˆæ¦‚ç‡çš„logã€‚å…¶ä¸­ï¼ŒH=\frac{\sum P}{n}<em>H</em>=<em>n</em>âˆ‘<em>P</em>)ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">S-537è¥¿ç­ç‰™ çš„ äººæƒ å›°å¢ƒ</span><br><span class="line">T-537Spain &amp;apos;s Human-Rights Dilemma</span><br><span class="line">H-537-0.16863664984703064Spain &amp;apos;s Human Rights Quandary</span><br><span class="line">D-537-0.16863664984703064Spain &amp;apos;s Human Rights Quandary</span><br><span class="line">P-537-0.0973 -0.1385 -0.1464 -0.0123 -0.4252 -0.4299 -0.0110 -0.0884</span><br><span class="line"></span><br><span class="line">S-5516è¿™æ˜¯ ä¸å¯ æ¥å— çš„ ã€‚</span><br><span class="line">T-5516that is unacceptable .</span><br><span class="line">H-5516-0.35840675234794617this is unacceptable .</span><br><span class="line">D-5516-0.35840675234794617this is unacceptable .</span><br><span class="line">P-5516-0.7625 -0.5517 -0.2005 -0.1513 -0.1261</span><br><span class="line"></span><br><span class="line">S-676ä¸ æœ€åˆ ç‰ˆæœ¬ çš„ ç ´äº§æ³• ç›¸ æ¯”è¾ƒ ï¼Œ 2006 å¹´ çš„ æ³•å¾‹ æ˜¯ ç‰¢ç‰¢ æ‰æ ¹ äº å¸‚åœºç»æµ çš„ ã€‚</span><br><span class="line">T-676compared with the original bankruptcy code , the 2006 code is firmly rooted in the needs of a market economy .</span><br><span class="line">H-676-0.624997079372406in contrast to the original bankruptcy law , the law of 2006 was firmly rooted in the market economy .</span><br><span class="line">D-676-0.624997079372406in contrast to the original bankruptcy law , the law of 2006 was firmly rooted in the market economy .</span><br><span class="line">P-676-1.4995 -0.9434 -0.1292 -0.3479 -0.9758 -0.6600 -0.9037 -0.1836 -0.4983 -1.6406 -0.3142 -0.0344 -0.1685 -1.0289 -1.0286 -0.1917 -1.5369 -0.6586 -0.1119 -0.1333 -0.1361</span><br><span class="line"></span><br><span class="line">S-432ç”¨ ç¼…å› å· å…±å’Œå…š å‚è®®å‘˜ è‹çŠ Â· æŸ¯æ—æ–¯ ï¼ˆ Susan Collins ï¼‰ çš„è¯ è¯´ ï¼Œ æ”¿åºœ å…³é—¨ å¯¹ å…¶ ç¼…å› å· é˜¿å¡è¿ªäºš å›½å®¶ å…¬å›­ ï¼ˆ Acadia National Park ï¼‰ å‘¨è¾¹ &quot; æ‰€æœ‰ å°ä¼ä¸š éƒ½ é€ æˆ äº† ä¼¤å®³ &quot; ï¼Œ &quot; è¿™æ˜¯ å®Œå…¨ é”™è¯¯ çš„ ã€‚ &quot; æ˜¯ å¥¹ é¦–å…ˆ æå‡º äº† å’Œè§£ åè®® çº²è¦ å¹¶ é€äº¤ å‚è®®é™¢ ã€‚</span><br><span class="line">T-432in the words of Senator Susan Collins , a Republican from Maine who first put together the outlines of a deal and took it to the Senate floor , the shutdown &quot; hurt all the small businesses &quot; around Acadia National Park in her home state , &quot; and that is plain wrong . &quot;</span><br><span class="line">H-432-0.7003933787345886in the words of Susan Collins , a Republican senator from Maine , it would be a mistake to shut down the government &amp;apos;s &quot; all small business &quot; around the Maine National Park , where she proposed a settlement and delivered it to the Senate .</span><br><span class="line">D-432-0.7003933787345886in the words of Susan Collins , a Republican senator from Maine , it would be a mistake to shut down the government &amp;apos;s &quot; all small business &quot; around the Maine National Park , where she proposed a settlement and delivered it to the Senate .</span><br><span class="line">P-432-1.2762 -0.3546 -0.0142 -0.1261 -0.0058 -0.7617 -0.1695 -0.2992 -0.0777 -0.3016 -0.4818 -0.0061 -0.0308 -0.3509 -2.5533 -1.5254 -0.2761 -1.1667 -0.6169 -0.6285 -1.2463 -0.0973 -1.4414 -0.3324 -0.2302 -0.3312 -0.6847 -1.0005 -0.1812 -2.9048 -0.3072 -1.8045 -0.0473 -0.8421 -0.4715 -0.6841 -1.1902 -1.6192 -0.3370 -2.3317 -0.3701 -0.2508 -3.0284 -0.2336 -1.1318 -0.3904 -0.1124 -0.0262 -0.2203 -0.1480</span><br></pre></td></tr></table></figure><h3 id="3-3-2-äº¤äº’å¼è§£ç "><a href="#3-3-2-äº¤äº’å¼è§£ç " class="headerlink" title="3.3.2 äº¤äº’å¼è§£ç "></a>3.3.2 äº¤äº’å¼è§£ç </h3><p>ä½¿ç”¨<code>fairseq-interactive</code>å‘½ä»¤è¿›è¡Œäº¤äº’å¼è§£ç (<strong>ç”¨äºæ–‡æœ¬æ–‡ä»¶</strong>)ã€‚æ³¨æ„å…¶<code>input</code>å‚æ•°</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">!fairseq-interactive $&#123;data_dir&#125;&#x2F;data-bin \</span><br><span class="line">    --input $&#123;data_dir&#125;&#x2F;test.zh \</span><br><span class="line">    --path $&#123;model_dir&#125;&#x2F;checkpoints&#x2F;checkpoint_best.pt \</span><br><span class="line">    --batch-size 1 --beam 8 --remove-bpe &gt; $&#123;data_dir&#125;&#x2F;result&#x2F;bestbeam8.txt</span><br></pre></td></tr></table></figure><h2 id="3-4-åå¤„ç†åŠè¯„ä»·"><a href="#3-4-åå¤„ç†åŠè¯„ä»·" class="headerlink" title="3.4 åå¤„ç†åŠè¯„ä»·"></a>3.4 åå¤„ç†åŠè¯„ä»·</h2><h3 id="3-4-1-æŠ½å–è¯‘æ–‡"><a href="#3-4-1-æŠ½å–è¯‘æ–‡" class="headerlink" title="3.4.1 æŠ½å–è¯‘æ–‡"></a>3.4.1 æŠ½å–è¯‘æ–‡</h3><p>ç”±äºè§£ç ç”Ÿæˆçš„æ–‡ä»¶åŒ…å«å¤§é‡æ— å…³ä¿¡æ¯ï¼Œæ‰€ä»¥éœ€è¦æŠŠ<strong>è¯‘æ–‡</strong>å’Œ<strong>æ­£ç¡®ç­”æ¡ˆ</strong>å•ç‹¬æŠ½å–å‡ºæ¥ï¼Œå…¶ä¸­predictæ˜¯è¯‘æ–‡ï¼Œansweræ˜¯æ­£ç¡®ç­”æ¡ˆï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep ^H $&#123;data_dir&#125;&#x2F;result&#x2F;bestbeam8.txt | cut -f3- &gt; $&#123;data_dir&#125;&#x2F;result&#x2F;predict.tok.true.bpe.en</span><br><span class="line">grep ^T $&#123;data_dir&#125;&#x2F;result&#x2F;bestbeam8.txt | cut -f2- &gt; $&#123;data_dir&#125;&#x2F;result&#x2F;answer.tok.true.bpe.en</span><br></pre></td></tr></table></figure><p>æ•ˆæœå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># predict.tok.true.bpe.en</span><br><span class="line">the subsidy .</span><br><span class="line">this is unacceptable .</span><br><span class="line">there is even worse .</span><br><span class="line">this must change .</span><br><span class="line"></span><br><span class="line"># answer.tok.true.bpe.en</span><br><span class="line">removal of subsidies .</span><br><span class="line">that is unacceptable .</span><br><span class="line">it gets worse .</span><br><span class="line">this must change .</span><br></pre></td></tr></table></figure><h3 id="3-4-1-å»é™¤bpeç¬¦å·"><a href="#3-4-1-å»é™¤bpeç¬¦å·" class="headerlink" title="3.4.1 å»é™¤bpeç¬¦å·"></a>3.4.1 å»é™¤bpeç¬¦å·</h3><p>æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥å»é™¤bpeç¬¦å·ï¼Œç¬¬ä¸€ç§æ˜¯åœ¨è§£ç æ—¶æ·»åŠ <code>--remove-bpe</code>å‚æ•°ï¼Œç¬¬äºŒç§æ˜¯ä½¿ç”¨<code>sed</code>æŒ‡ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -r &#39;s&#x2F;(@@ )| (@@ ?$)&#x2F;&#x2F;g&#39; &lt; $&#123;data_dir&#125;&#x2F;result&#x2F;predict.tok.true.bpe.en  &gt; $&#123;data_dir&#125;&#x2F;result&#x2F;predict.tok.true.en</span><br><span class="line">sed -r &#39;s&#x2F;(@@ )| (@@ ?$)&#x2F;&#x2F;g&#39; &lt; $&#123;data_dir&#125;&#x2F;result&#x2F;answer.tok.true.bpe.en  &gt; $&#123;data_dir&#125;&#x2F;result&#x2F;answer.tok.true.en</span><br></pre></td></tr></table></figure><p>æ•ˆæœå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># answer.tok.true.bpe.en</span><br><span class="line">a World of Under@@ investment</span><br><span class="line">that needs to change .</span><br><span class="line">revolts of the Righ@@ teous</span><br><span class="line">Russia &amp;apos;s Economic Imperi@@ alism</span><br><span class="line">shock and Pan@@ ic</span><br><span class="line"></span><br><span class="line"># answer.tok.true.en</span><br><span class="line">a World of Underinvestment</span><br><span class="line">that needs to change .</span><br><span class="line">revolts of the Righteous</span><br><span class="line">Russia &amp;apos;s Economic Imperialism</span><br><span class="line">shock and Panic</span><br></pre></td></tr></table></figure><h3 id="3-4-2-detruecase"><a href="#3-4-2-detruecase" class="headerlink" title="3.4.2 detruecase"></a>3.4.2 detruecase</h3><p>éœ€è¦ä½¿ç”¨detruecase.perlå°†æ–‡ä»¶ä¸­çš„å¤§å°å†™æ¢å¤æ­£å¸¸ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$&#123;DETC&#125; &lt; $&#123;data_dir&#125;&#x2F;result&#x2F;predict.tok.true.en &gt; $&#123;data_dir&#125;&#x2F;result&#x2F;predict.tok.en</span><br><span class="line">$&#123;DETC&#125; &lt; $&#123;data_dir&#125;&#x2F;result&#x2F;answer.tok.true.en &gt; $&#123;data_dir&#125;&#x2F;result&#x2F;answer.tok.en</span><br></pre></td></tr></table></figure><p>æ•ˆæœå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># predict.tok.true.en</span><br><span class="line">the subsidy .</span><br><span class="line">this is unacceptable .</span><br><span class="line">there is even worse .</span><br><span class="line">this must change .</span><br><span class="line"></span><br><span class="line"># predict.tok.en</span><br><span class="line">The subsidy .</span><br><span class="line">This is unacceptable .</span><br><span class="line">There is even worse .</span><br><span class="line">This must change .</span><br></pre></td></tr></table></figure><h3 id="3-4-3-è¯„ä»·"><a href="#3-4-3-è¯„ä»·" class="headerlink" title="3.4.3 è¯„ä»·"></a>3.4.3 è¯„ä»·</h3><p>1.<strong>multi-bleu</strong>ï¼šåœ¨detokenizeå‰è¿›è¡Œè¯„ä»·</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$&#123;MULTI_BLEU&#125; -lc $&#123;data_dir&#125;&#x2F;result&#x2F;answer.tok.en &lt; $&#123;data_dir&#125;&#x2F;result&#x2F;predict.tok.en</span><br></pre></td></tr></table></figure><p>ç»“æœå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">BLEU &#x3D; 28.81, 61.8&#x2F;35.4&#x2F;22.8&#x2F;15.2 (BP&#x3D;0.976, ratio&#x3D;0.977, hyp_len&#x3D;187605, ref_len&#x3D;192093)</span><br><span class="line">It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.</span><br></pre></td></tr></table></figure><p>2.<strong>sacrebleu</strong>ï¼šåœ¨detokenizeåè¿›è¡Œè¯„ä»·ã€‚<a href="https://github.com/mjpost/sacreBLEU">link</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Option 1: Pass the reference file as a positional argument to sacreBLEU</span><br><span class="line">sacrebleu ref.detok.txt -i output.detok.txt -m bleu -b -w 4</span><br><span class="line">20.7965</span><br><span class="line"></span><br><span class="line"># Option 2: Redirect the system into STDIN (Compatible with multi-bleu.perl way of doing things)</span><br><span class="line">cat output.detok.txt | sacrebleu ref.detok.txt -m bleu -b -w 4</span><br><span class="line">20.7965</span><br></pre></td></tr></table></figure><p>3.<strong>mteval-v14</strong>ï¼šUsage: <code>$0 -r &lt;ref_file&gt; -s &lt;src_file&gt; -t &lt;tst_file&gt;</code></p><h3 id="3-4-4-detokenize"><a href="#3-4-4-detokenize" class="headerlink" title="3.4.4 detokenize"></a>3.4.4 detokenize</h3><p>æœ€åä¸€æ­¥ï¼Œæ˜¯ä½¿ç”¨detokenize.perlå¾—åˆ°çº¯é¢„æµ‹æ–‡æœ¬</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$&#123;DETOKENIZER&#125; -l en &lt; $&#123;data_dir&#125;&#x2F;result&#x2F;predict.tok.en &gt; $&#123;data_dir&#125;&#x2F;result&#x2F;predict.en</span><br></pre></td></tr></table></figure><p>æ•ˆæœå¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># predict.tok.en</span><br><span class="line">what &amp;apos;s wrong with protectionism ?</span><br><span class="line">The &quot; establishment &quot; and counterinsurgency strategy , introduced by President Barack Obama &amp;apos;s military surge in 2010 , was intended to reverse the war .</span><br><span class="line"></span><br><span class="line"># predict.en</span><br><span class="line">What&#39;s wrong with protectionism?</span><br><span class="line">The &quot;establishment&quot; and counterinsurgency strategy, introduced by President Barack Obama&#39;s military surge in 2010, was intended to reverse the war.</span><br></pre></td></tr></table></figure><blockquote><p>å‚è€ƒï¼š</p><p> <a href="https://hannlp.github.io/2021-01-16-Use-fairseq-to-train-a-Chinese-English-translation-model-from-scratch/">https://hannlp.github.io/2021-01-16-Use-fairseq-to-train-a-Chinese-English-translation-model-from-scratch/</a></p><p><a href="https://zhuanlan.zhihu.com/p/194176917">https://zhuanlan.zhihu.com/p/194176917</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;ä¸­è‹±æœºå™¨ç¿»è¯‘çš„æ•°æ®é¢„å¤„ç†æµç¨‹ï¼Œæš‚å­˜ä¸€ä¸‹çœ‹åˆ°çš„ä¼˜ç§€åšæ–‡ï¼Œè¿‡æ®µæ—¶é—´æ”¹æˆè‡ªç”¨ç‰ˆæœ¬ã€‚&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="research" scheme="http://example.com/categories/research/"/>
    
    <category term="NMT" scheme="http://example.com/categories/research/NMT/"/>
    
    
  </entry>
  
  <entry>
    <title>latex-tips</title>
    <link href="http://example.com/2021/11/27/latex-tips/"/>
    <id>http://example.com/2021/11/27/latex-tips/</id>
    <published>2021-11-27T15:05:54.000Z</published>
    <updated>2021-11-27T15:33:19.133Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>latex/overleafä¸€äº›ç¬”è®°ã€‚</p></blockquote><span id="more"></span><h1 id="å›¾ç‰‡æ’ç‰ˆ"><a href="#å›¾ç‰‡æ’ç‰ˆ" class="headerlink" title="å›¾ç‰‡æ’ç‰ˆ"></a>å›¾ç‰‡æ’ç‰ˆ</h1><h2 id="å®åŒ…ï¼š"><a href="#å®åŒ…ï¼š" class="headerlink" title="å®åŒ…ï¼š"></a>å®åŒ…ï¼š</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">\usepackage&#123;graphicx&#125; %æ’å›¾å®åŒ…</span><br><span class="line">\usepackage&#123;subfig&#125; %å­å›¾åŒ…å«å®åŒ…ï¼Œè¾ƒæ–°</span><br><span class="line">\usepackage&#123;subfigure&#125; %å­å›¾åŒ…å«å®åŒ…ï¼Œè¾ƒæ—§</span><br></pre></td></tr></table></figure><h2 id="åŸºæœ¬å‘½ä»¤ï¼š"><a href="#åŸºæœ¬å‘½ä»¤ï¼š" class="headerlink" title="åŸºæœ¬å‘½ä»¤ï¼š"></a>åŸºæœ¬å‘½ä»¤ï¼š</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;figure&#125;[ht]</span><br><span class="line">\centering</span><br><span class="line">\includegraphics[width&#x3D;10cm]&#123;example.png&#125;</span><br><span class="line">\caption&#123;this is a figure&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br></pre></td></tr></table></figure><p>\centeringè¡¨ç¤ºçš„æ˜¯é‡Œé¢ç´§è·Ÿçš„å†…å®¹éƒ½å±…ä¸­ï¼›</p><p>\includegrapics[å‚æ•°1]{å‚æ•°2}</p><p>å‚æ•°1ï¼šå¯¹å›¾ç‰‡è¿›è¡Œä¸€äº›è°ƒæ•´ï¼Œä¾‹å¦‚å®½é«˜ç¼©æ”¾width=10cm,height=8cm,scale=0.4</p><p>å‚æ•°2ï¼šå›¾ç‰‡å</p><p>\caption{æ ‡é¢˜}è®¾ç½®å›¾ç‰‡çš„ä¸€ä¸ªç¼–å·ä»¥åŠä¸ºå›¾ç‰‡æ·»åŠ æ ‡é¢˜ï¼›</p><h2 id="å›¾ç‰‡ä½ç½®ï¼š"><a href="#å›¾ç‰‡ä½ç½®ï¼š" class="headerlink" title="å›¾ç‰‡ä½ç½®ï¼š"></a>å›¾ç‰‡ä½ç½®ï¼š</h2><p>\begin{figure}[å‚æ•°1]</p><p>å‚æ•°1ï¼šå¯¹å›¾ç‰‡åœ¨æ–‡ä¸­çš„ä½ç½®è¿›è¡Œè®¾ç½®ï¼Œh æ­¤å¤„ï¼ˆhereï¼‰t é¡µé¡¶ï¼ˆtopï¼‰b é¡µåº•ï¼ˆbottomï¼‰p ç‹¬ç«‹ä¸€é¡µï¼ˆpageï¼‰ï¼Œ<strong>H å›ºå®šä½ç½®</strong>ï¼›</p><h2 id="subfigå’Œsubfigureçš„åŒºåˆ«ï¼š"><a href="#subfigå’Œsubfigureçš„åŒºåˆ«ï¼š" class="headerlink" title="subfigå’Œsubfigureçš„åŒºåˆ«ï¼š"></a>subfigå’Œsubfigureçš„åŒºåˆ«ï¼š</h2><p>subfigï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;figure&#125;[tbp]</span><br><span class="line">\centering</span><br><span class="line">\subfloat[Arabic numerals]&#123;\label&#123;fig:a&#125;\includegraphics[width&#x3D;1in]&#123;placeholder&#125;&#125;\quad</span><br><span class="line">\subfloat[Arabic numerals]&#123;\label&#123;fig:b&#125;\includegraphics[width&#x3D;1in]&#123;placeholder&#125;&#125;\\</span><br><span class="line">\caption&#123;Capital Roman numerals.&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br></pre></td></tr></table></figure><p>subfigureï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;figure&#125; \centering </span><br><span class="line">\subfigure[figure 1 title.] &#123; \label&#123;fig:a&#125; </span><br><span class="line">\includegraphics[width&#x3D;0.8\columnwidth]&#123;fig1.eps&#125; </span><br><span class="line">&#125; </span><br><span class="line">\subfigure[figure 2 title.] &#123; \label&#123;fig:b&#125; </span><br><span class="line">\includegraphics[width&#x3D;0.8\columnwidth]&#123;fig2.eps&#125; </span><br><span class="line">&#125; </span><br><span class="line">\caption&#123; general title. &#125; </span><br><span class="line">\label&#123;fig&#125; </span><br><span class="line">\end&#123;figure&#125; </span><br></pre></td></tr></table></figure><blockquote><p>å‚è€ƒï¼š</p><p><a href="https://zhuanlan.zhihu.com/p/143529262">https://zhuanlan.zhihu.com/p/143529262</a></p><p><a href="https://blog.csdn.net/yq_forever/article/details/84796802">https://blog.csdn.net/yq_forever/article/details/84796802</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;latex/overleafä¸€äº›ç¬”è®°ã€‚&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="other" scheme="http://example.com/categories/other/"/>
    
    
  </entry>
  
  <entry>
    <title>çº¿æ€§è§„åˆ’_GLPKå·¥å…·</title>
    <link href="http://example.com/2021/11/27/LP-GLPK/"/>
    <id>http://example.com/2021/11/27/LP-GLPK/</id>
    <published>2021-11-27T14:16:28.000Z</published>
    <updated>2021-11-27T15:03:09.043Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>çº¿æ€§è§„åˆ’æ±‚è§£å·¥å…·GLPKåœ¨windowsç¯å¢ƒä¸‹çš„å®‰è£…å’Œä½¿ç”¨æ ·ä¾‹ã€‚</p></blockquote><span id="more"></span><p>è®°å½•ä¸€ä¸ªGLPKå·¥å…·æ— éœ€VSç¼–è¯‘ï¼Œç›´æ¥å¢åŠ ç³»ç»Ÿè·¯å¾„çš„æ–¹æ³•ï¼Œç®€å•å¥½ç”¨ã€‚</p><h1 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h1><p>1.ä»link<a href="https://sourceforge.net/projects/winglpk/%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E5%8C%85%E3%80%82">https://sourceforge.net/projects/winglpk/ä¸‹è½½å®‰è£…åŒ…ã€‚</a><br>2.ä¸‹è½½å¥½ä¹‹åå°†å®‰è£…åŒ…è§£å‹ï¼Œå¹¶å°†å…¶å¤åˆ¶åˆ°Cç›˜ä¸‹ã€‚<br>3.è¿›å…¥C:\glpk-4.65\w64æˆ–è€…C:\glpk-4.65\w32ï¼Œæ ¹æ®è‡ªå·±ç”µè„‘çš„ç³»ç»Ÿç±»å‹é€‰æ‹©æ‰“å¼€64ä½çš„è¿˜æ˜¯32ä½çš„ã€‚ï¼ˆæŸ¥çœ‹ç”µè„‘ç³»ç»Ÿç±»å‹çš„æ“ä½œï¼šæ§åˆ¶é¢æ¿â€“ç³»ç»Ÿå’Œå®‰å…¨â€“ç³»ç»Ÿï¼‰<br>4.æ‰“å¼€æ§åˆ¶é¢æ¿â€“ç³»ç»Ÿå’Œå®‰å…¨â€“ç³»ç»Ÿâ€“é«˜çº§ç³»ç»Ÿè®¾ç½®-ç¯å¢ƒå˜é‡ï¼šç¼–è¾‘ç³»ç»Ÿå˜é‡ä¸­çš„Pathï¼Œå°†è·¯å¾„C:\glpk-4.65\w64åŠ å…¥Pathä¸­ã€‚<br>5.æ£€éªŒå®‰è£…æ˜¯å¦æˆåŠŸï¼šåœ¨C:\glpk-4.65\w64æ–‡ä»¶å¤¹ä¸‹ï¼Œè·¯å¾„ä¸­è¾“å…¥cmdæ‰“å¼€å‘½ä»¤è¡Œçª—å£ï¼Œè¾“å…¥glpsolå›è½¦ï¼Œæ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯åˆ™è¯´æ˜å®‰è£…æˆåŠŸã€‚</p><h1 id="è¾“å…¥æ–‡ä»¶-input-mod"><a href="#è¾“å…¥æ–‡ä»¶-input-mod" class="headerlink" title="è¾“å…¥æ–‡ä»¶:input.mod"></a>è¾“å…¥æ–‡ä»¶:input.mod</h1><p>var x1;<br>var x2;<br>var x3;<br>//var x4 binary;å¸ƒå°”å˜é‡binaryï¼Œç±»ä¼¼çš„è¿˜æœ‰æ•´æ•°integerã€‚</p><p>maximize z: 10 * x1 + 8 * x2 + 16 * x3;</p><p>s.t. con1 : 3 * x1 + 3 * x2 + 2 * x3 &lt;= 200;<br>s.t. con2 : 4 * x1 + 3 * x2 + 7 * x3 &lt;= 300;<br>s.t. con3 : -x1 &lt;= 0;<br>s.t. con4 : -x2 &lt;= 0;<br>s.t. con5 : -x3 &lt;= 0;<br>end;</p><h1 id="å‘½ä»¤"><a href="#å‘½ä»¤" class="headerlink" title="å‘½ä»¤"></a>å‘½ä»¤</h1><p>glpsol -m input.mod -o output.sol ã€€<br>-m filename: æŒ‡å®šæè¿°é—®é¢˜çš„æ–‡ä»¶<br>-o filename: æŒ‡å®šè¾“å‡ºç»“æœä¿å­˜åœ¨å“ªä¸ªæ–‡ä»¶</p><h1 id="è¾“å‡º-output-sol"><a href="#è¾“å‡º-output-sol" class="headerlink" title="è¾“å‡º:output.sol"></a>è¾“å‡º:output.sol</h1><p>Problem:    input<br>Rows:       6<br>Columns:    3<br>Non-zeros:  12<br>Status:     OPTIMAL<br>Objective:  z = 746.6666667 (MAXimum)</p><p>   No.   Row name   St   Activity     Lower bound   Upper bound    Marginal</p><hr><pre><code> 1 z            B        746.667                              2 con1         NU           200                         200      0.533333  3 con2         NU           300                         300       2.13333  4 con3         NU             0                          -0      0.133333  5 con4         B       -53.3333                          -0  6 con5         B            -20                          -0 </code></pre><p>   No. Column name  St   Activity     Lower bound   Upper bound    Marginal</p><hr><pre><code> 1 x1           B              0                              2 x2           B        53.3333                              3 x3           B             20                             </code></pre><p>Karush-Kuhn-Tucker optimality conditions:</p><p>KKT.PE: max.abs.err = 0.00e+00 on row 0<br>        max.rel.err = 0.00e+00 on row 0<br>        High quality</p><p>KKT.PB: max.abs.err = 0.00e+00 on row 0<br>        max.rel.err = 0.00e+00 on row 0<br>        High quality</p><p>KKT.DE: max.abs.err = 1.78e-15 on column 1<br>        max.rel.err = 8.35e-17 on column 1<br>        High quality</p><p>KKT.DB: max.abs.err = 0.00e+00 on row 0<br>        max.rel.err = 0.00e+00 on row 0<br>        High quality</p><p>End of output</p><blockquote><p>å‚è€ƒï¼š<a href="https://blog.csdn.net/weixin_42848399/article/details/91654118">https://blog.csdn.net/weixin_42848399/article/details/91654118</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;çº¿æ€§è§„åˆ’æ±‚è§£å·¥å…·GLPKåœ¨windowsç¯å¢ƒä¸‹çš„å®‰è£…å’Œä½¿ç”¨æ ·ä¾‹ã€‚&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="other" scheme="http://example.com/categories/other/"/>
    
    
  </entry>
  
  <entry>
    <title>DPåŠ¨æ€è§„åˆ’</title>
    <link href="http://example.com/2021/10/15/oj-DP/"/>
    <id>http://example.com/2021/10/15/oj-DP/</id>
    <published>2021-10-15T04:33:12.000Z</published>
    <updated>2021-10-15T07:58:41.473Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ç®—æ³•è¯¾ç¬”è®°-åŠ¨æ€è§„åˆ’<br>è¯­è¨€: C++</p></blockquote><span id="more"></span><h1 id="ä¸­æ–‡æ ‡é¢˜"><a href="#ä¸­æ–‡æ ‡é¢˜" class="headerlink" title="ä¸­æ–‡æ ‡é¢˜"></a>ä¸­æ–‡æ ‡é¢˜</h1><p>å†…å®¹ã€‚</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;ç®—æ³•è¯¾ç¬”è®°-åŠ¨æ€è§„åˆ’&lt;br&gt;è¯­è¨€: C++&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    <category term="oj" scheme="http://example.com/categories/code/oj/"/>
    
    
  </entry>
  
  <entry>
    <title>DCåˆ†æ²»</title>
    <link href="http://example.com/2021/10/15/oj-DC/"/>
    <id>http://example.com/2021/10/15/oj-DC/</id>
    <published>2021-10-15T04:28:54.000Z</published>
    <updated>2021-10-15T04:40:45.048Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ç®—æ³•è¯¾ç¬”è®°-åˆ†æ²»<br>è¯­è¨€ï¼šC++</p></blockquote><span id="more"></span><h1 id="æ ‡é¢˜"><a href="#æ ‡é¢˜" class="headerlink" title="æ ‡é¢˜"></a>æ ‡é¢˜</h1><p>å†…å®¹ã€‚</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;ç®—æ³•è¯¾ç¬”è®°-åˆ†æ²»&lt;br&gt;è¯­è¨€ï¼šC++&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    <category term="oj" scheme="http://example.com/categories/code/oj/"/>
    
    
  </entry>
  
  <entry>
    <title>pythonç¬”è®°</title>
    <link href="http://example.com/2021/05/31/python-note/"/>
    <id>http://example.com/2021/05/31/python-note/</id>
    <published>2021-05-31T09:07:14.000Z</published>
    <updated>2021-06-04T09:42:13.687Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>python3çš„ä¸€äº›çŸ¥è¯†ç‚¹</p></blockquote><span id="more"></span><h1 id="å‡½æ•°"><a href="#å‡½æ•°" class="headerlink" title="å‡½æ•°"></a>å‡½æ•°</h1><ul><li><p>å‡½æ•°ä¸­çš„é»˜è®¤å‚æ•°å¿…é¡»æŒ‡å‘ä¸å˜å¯¹è±¡ï¼Œå¦åˆ™åœ¨å¤šæ¬¡è°ƒç”¨æ—¶ä¼šæ”¹å˜é»˜è®¤å€¼ï¼ˆä¾‹å¦‚Noneã€strï¼Œåä¾‹å¦‚listï¼‰ã€‚</p></li><li><p>å¯å˜å‚æ•°ï¼šå…è®¸ä¸å®šé‡ä¸ªå‚æ•°è¾“å…¥ï¼Œåœ¨å‚æ•°å‰åŠ <em>ï¼Œä¼ å…¥å‚æ•°ç±»å‹æ˜¯tupleã€‚<br>åœ¨è¾“å…¥list/tupleè¿›å…¥å¯å˜å‚æ•°çš„å‡½æ•°æ—¶ï¼Œå¯ä»¥åŠ ä¸Š</em>ç›´æ¥ä¼ å…¥ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def func(*num):</span><br><span class="line">    pass</span><br><span class="line">a &#x3D; (1,2,3)</span><br><span class="line">func(*a)</span><br></pre></td></tr></table></figure></li><li><p>å…³é”®å­—å‚æ•°ï¼š**æ¥è¡¨ç¤ºï¼Œç”¨æ³•åŒå¯å˜å‚æ•°ï¼ŒåŒºåˆ«æ˜¯ä¼ å…¥çš„å‚æ•°éƒ½ä¸º<code>x=y</code>æ ¼å¼ï¼Œä¼ å…¥åå˜æˆä¸€ä¸ªå…³é”®å­—ä¸ºxï¼Œå€¼ä¸ºyçš„å­—å…¸ã€‚<br>å¯ä»¥ç”¨ä½œç”¨æˆ·å¯é€‰è¾“å…¥çš„æ”¶é›†ä¸Šã€‚</p></li><li><p>å‘½åå…³é”®å­—å‚æ•°ï¼šç”¨<em>æˆ–è€…å¯å˜å‚æ•°</em>xåšåˆ†éš”ç¬¦ï¼Œè§„å®šå¿…é¡»è¾“å…¥çš„å…³é”®å­—å‚æ•°ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def func(x,y,*,z):</span><br><span class="line">    pass</span><br><span class="line">func(1,2,z&#x3D;4)</span><br></pre></td></tr></table></figure><h1 id="åˆ‡ç‰‡"><a href="#åˆ‡ç‰‡" class="headerlink" title="åˆ‡ç‰‡"></a>åˆ‡ç‰‡</h1></li><li><p>å·¦é—­å³å¼€å–å€¼ï¼Œç¬¬ä¸‰ä¸ªå‚æ•°è¡¨ç¤ºé—´éš”</p></li></ul><h1 id="è¿­ä»£"><a href="#è¿­ä»£" class="headerlink" title="è¿­ä»£"></a>è¿­ä»£</h1><ul><li>å­—å…¸çš„è¿­ä»£é»˜è®¤æ˜¯keyï¼Œè¿­ä»£value:<code>for value in d.values()</code>ï¼Œ<br>åŒæ—¶è¿­ä»£keyå’Œvalue:<code>for k, v in d.items()</code></li></ul><h1 id="ç”Ÿæˆå™¨generator"><a href="#ç”Ÿæˆå™¨generator" class="headerlink" title="ç”Ÿæˆå™¨generator"></a>ç”Ÿæˆå™¨generator</h1><ul><li><p>æŠŠç”Ÿæˆå¼åˆ—è¡¨çš„[]æ”¹ä¸º()ï¼Œæ¯æ¬¡è°ƒç”¨next(x)è®¡ç®—ä¸‹ä¸€ä¸ªå…ƒç´ çš„å€¼ï¼Œæˆ–è€…ç”¨forå¾ªç¯è¿­ä»£</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">g &#x3D; (x*x for x in range(0,10))</span><br><span class="line">a &#x3D; next(g)</span><br><span class="line">for i in g:</span><br><span class="line">print(i)</span><br></pre></td></tr></table></figure></li><li><p>åœ¨å‡½æ•°ä¸­æ·»åŠ yieldè¯­å¥ï¼Œæ¯æ¬¡è°ƒç”¨<code>next()</code>ï¼Œè¿è¡Œåˆ°yieldè¿”å›ï¼Œä¸‹æ¬¡è°ƒç”¨ä»yieldä¸‹ç»§ç»­</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def odd():</span><br><span class="line">print(&quot;step 1&quot;)</span><br><span class="line">yield 1</span><br><span class="line">print(&quot;step 2&quot;)</span><br><span class="line">yield 3</span><br><span class="line">print(&quot;step 3&quot;)</span><br><span class="line">yield 5</span><br><span class="line">o &#x3D; odd()</span><br><span class="line">a &#x3D; next(o) #step 2\n3</span><br></pre></td></tr></table></figure><ul><li>è¿™é‡Œè¦æ³¨æ„forå¾ªç¯è°ƒç”¨å‡½æ•°ç”Ÿæˆå™¨æ—¶ï¼Œå‡½æ•°å†…çš„printå†…å®¹æ— æ³•è¾“å‡ºï¼Œå¯ä»¥é€šè¿‡<code>StopIteration</code>é”™è¯¯çš„valueè·å–ã€‚<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for i in o:</span><br><span class="line">print(i) #1 3 5</span><br><span class="line">while True:</span><br><span class="line">try:</span><br><span class="line">x &#x3D; next(o)</span><br><span class="line">print(x)</span><br><span class="line">except StopIteration as e:</span><br><span class="line">print(e.value)</span><br><span class="line">break</span><br></pre></td></tr></table></figure></li></ul><h1 id="è¿­ä»£å™¨"><a href="#è¿­ä»£å™¨" class="headerlink" title="è¿­ä»£å™¨"></a>è¿­ä»£å™¨</h1><ul><li>åˆ¤æ–­å¯¹è±¡æ˜¯ä¸æ˜¯<code>Iterable</code>å¯¹è±¡</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from collections.abc import Iterable</span><br><span class="line">isinstance([], Iterable) # True</span><br></pre></td></tr></table></figure><ul><li>å¯ä»¥è¢«<code>next()</code>ä¸æ–­è°ƒç”¨å¹¶è¿”å›ä¸‹ä¸€ä¸ªå€¼çš„å¯¹è±¡ç§°ä¸ºè¿­ä»£å™¨<code>Iterator</code>å¯¹è±¡ï¼Œç”Ÿæˆå™¨éƒ½æ˜¯<code>Iterator</code>å¯¹è±¡ï¼Œä½†æ˜¯<code>Iterable</code>å¯¹è±¡ä¸å…¨æ˜¯<code>Iterator</code>å¯¹è±¡</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from collections.abc import Iterator</span><br><span class="line">isinstance([],Iterator) # False</span><br></pre></td></tr></table></figure><ul><li><code>Iterable</code>å¯¹è±¡å¯ä»¥é€šè¿‡ä½¿ç”¨<code>iter()</code>å‡½æ•°å˜æˆ<code>Iterator</code>å¯¹è±¡ï¼Œä¸¤è€…çš„åŒºåˆ«æ˜¯åè€…æ˜¯æƒ°æ€§çš„ï¼Œå¯ä»¥æ˜¯æ— é™é•¿åº¦çš„åºåˆ—æµï¼Œæ— æ³•æå‰çŸ¥é“é•¿åº¦ï¼Œå‰è€…æ˜¯æœ‰é™çš„ï¼Œé•¿åº¦å¯çŸ¥çš„ã€‚<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">isinstance(iter([]), Iterator) # True</span><br></pre></td></tr></table></figure></li></ul><h1 id="å‡½æ•°å¼ç¼–ç¨‹"><a href="#å‡½æ•°å¼ç¼–ç¨‹" class="headerlink" title="å‡½æ•°å¼ç¼–ç¨‹"></a>å‡½æ•°å¼ç¼–ç¨‹</h1><p>å‡½æ•°å¼ç¼–ç¨‹çš„ä¸€ä¸ªç‰¹ç‚¹ï¼šå…è®¸æŠŠå‡½æ•°æœ¬èº«ä½œä¸ºå‚æ•°ä¼ å…¥å¦ä¸€ä¸ªå‡½æ•°ï¼Œè¿˜å…è®¸è¿”å›ä¸€ä¸ªå‡½æ•°ã€‚</p><h2 id="é«˜é˜¶å‡½æ•°"><a href="#é«˜é˜¶å‡½æ•°" class="headerlink" title="é«˜é˜¶å‡½æ•°"></a>é«˜é˜¶å‡½æ•°</h2><ul><li>æ¥æ”¶å¦ä¸€ä¸ªå‡½æ•°ä½œä¸ºå‚æ•°çš„å‡½æ•°</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def add(x, y, f):</span><br><span class="line">return f(x) + f(y)</span><br></pre></td></tr></table></figure><ul><li>map()ï¼šæ¥æ”¶ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªå‡½æ•°ï¼Œä¸€ä¸ª<code>Iterable</code>å¯¹è±¡ï¼Œå¯¹æ¯ä¸ªå¯¹è±¡å®æ–½å‡½æ•°ï¼Œè¿”å›ç»“æœæ˜¯ä¸€ä¸ª<code>Iterator</code>å¯¹è±¡ã€‚</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def f(x):</span><br><span class="line">return x*x</span><br><span class="line">r &#x3D; map(f, [1,2,3,4,5,6])</span><br></pre></td></tr></table></figure><ul><li>reduce()ï¼šæ¥æ”¶ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªå‡½æ•°å’Œä¸€ä¸ªåºåˆ—ï¼ŒåŠŸèƒ½æ˜¯æŠŠç»“æœç»§ç»­å’Œåºåˆ—çš„ä¸‹ä¸€ä¸ªå…ƒç´ åšç´¯ç§¯è®¡ç®—ã€‚</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#str2intåŠŸèƒ½å®ç°</span><br><span class="line">from functools import reduce</span><br><span class="line">def fn(x, y):</span><br><span class="line">return x * 10 + y</span><br><span class="line">def char2num(s):</span><br><span class="line">digits &#x3D; &#123;&#39;0&#39;: 0, &#39;1&#39;: 1, &#39;2&#39;: 2, &#39;3&#39;: 3, &#39;4&#39;: 4, &#39;5&#39;: 5, &#39;6&#39;: 6, &#39;7&#39;: 7, &#39;8&#39;: 8, &#39;9&#39;: 9&#125;</span><br><span class="line">return digits[s]</span><br><span class="line">reduce(fn, map(char2num, &#39;13579&#39;)) # 13579</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#åˆ©ç”¨mapå’Œreduceç¼–å†™ä¸€ä¸ªstr2floatå‡½æ•°ï¼ŒæŠŠå­—ç¬¦ä¸²&#39;123.456&#39;è½¬æ¢æˆæµ®ç‚¹æ•°123.456</span><br><span class="line">def str2float(s):</span><br><span class="line">    def ten(x, y):</span><br><span class="line">        return x*10+y</span><br><span class="line">    def st(x):</span><br><span class="line">        D &#x3D; &#123;&#39;0&#39;: 0, &#39;1&#39;: 1, &#39;2&#39;: 2, &#39;3&#39;: 3, &#39;4&#39;: 4, &#39;5&#39;: 5, &#39;6&#39;: 6, &#39;7&#39;: 7, &#39;8&#39;: 8, &#39;9&#39;: 9&#125;</span><br><span class="line">        return D[x]</span><br><span class="line">    a, b &#x3D; s.split(&#39;.&#39;)</span><br><span class="line">    num &#x3D; len(b)</span><br><span class="line">    ans1 &#x3D; reduce(ten, list(map(st, a)))</span><br><span class="line">    ans2 &#x3D; reduce(ten, list(map(st, b)))</span><br><span class="line">    ans &#x3D; ans1 +ans2&#x2F;(10**num)</span><br><span class="line">    return ans</span><br><span class="line"></span><br><span class="line">print(&#39;str2float(\&#39;123.456\&#39;) &#x3D;&#39;, str2float(&#39;123.456&#39;))</span><br><span class="line">if abs(str2float(&#39;123.456&#39;) - 123.456) &lt; 0.00001:</span><br><span class="line">    print(&#39;æµ‹è¯•æˆåŠŸ!&#39;)</span><br><span class="line">else:</span><br><span class="line">    print(&#39;æµ‹è¯•å¤±è´¥!&#39;)</span><br></pre></td></tr></table></figure><ul><li>filter():æ¥æ”¶ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªå‡½æ•°ï¼Œä¸€ä¸ªåºåˆ—ï¼Œæ ¹æ®å‡½æ•°çš„True/Falseæ¥å†³å®šåºåˆ—æ˜¯å¦ä¿ç•™ï¼Œè¿”å›å€¼æ˜¯ä¸€ä¸ª<code>Iterator</code>å¯¹è±¡<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def not_empty(s):</span><br><span class="line">    return s and s.strip()</span><br><span class="line">x &#x3D; list(filter(not_empty, [&#39;A&#39;, &#39;&#39;, &#39;B&#39;, None, &#39;C&#39;, &#39;  &#39;])) # [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;]</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;python3çš„ä¸€äº›çŸ¥è¯†ç‚¹&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    <category term="python" scheme="http://example.com/categories/code/python/"/>
    
    
  </entry>
  
  <entry>
    <title>pytorchç¬”è®°</title>
    <link href="http://example.com/2021/05/28/pytorch-note/"/>
    <id>http://example.com/2021/05/28/pytorch-note/</id>
    <published>2021-05-28T08:25:31.000Z</published>
    <updated>2022-01-15T15:25:24.436Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>pytorch-å­¦ä¹ ç¬”è®°</p></blockquote><span id="more"></span><h1 id="0-pytorchçš„ç»„ä»¶"><a href="#0-pytorchçš„ç»„ä»¶" class="headerlink" title="0 pytorchçš„ç»„ä»¶"></a>0 pytorchçš„ç»„ä»¶</h1><table><thead><tr><th>Component</th><th>Description</th></tr></thead><tbody><tr><td><a href="https://pytorch.org/docs/stable/torch.html"><strong>torch</strong></a></td><td>åœ¨GPUä¸Šçš„ç±»ä¼¼Numpyçš„å¼ é‡åº“ï¼Œä¸€äº›åŸºæœ¬æ“ä½œ</td></tr><tr><td><a href="https://pytorch.org/docs/stable/autograd.html"><strong>torch.autograd</strong></a></td><td>æ”¯æŒtorchä¸­å¼ é‡çš„å¾®åˆ†æ“ä½œ</td></tr><tr><td><a href="https://pytorch.org/docs/stable/jit.html"><strong>torch.jit</strong></a></td><td>åˆ›å»ºå¯åºåˆ—åŒ–å’Œå¯ä¼˜åŒ–çš„ç¼–è¯‘å †æ ˆ(TorchScript)</td></tr><tr><td><a href="https://pytorch.org/docs/stable/nn.html"><strong>torch.nn</strong></a></td><td>ä¸autogradæ·±åº¦é›†æˆçš„ç¥ç»ç½‘ç»œåº“</td></tr><tr><td><a href="https://pytorch.org/docs/stable/multiprocessing.html"><strong>torch.multiprocessing</strong></a></td><td>å¯¹æ•°æ®åŠ è½½Hogwildè®­ç»ƒèµ·æ•ˆçš„å¤šè¿›ç¨‹</td></tr><tr><td><a href="https://pytorch.org/docs/stable/data.html"><strong>torch.utils</strong></a></td><td>æ•°æ®åŠ è½½å’Œå…¶ä»–å®ç”¨ç¨‹åºåŠŸèƒ½</td></tr></tbody></table><h1 id="1-pytorchæ‰‹å†Œ"><a href="#1-pytorchæ‰‹å†Œ" class="headerlink" title="1 pytorchæ‰‹å†Œ"></a>1 pytorchæ‰‹å†Œ</h1><h2 id="1-1-å®˜æ–¹å¤‡å¿˜å½•"><a href="#1-1-å®˜æ–¹å¤‡å¿˜å½•" class="headerlink" title="1.1 å®˜æ–¹å¤‡å¿˜å½•"></a><a href="https://pytorch.org/tutorials/beginner/ptcheat.html">1.1 å®˜æ–¹å¤‡å¿˜å½•</a></h2><p><strong>import:</strong></p><p>ä¸€èˆ¬çš„ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch                                        <span class="comment"># root package</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader    <span class="comment"># dataset representation and loading</span></span><br></pre></td></tr></table></figure><p>ç¥ç»ç½‘ç»œAPIï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.autograd <span class="keyword">as</span> autograd         <span class="comment"># computation graph</span></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor                  <span class="comment"># tensor node in the computation graph</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn                     <span class="comment"># neural networks</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F           <span class="comment"># layers, activations and more</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim               <span class="comment"># optimizers e.g. gradient descent, ADAM, etc.</span></span><br><span class="line"><span class="keyword">from</span> torch.jit <span class="keyword">import</span> script, trace       <span class="comment"># hybrid frontend decorator and tracing jit</span></span><br></pre></td></tr></table></figure><p><strong>Tensor:</strong></p><p>åˆ›å»ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(*size)              <span class="comment"># tensor with independent N(0,1) entries</span></span><br><span class="line">x = torch.[ones|zeros](*size)       <span class="comment"># tensor with all 1&#x27;s [or 0&#x27;s]</span></span><br><span class="line">x = torch.tensor(L)                 <span class="comment"># create tensor from [nested] list or ndarray L</span></span><br><span class="line">y = x.clone()                       <span class="comment"># clone of x</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():               <span class="comment"># code wrap that stops autograd from tracking tensor history</span></span><br><span class="line">requires_grad=<span class="literal">True</span>                  <span class="comment"># arg, when set to True, tracks computation</span></span><br><span class="line">                                    <span class="comment"># history for future derivative calculations</span></span><br></pre></td></tr></table></figure><p>ç»´åº¦ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x.size()                                  <span class="comment"># return tuple-like object of dimensions</span></span><br><span class="line">x = torch.cat(tensor_seq, dim=<span class="number">0</span>)          <span class="comment"># concatenates tensors along dim</span></span><br><span class="line">y = x.view(a,b,...)                       <span class="comment"># reshapes x into size (a,b,...)</span></span><br><span class="line">y = x.view(-<span class="number">1</span>,a)                          <span class="comment"># reshapes x into size (b,a) for some b</span></span><br><span class="line">y = x.transpose(a,b)                      <span class="comment"># swaps dimensions a and b</span></span><br><span class="line">y = x.permute(*dims)                      <span class="comment"># permutes dimensions</span></span><br><span class="line">y = x.unsqueeze(dim)                      <span class="comment"># tensor with added axis</span></span><br><span class="line">y = x.unsqueeze(dim=<span class="number">2</span>)                    <span class="comment"># (a,b,c) tensor -&gt; (a,b,1,c) tensor</span></span><br><span class="line">y = x.squeeze()                           <span class="comment"># removes all dimensions of size 1 (a,1,b,1) -&gt; (a,b)</span></span><br><span class="line">y = x.squeeze(dim=<span class="number">1</span>)                      <span class="comment"># removes specified dimension of size 1 (a,1,b,1) -&gt; (a,b,1)</span></span><br></pre></td></tr></table></figure><h1 id="æ•°æ®æ“ä½œ"><a href="#æ•°æ®æ“ä½œ" class="headerlink" title="æ•°æ®æ“ä½œ"></a>æ•°æ®æ“ä½œ</h1><h2 id="è®¿é—®å…ƒç´ "><a href="#è®¿é—®å…ƒç´ " class="headerlink" title="è®¿é—®å…ƒç´ "></a>è®¿é—®å…ƒç´ </h2><p><code>[1,:]</code>å…¶ä¸­:è¡¨ç¤ºé€‰æ‹©èŒƒå›´ï¼Œåªæœ‰:è¡¨ç¤ºå…¨é€‰ï¼Œä¸æ•°å­—ç»“åˆè¡¨ç¤ºèŒƒå›´ã€‚</p><p><code>[::3,::2]</code>å…¶ä¸­::è¡¨ç¤ºè·³é€‰ï¼Œæ¯éš”xä¸ªé€‰æ‹©ä¸€ä¸ªã€‚</p><p>å¼ é‡:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.arange(12) #ç”Ÿæˆ</span><br><span class="line">x.shape #å½¢çŠ¶</span><br><span class="line">x.numel() #å…ƒç´ æ€»æ•°</span><br><span class="line">x &#x3D; x.reshape(3,4) #å˜æ¢</span><br><span class="line">x &#x3D; torch.zeros((1,2,3)) #å…¨é›¶</span><br><span class="line">x &#x3D; torch.ones((2,3,4)) #å…¨ä¸€</span><br><span class="line">x &#x3D; torch.tensor(list) #æ ¹æ®listç”Ÿæˆtensor</span><br><span class="line">+ - * &#x2F; ** #å¯¹å…ƒç´ è¿›è¡Œè¿ç®—</span><br><span class="line">torch.exp(x) #æŒ‡æ•°è¿ç®—</span><br><span class="line">torch.cat((x,y),dim&#x3D;0) #åœ¨ç¬¬é›¶ç»´æ‹¼æ¥ï¼Œé›¶ç»´æ˜¯æœ€å¤–ä¾§</span><br><span class="line">x &#x3D;&#x3D; y #æ„å»ºäºŒå…ƒå¼ é‡ï¼Œæ˜¯å…ƒç´ æ¯”è¾ƒçš„ç»“æœ</span><br><span class="line">x.sum() #æ±‚å’Œï¼Œç»“æœæ˜¯ä¸€ä¸ªå…ƒç´ çš„tensor</span><br><span class="line">x[0:2,:]&#x3D;12 #åŒºåŸŸèµ‹å€¼</span><br><span class="line">x[:]&#x3D;x+y &#x2F; x+&#x3D;y #å‡å°‘å†…å­˜å¼€é”€ï¼Œå‰åä¸å˜</span><br><span class="line">y &#x3D; x.numpy() #tensorè½¬ndarray</span><br><span class="line">x &#x3D; torch.tensor(y) #ndarrayè½¬tensor</span><br><span class="line">x.item() &#x2F; float(x) &#x2F; int(x) #0ç»´å¼ é‡è½¬æ ‡é‡</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;pytorch-å­¦ä¹ ç¬”è®°&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    <category term="pytorch" scheme="http://example.com/categories/code/pytorch/"/>
    
    
  </entry>
  
  <entry>
    <title>fairseqè¸©å‘è®°å½•</title>
    <link href="http://example.com/2021/05/27/fairseq-tips1/"/>
    <id>http://example.com/2021/05/27/fairseq-tips1/</id>
    <published>2021-05-27T07:42:39.000Z</published>
    <updated>2021-05-27T08:45:45.621Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>è®°å½•ä¸€äº›fairseqä¸­é‡åˆ°çš„bugå’Œè§£å†³æ–¹æ¡ˆã€‚<br>fairseqç‰ˆæœ¬: 0.9.0</p></blockquote><span id="more"></span><h1 id="torch-maxè¿”å›å€¼"><a href="#torch-maxè¿”å›å€¼" class="headerlink" title="torch.maxè¿”å›å€¼"></a>torch.maxè¿”å›å€¼</h1><p>æŠ¥é”™ï¼š<code>TypeError: expected Tensor as element 0 in argument 0, but got torch.return_types.max</code></p><p>åŸå› æ˜¯torch.max(a, dim=)è¿”å›å€¼æ˜¯tupleç±»å‹ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å€¼ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯ç´¢å¼•ï¼Œå› æ­¤åªéœ€è¦è¿”å›å€¼çš„tensoræ—¶ï¼Œtorch.max(a, dim=).valueså³å¯</p><h1 id="å¯¼è‡´ç»´åº¦å˜åŒ–çš„å‘½ä»¤"><a href="#å¯¼è‡´ç»´åº¦å˜åŒ–çš„å‘½ä»¤" class="headerlink" title="å¯¼è‡´ç»´åº¦å˜åŒ–çš„å‘½ä»¤"></a>å¯¼è‡´ç»´åº¦å˜åŒ–çš„å‘½ä»¤</h1><p>torch.max=tf.reduce_sumï¼Œéƒ½ä¼šä½¿ç»´åº¦å‡ä¸€</p><p>a = a[:-1:] ä¹Ÿä¼šä½¿ç»´åº¦å‡ä¸€</p><p>catç»´åº¦ä¸å˜ï¼Œstackä½¿ç»´åº¦åŠ ä¸€ï¼Œéƒ½æ˜¯tensoræ‹¼æ¥çš„åŠŸèƒ½</p><h1 id="cpuå’Œgpuä¸Šå˜é‡çš„ç±»å‹ä¸åŒ¹é…é—®é¢˜"><a href="#cpuå’Œgpuä¸Šå˜é‡çš„ç±»å‹ä¸åŒ¹é…é—®é¢˜" class="headerlink" title="cpuå’Œgpuä¸Šå˜é‡çš„ç±»å‹ä¸åŒ¹é…é—®é¢˜"></a>cpuå’Œgpuä¸Šå˜é‡çš„ç±»å‹ä¸åŒ¹é…é—®é¢˜</h1><p>æŠ¥é”™ï¼šRuntimeError: expected device cpu but got device cuda:0</p><p>å¯èƒ½å‡ºç°é”™è¯¯çš„ä½ç½®ï¼š</p><ul><li><p>ç­‰å·å·¦è¾¹å’Œå³è¾¹ç±»å‹ä¸ä¸€æ ·</p></li><li><p>è¿ç®—ç¬¦å·¦å³ä¸¤ç«¯ç±»å‹ä¸åŒï¼Œä¾‹ï¼š+ - * /</p></li><li><p>åŒä¸€ä¸ªå‡½æ•°å†…ï¼Œä¼ å…¥å‚æ•°çš„ç±»å‹ä¸åŒï¼Œä¾‹matmulç­‰</p></li></ul><p>æŠŠtensorè½¬ç§»åˆ°ç›¸åŒçš„è®¾å¤‡ä¸Šè§£å†³é—®é¢˜</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-&gt;cuda : data.cuda()</span><br><span class="line">-&gt;cpu: data.cpu()</span><br><span class="line">-&gt;numpyï¼š</span><br><span class="line">cudaç±»å‹ä¸èƒ½ç›´æ¥è½¬numpy é¡»å…ˆè½¬æˆcpuç±»å‹ï¼Œdata.cpu().numpy()</span><br><span class="line">åœ¨cudaä¸‹è®­ç»ƒä¸­çš„æ•°æ®ä¸èƒ½ç›´æ¥è½¬æ¢ä¸ºnumpyï¼Œdata.cpu().detach().numpy()</span><br></pre></td></tr></table></figure><blockquote><p>å‚è€ƒ: <a href="https://blog.csdn.net/qq_41368074/article/details/105942534">https://blog.csdn.net/qq_41368074/article/details/105942534</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;è®°å½•ä¸€äº›fairseqä¸­é‡åˆ°çš„bugå’Œè§£å†³æ–¹æ¡ˆã€‚&lt;br&gt;fairseqç‰ˆæœ¬: 0.9.0&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    <category term="pytorch" scheme="http://example.com/categories/code/pytorch/"/>
    
    <category term="fairseq" scheme="http://example.com/categories/code/pytorch/fairseq/"/>
    
    
  </entry>
  
  <entry>
    <title>hexo-nextæ¡†æ¶é™„åŠ åŠŸèƒ½</title>
    <link href="http://example.com/2021/05/27/hexo-next-tips/"/>
    <id>http://example.com/2021/05/27/hexo-next-tips/</id>
    <published>2021-05-27T06:17:10.000Z</published>
    <updated>2021-05-28T05:10:34.487Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>hexo+nextæ¡†æ¶åšå®¢çš„ä¸€äº›é™„åŠ åŠŸèƒ½è®°å½•ã€‚<br>hexo: 5.4.0<br>next: 7.8.0</p></blockquote><span id="more"></span><h1 id="ç‰ˆæœ¬ä¿¡æ¯ï¼š"><a href="#ç‰ˆæœ¬ä¿¡æ¯ï¼š" class="headerlink" title="ç‰ˆæœ¬ä¿¡æ¯ï¼š"></a>ç‰ˆæœ¬ä¿¡æ¯ï¼š</h1><p>hexoå’Œnextç‰ˆæœ¬ä¿¡æ¯å¯åœ¨ç›¸åº”æ–‡ä»¶å¤¹çš„package.jsonä¸­æœç´¢versionæŸ¥çœ‹ã€‚</p><h1 id="ç‰ˆæƒå£°æ˜"><a href="#ç‰ˆæƒå£°æ˜" class="headerlink" title="ç‰ˆæƒå£°æ˜:"></a>ç‰ˆæƒå£°æ˜:</h1><p>åœ¨.\themes\next\layout_macro\ç›®å½•ä¸‹ï¼Œæ–°å»ºmy-copyright.swigæ–‡ä»¶ï¼Œå†…å®¹ä¸ºï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if page.copyright %&#125;</span><br><span class="line">&lt;div class&#x3D;&quot;my_post_copyright&quot;&gt;</span><br><span class="line">  &lt;script src&#x3D;&quot;&#x2F;&#x2F;cdn.bootcss.com&#x2F;clipboard.js&#x2F;1.5.10&#x2F;clipboard.min.js&quot;&gt;&lt;&#x2F;script&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- JSåº“ sweetalert å¯ä¿®æ”¹è·¯å¾„ --&gt;</span><br><span class="line">  &lt;script type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;&quot;http:&#x2F;&#x2F;jslibs.wuxubj.cn&#x2F;sweetalert_mini&#x2F;jquery-1.7.1.min.js&quot;&gt;&lt;&#x2F;script&gt;</span><br><span class="line">  &lt;script src&#x3D;&quot;http:&#x2F;&#x2F;jslibs.wuxubj.cn&#x2F;sweetalert_mini&#x2F;sweetalert.min.js&quot;&gt;&lt;&#x2F;script&gt;</span><br><span class="line">  &lt;link rel&#x3D;&quot;stylesheet&quot; type&#x3D;&quot;text&#x2F;css&quot; href&#x3D;&quot;http:&#x2F;&#x2F;jslibs.wuxubj.cn&#x2F;sweetalert_mini&#x2F;sweetalert.mini.css&quot;&gt;</span><br><span class="line"></span><br><span class="line">  &lt;p&gt;&lt;span&gt;æœ¬æ–‡æ ‡é¢˜:&lt;&#x2F;span&gt;&#123;&#123; page.title &#125;&#125;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;æœ¬æ–‡ä½œè€…:&lt;&#x2F;span&gt;xxx&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;æœ¬æ–‡é“¾æ¥:&lt;&#x2F;span&gt;&lt;a href&#x3D;&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot; title&#x3D;&quot;&#123;&#123; page.title &#125;&#125;&quot;&gt;&#123;&#123; page.permalink &#125;&#125;&lt;&#x2F;a&gt;</span><br><span class="line">    &lt;span class&#x3D;&quot;copy-path&quot;  title&#x3D;&quot;ç‚¹å‡»å¤åˆ¶æ–‡ç« é“¾æ¥&quot;&gt;&lt;i class&#x3D;&quot;fa fa-clipboard&quot; data-clipboard-text&#x3D;&quot;&#123;&#123; page.permalink &#125;&#125;&quot;  aria-label&#x3D;&quot;å¤åˆ¶æˆåŠŸï¼&quot;&gt;&lt;&#x2F;i&gt;&lt;&#x2F;span&gt;</span><br><span class="line">  &lt;&#x2F;p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;ç‰ˆæƒå£°æ˜:&lt;&#x2F;span&gt;æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨&lt;a rel&#x3D;&quot;license&quot; href&#x3D;&quot;https:&#x2F;&#x2F;creativecommons.org&#x2F;licenses&#x2F;by-nc-nd&#x2F;4.0&#x2F;&quot; target&#x3D;&quot;_blank&quot; title&#x3D;&quot;Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)&quot;&gt;CC BY-NC-ND&lt;&#x2F;a&gt;è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼&lt;&#x2F;p&gt;  </span><br><span class="line">&lt;&#x2F;div&gt;</span><br><span class="line">&lt;script&gt; </span><br><span class="line">    var clipboard &#x3D; new Clipboard(&#39;.fa-clipboard&#39;);</span><br><span class="line">    clipboard.on(&#39;success&#39;, $(function()&#123;</span><br><span class="line">      $(&quot;.fa-clipboard&quot;).click(function()&#123;</span><br><span class="line">        swal(&#123;   </span><br><span class="line">          title: &quot;&quot;,   </span><br><span class="line">          text: &#39;å¤åˆ¶æˆåŠŸ&#39;,   </span><br><span class="line">          html: false,</span><br><span class="line">          timer: 500,   </span><br><span class="line">          showConfirmButton: false</span><br><span class="line">        &#125;);</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;));  </span><br><span class="line">&lt;&#x2F;script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><p>æ‰“å¼€.\themes\next\layout_macro\post.swigæ–‡ä»¶ï¼Œåœ¨</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;#####################&#125;</span><br><span class="line">&#123;### END POST BODY ###&#125;</span><br><span class="line">&#123;#####################&#125;</span><br></pre></td></tr></table></figure><p>ä¹‹åæ·»åŠ ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--æ·»åŠ ç‰ˆæƒä¿¡æ¯--&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">    &#123;% if not is_index %&#125;</span><br><span class="line">    &#123;% include &#39;my-copyright.swig&#39; %&#125;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br></pre></td></tr></table></figure><p>åœ¨.\themes\next\source\css_common\components\post\ç›®å½•ä¸‹ï¼Œæ–°å»ºmy-post-copyright.stylæ–‡ä»¶</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">.my_post_copyright &#123;</span><br><span class="line">  width: 85%;</span><br><span class="line">  max-width: 45em;</span><br><span class="line">  margin: 2.8em auto 0;</span><br><span class="line">  padding: 0.5em 1.0em;</span><br><span class="line">  border: 1px solid #d3d3d3;</span><br><span class="line">  font-size: 0.93rem;</span><br><span class="line">  line-height: 1.6em;</span><br><span class="line">  word-break: break-all;</span><br><span class="line">  background: rgba(255,255,255,0.4);</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright p&#123;margin:0;&#125;</span><br><span class="line">.my_post_copyright span &#123;</span><br><span class="line">  display: inline-block;</span><br><span class="line">  width: 5.2em;</span><br><span class="line">  color: #333333; &#x2F;&#x2F; title color</span><br><span class="line">  font-weight: bold;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .raw &#123;</span><br><span class="line">  margin-left: 1em;</span><br><span class="line">  width: 5em;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright a &#123;</span><br><span class="line">  color: #808080;</span><br><span class="line">  border-bottom:0;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright a:hover &#123;</span><br><span class="line">  color: #0593d3; &#x2F;&#x2F; link color</span><br><span class="line">  text-decoration: underline;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright:hover .fa-clipboard &#123;</span><br><span class="line">  color: #000;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .post-url:hover &#123;</span><br><span class="line">  font-weight: normal;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .copy-path &#123;</span><br><span class="line">  margin-left: 1em;</span><br><span class="line">  width: 1em;</span><br><span class="line">  +mobile()&#123;display:none;&#125;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .copy-path:hover &#123;</span><br><span class="line">  color: #808080;</span><br><span class="line">  cursor: pointer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ‰“å¼€.\themes\next\source\css_common\components\post\post.stylæ–‡ä»¶ï¼Œåœ¨æœ€åæ·»åŠ ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@import &quot;my-post-copyright&quot;</span><br></pre></td></tr></table></figure><p>æ‰“å¼€.\scaffolds\post.mdæ–‡ä»¶ï¼Œè®¾ç½®æ–°æ–‡ä»¶å¼€å¯ç‰ˆæƒå£°æ˜</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: &#123;&#123; title &#125;&#125;</span><br><span class="line">date: &#123;&#123; date &#125;&#125;</span><br><span class="line">copyright: true #å¼€å¯</span><br><span class="line">---</span><br></pre></td></tr></table></figure><blockquote><p>å‚è€ƒï¼š<a href="https://blog.csdn.net/u011236348/article/details/88169271">https://blog.csdn.net/u011236348/article/details/88169271</a></p></blockquote><h1 id="è®¿å®¢-é˜…è¯»é‡ç»Ÿè®¡"><a href="#è®¿å®¢-é˜…è¯»é‡ç»Ÿè®¡" class="headerlink" title="è®¿å®¢/é˜…è¯»é‡ç»Ÿè®¡"></a>è®¿å®¢/é˜…è¯»é‡ç»Ÿè®¡</h1><p>æ‰“å¼€.\themes\next_config.ymlæ–‡ä»¶ï¼Œ<br>æœç´¢busuanzi_countå…³é”®å­—ï¼ŒæŠŠenableè®¾ç½®ä¸ºtrueï¼Œ</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Show Views &#x2F; Visitors of the website &#x2F; page with busuanzi.</span><br><span class="line"># Get more information on http:&#x2F;&#x2F;ibruce.info&#x2F;2015&#x2F;04&#x2F;04&#x2F;busuanzi</span><br><span class="line">busuanzi_count:</span><br><span class="line">  enable: true</span><br><span class="line">  total_visitors: true #è®¿å®¢æ•°</span><br><span class="line">  total_visitors_icon: fa fa-user</span><br><span class="line">  total_views: true #è®¿é—®æ•°</span><br><span class="line">  total_views_icon: fa fa-eye</span><br><span class="line">  post_views: true #æ–‡ç« é˜…è¯»é‡</span><br><span class="line">  post_views_icon: fa fa-eye</span><br></pre></td></tr></table></figure><p>åŒä¸€æ–‡ä»¶ï¼Œæœç´¢footerå…³é”®å­—ï¼Œåœ¨å…¶åº•ä¸‹æ·»åŠ counterï¼Œè®¾å€¼ä¸ºtrueã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">footer:</span><br><span class="line">  # Specify the date when the site was setup. If not defined, current year will be used.</span><br><span class="line">  #since: 2015</span><br><span class="line">  # count for visit</span><br><span class="line">  counter: true</span><br></pre></td></tr></table></figure><p>æ‰“å¼€.\themes\next\layout_partials\footer.swigæ–‡ä»¶ï¼Œæ·»åŠ ä»£ç ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if theme.footer.counter %&#125;</span><br><span class="line">    &lt;script async src&#x3D;&quot;&#x2F;&#x2F;dn-lbstatics.qbox.me&#x2F;busuanzi&#x2F;2.3&#x2F;busuanzi.pure.mini.js&quot;&gt;&lt;&#x2F;script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><p>è®¿å®¢ã€è®¿é—®æ¬¡æ•°åœ¨ç½‘ç«™ä¸»é¡µåº•éƒ¨ï¼Œæ–‡ç« é˜…è¯»é‡åœ¨æ–‡ç« å¼€å¤´ã€‚</p><blockquote><p>å‚è€ƒï¼š<a href="https://blog.csdn.net/baidu_34310405/article/details/102665373">https://blog.csdn.net/baidu_34310405/article/details/102665373</a></p></blockquote><h1 id="åšå®¢ä¸­æ’å…¥è‡ªå·±ç¼–å†™çš„htmlé¡µé¢"><a href="#åšå®¢ä¸­æ’å…¥è‡ªå·±ç¼–å†™çš„htmlé¡µé¢" class="headerlink" title="åšå®¢ä¸­æ’å…¥è‡ªå·±ç¼–å†™çš„htmlé¡µé¢"></a>åšå®¢ä¸­æ’å…¥è‡ªå·±ç¼–å†™çš„htmlé¡µé¢</h1><p>çœ‹åˆ°nextå®˜æ–¹readmeä¸­LEAFERxåšå®¢sentenceé¡µé¢å¾ˆå¥½çœ‹ï¼Œä¹ŸåŠ¨æ‰‹æä¸€ä¸ªç±»ä¼¼çš„ã€‚åˆ©ç”¨jQueryçš„å…¨å±æ»šåŠ¨æ’ä»¶fullPage.jså®ç°ï¼Œç½‘é¡µéƒ¨åˆ†ä¸»è¦å‚è€ƒé“¾æ¥ä¸­çš„ä»£ç ã€‚</p><p>å°†è‡ªå·±çš„htmlé¡µé¢æ’å…¥åšå®¢ä¸­ï¼Œé¦–å…ˆæ–°å»ºä¸€ä¸ªé¡µé¢<code>hexo new page &quot;schedule&quot;</code>ï¼Œåœ¨ç”Ÿæˆçš„æ–‡ä»¶å¤¹source/schedule/ä¸‹å¤åˆ¶ç½‘é¡µçš„css/js/htmlæ–‡ä»¶ã€‚</p><p>ä¿®æ”¹æ ¹ç›®å½•ä¸‹çš„<code>_config.yml</code>æ–‡ä»¶ï¼Œè·³è¿‡è‡ªå®šä¹‰é¡µé¢çš„æ¸²æŸ“è¿‡ç¨‹ï¼Œè‹¥æ–‡ä»¶å¤¹ä¸‹æœ‰å­æ–‡ä»¶å¤¹ï¼Œéœ€è¦æ”¹ä¸º<code>schedule/**</code>ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">skip_render:</span><br><span class="line"> - &quot;schedule&#x2F;*&quot;</span><br></pre></td></tr></table></figure><blockquote><p>å‚è€ƒï¼š<a href="https://www.dowebok.com/77.html">https://www.dowebok.com/77.html</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;hexo+nextæ¡†æ¶åšå®¢çš„ä¸€äº›é™„åŠ åŠŸèƒ½è®°å½•ã€‚&lt;br&gt;hexo: 5.4.0&lt;br&gt;next: 7.8.0&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="other" scheme="http://example.com/categories/other/"/>
    
    <category term="hexo" scheme="http://example.com/categories/other/hexo/"/>
    
    <category term="next" scheme="http://example.com/categories/other/hexo/next/"/>
    
    
  </entry>
  
  <entry>
    <title>tf-tensorå˜æ¢</title>
    <link href="http://example.com/2021/05/27/tf-tensor-conversion/"/>
    <id>http://example.com/2021/05/27/tf-tensor-conversion/</id>
    <published>2021-05-27T05:53:10.000Z</published>
    <updated>2021-05-27T08:39:45.786Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>tensorflowä¸­tensorå˜æ¢çš„å‡½æ•°æ±‡æ€»ã€‚</p></blockquote><span id="more"></span><p><code>tf.stack</code><br>list-&gt;tensor<br>ï¼ˆtf.convert_to_tensorï¼‰</p><p><code>tf.unstack</code><br>tensor-&gt;list</p><p><code>tf.expand_dims</code><br>æ‰©å±•ç»´åº¦</p><p><code>reduce_sum/max/mean</code><br>å‡å°‘ç»´åº¦</p><p><code>tf.reshape</code><br>æ”¹å˜å„ç»´åº¦å¤§å°ï¼ˆå¯å¢åŠ å‡å°‘ç»´åº¦ï¼‰</p><p><code>tf.transpose</code><br>è°ƒæ¢ç»´åº¦é¡ºåº</p><p><code>tf.tile</code><br>ä¸æ”¹å˜ç»´åº¦çš„å¤åˆ¶</p><p><code>tf.concat</code><br>ä¸æ”¹å˜ç»´åº¦çš„æ‹¼æ¥</p><p><code>tf.broadcast_to</code><br>å¹¿æ’­</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;tensorflowä¸­tensorå˜æ¢çš„å‡½æ•°æ±‡æ€»ã€‚&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    <category term="tensorflow" scheme="http://example.com/categories/code/tensorflow/"/>
    
    
  </entry>
  
  <entry>
    <title>githubåšå®¢å¸¸ç”¨å‘½ä»¤</title>
    <link href="http://example.com/2021/05/27/blog-instructions/"/>
    <id>http://example.com/2021/05/27/blog-instructions/</id>
    <published>2021-05-27T04:00:45.000Z</published>
    <updated>2021-05-27T08:43:25.186Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>æ±‡æ€»ä¸€äº›åšå®¢å¸¸ç”¨å‘½ä»¤å’Œå¤‡ä»½åšå®¢çš„æ–¹æ³•ã€‚</p></blockquote><span id="more"></span><h1 id="æ–°å»ºï¼š"><a href="#æ–°å»ºï¼š" class="headerlink" title="æ–°å»ºï¼š"></a>æ–°å»ºï¼š</h1><p><code>hexo init [folder]</code><br>æ–°å»ºç½‘ç«™ï¼Œæœ‰folderå°±æ–°å»ºä¸€ä¸ªåä¸ºfolderçš„æ–‡ä»¶å¤¹å¹¶å°†ç½‘ç«™å­˜åœ¨è¯¥æ–‡ä»¶å¤¹ä¸‹ï¼Œæ²¡æœ‰folderå°±å°†ç½‘ç«™å­˜åœ¨å½“å‰ç›®å½•ä¸‹ã€‚</p><p><code>hexo new [layout] â€œtitleâ€</code><br>æ–°å»ºæ–‡ç« ï¼Œå¦‚æœæ²¡æœ‰è®¾ç½® layout çš„è¯ï¼Œé»˜è®¤ä½¿ç”¨ _config.yml ä¸­çš„ default_layout å‚æ•°ä»£æ›¿ï¼Œæ–‡ç« æ ‡é¢˜ç”¨åŒå¼•å·æ‹¬èµ·æ¥ã€‚</p><h1 id="éƒ¨ç½²æ›´æ”¹"><a href="#éƒ¨ç½²æ›´æ”¹" class="headerlink" title="éƒ¨ç½²æ›´æ”¹:"></a>éƒ¨ç½²æ›´æ”¹:</h1><p><code>hexo clean</code><br>æ¸…é™¤ç¼“å­˜æ–‡ä»¶(db.json)å’Œå·²ç”Ÿæˆçš„é™æ€æ–‡ä»¶(public)ï¼Œå½“æ›´æ”¹ä¸ç”Ÿæ•ˆæ—¶å¯ä»¥ä½¿ç”¨è¯¥å‘½ä»¤ã€‚</p><p><code>hexo g / hexo generate</code><br>ç”Ÿæˆé™æ€æ–‡ä»¶ï¼Œä¹‹åå¯å¯åŠ¨æœåŠ¡å™¨æˆ–è€…éƒ¨ç½²ç½‘ç«™ã€‚</p><p><code>hexo s / hexo server</code><br>å¯åŠ¨æœåŠ¡å™¨ï¼Œå¯è®¿é—®<a href="http://localhost:4000/%E6%9F%A5%E7%9C%8B%E3%80%82">http://localhost:4000/æŸ¥çœ‹ã€‚</a></p><p><code>hexo d / hexo deploy</code><br>éƒ¨ç½²ç½‘ç«™ï¼Œå¯è®¿é—®ç½‘ç«™é“¾æ¥æŸ¥çœ‹ã€‚</p><h1 id="ä¸Šä¼ æ–‡ä»¶ï¼š"><a href="#ä¸Šä¼ æ–‡ä»¶ï¼š" class="headerlink" title="ä¸Šä¼ æ–‡ä»¶ï¼š"></a>ä¸Šä¼ æ–‡ä»¶ï¼š</h1><p>åœ¨githubä¸Šcodeä¸‹è½½å¤„å¤åˆ¶<a href="https://github.com/xxx.git">https://github.com/xxx.git</a> çš„é“¾æ¥ï¼Œ<br>åœ¨æœ¬åœ°git bashä¸­è¾“å…¥<code>git clone https://github.com/xxx.git</code> å…‹éš†ä»“åº“åˆ°æœ¬åœ°ï¼Œ<br>å°†éœ€è¦ä¸Šä¼ çš„æ–‡ä»¶å¤åˆ¶åˆ°æœ¬åœ°ç”Ÿæˆçš„æ–‡ä»¶å¤¹ä¸­ï¼Œè¾“å…¥å‘½ä»¤ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add . #å°†æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶éƒ½æ·»åŠ è¿›æ¥</span><br><span class="line">git commit  -m  &quot;first commit&quot;  #â€œfirst commitâ€å¯æ›¿æ¢æˆä»»æ„éœ€è¦çš„æ³¨é‡Šä¿¡æ¯</span><br><span class="line">git push -u origin main  #å°†æœ¬åœ°ä»“åº“pushåˆ°githubä¸Šé¢ï¼Œ2020å¹´10æœˆ1æ—¥ä¹‹åï¼Œgithubæ–°åˆ›å»ºçš„ä»“åº“é»˜è®¤åˆ†æ”¯éƒ½å°†ä½¿ç”¨mainï¼Œè€Œä¸æ˜¯ä¹‹å‰çš„masterï¼Œè¦æ³¨æ„ã€‚</span><br></pre></td></tr></table></figure><h1 id="å¤‡ä»½"><a href="#å¤‡ä»½" class="headerlink" title="å¤‡ä»½"></a>å¤‡ä»½</h1><p>é‡‡ç”¨åŒä¸Šä¼ æ–‡ä»¶çš„æ–¹å¼æ¥å¤‡ä»½ç½‘ç«™æºæ–‡ä»¶ï¼Œåœ¨githubä¸Šå»ºç«‹ä¸€ä¸ªprivateä»“åº“ï¼Œå°†ç½‘ç«™çš„æ–‡ä»¶å¤¹æ•´ä½“ç§»åŠ¨åˆ°å…‹éš†åˆ°æœ¬åœ°çš„å¤‡ä»½æ–‡ä»¶å¤¹ä¸­ï¼Œæ¯éš”ä¸€æ®µæ—¶é—´ä¸Šä¼ æœ€æ–°çš„æ–‡ä»¶æ¥å¤‡ä»½ç½‘ç«™ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit  -m  &quot;backup&quot;</span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;æ±‡æ€»ä¸€äº›åšå®¢å¸¸ç”¨å‘½ä»¤å’Œå¤‡ä»½åšå®¢çš„æ–¹æ³•ã€‚&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="other" scheme="http://example.com/categories/other/"/>
    
    <category term="github" scheme="http://example.com/categories/other/github/"/>
    
    
  </entry>
  
  <entry>
    <title>fairseqä»£ç ä½ç½®è®°å½•</title>
    <link href="http://example.com/2021/05/21/fairseq-tips/"/>
    <id>http://example.com/2021/05/21/fairseq-tips/</id>
    <published>2021-05-21T10:59:52.000Z</published>
    <updated>2021-05-27T08:42:15.500Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>è®°å½•ä¸€äº›fairseqä¸­åŠŸèƒ½å®ç°çš„ä»£ç ä½ç½®ã€‚<br>fairseqç‰ˆæœ¬: 0.9.0</p></blockquote><span id="more"></span><h1 id="ensembleé›†æˆ"><a href="#ensembleé›†æˆ" class="headerlink" title="ensembleé›†æˆ"></a>ensembleé›†æˆ</h1><p>åœ¨fairseq/sequence_generator.pyä¸­760è¡Œï¼Œensembleåœ¨beam searchä¹‹å‰ã€‚</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;è®°å½•ä¸€äº›fairseqä¸­åŠŸèƒ½å®ç°çš„ä»£ç ä½ç½®ã€‚&lt;br&gt;fairseqç‰ˆæœ¬: 0.9.0&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="code" scheme="http://example.com/categories/code/"/>
    
    <category term="pytorch" scheme="http://example.com/categories/code/pytorch/"/>
    
    <category term="fairseq" scheme="http://example.com/categories/code/pytorch/fairseq/"/>
    
    
  </entry>
  
</feed>
